Index: PAMI/periodicFrequentPattern/maximal/MaxPFGrowth.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#  Copyright (C)  2021 Rage Uday Kiran\n#\n#      This program is free software: you can redistribute it and/or modify\n#      it under the terms of the GNU General Public License as published by\n#      the Free Software Foundation, either version 3 of the License, or\n#      (at your option) any later version.\n#\n#      This program is distributed in the hope that it will be useful,\n#      but WITHOUT ANY WARRANTY; without even the implied warranty of\n#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#      GNU General Public License for more details.\n#\n#      You should have received a copy of the GNU General Public License\n#      along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\n\nfrom PAMI.periodicFrequentPattern.maximal import abstract as _ab\n\n\n_minSup = float()\n_maxPer = float()\n_lno = int()\n\n\nclass _Node(object):\n    \"\"\"\n     A class used to represent the node of frequentPatternTree\n\n        ...\n\n        Attributes:\n        ----------\n            item : int\n                storing item of a node\n            timeStamps : list\n                To maintain the timestamps of Database at the end of the branch\n            parent : node\n                To maintain the parent of every node\n            children : list\n                To maintain the children of node\n\n        Methods:\n        -------\n            addChild(itemName)\n                storing the children to their respective parent nodes\n    \"\"\"\n    def __init__(self, item, children):\n        self.item = item\n        self.children = children\n        self.parent = None\n        self.timeStamps = []\n\n    def addChild(self, node):\n        \"\"\"\n        To add the children details to the parent node children list\n\n        :param node: children node\n\n        :return: adding to parent node children\n        \"\"\"\n        self.children[node.item] = node\n        node.parent = self\n\n\nclass _Tree(object):\n    \"\"\"\n    A class used to represent the frequentPatternGrowth tree structure\n\n        ...\n\n        Attributes:\n        ----------\n            root : Node\n                Represents the root node of the tree\n            summaries : dictionary\n                storing the nodes with same item name\n            info : dictionary\n                stores the support of items\n\n\n        Methods:\n        -------\n            addTransaction(Database)\n                creating Database as a branch in frequentPatternTree\n            getConditionPatterns(Node)\n                generates the conditional patterns from tree for specific node\n            conditionalTransaction(prefixPaths,Support)\n                takes the prefixPath of a node and support at child of the path and extract the frequent items from\n                prefixPaths and generates prefixPaths with items which are frequent\n            remove(Node)\n                removes the node from tree once after generating all the patterns respective to the node\n            generatePatterns(Node)\n                starts from the root node of the tree and mines the frequent patterns\n    \"\"\"\n    def __init__(self):\n        self.root = _Node(None, {})\n        self.summaries = {}\n        self.info = {}\n        self.maximalTree = _MPTree()\n\n    def addTransaction(self, transaction, tid):\n        \"\"\"\n        adding transaction into database\n\n        :param transaction: transactions in a database\n\n        :param tid: timestamp of the transaction in database\n\n        :return: pftree\n        \"\"\"\n        currentNode = self.root\n        for i in range(len(transaction)):\n            if transaction[i] not in currentNode.children:\n                newNode = _Node(transaction[i], {})\n                currentNode.addChild(newNode)\n                if transaction[i] in self.summaries:\n                    self.summaries[transaction[i]].append(newNode)\n                else:\n                    self.summaries[transaction[i]] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i]]\n        currentNode.timeStamps = currentNode.timeStamps + tid\n\n    def getConditionalPatterns(self, alpha):\n        \"\"\"\n        to get the conditional patterns of a node\n\n        :param alpha: node in the tree\n\n        :return: conditional patterns of a node\n        \"\"\"\n        finalPatterns = []\n        finalSets = []\n        for i in self.summaries[alpha]:\n            set1 = i.timeStamps\n            set2 = []\n            while i.parent.item is not None:\n                set2.append(i.parent.item)\n                i = i.parent\n            if len(set2) > 0:\n                set2.reverse()\n                finalPatterns.append(set2)\n                finalSets.append(set1)\n        finalPatterns, finalSets, info = _conditionalTransactions(finalPatterns, finalSets)\n        return finalPatterns, finalSets, info\n\n    def removeNode(self, nodeValue):\n        \"\"\"\n        removes the leaf node by pushing its timestamps to parent node\n\n        :param nodeValue: node of a tree\n\n        \"\"\"\n        for i in self.summaries[nodeValue]:\n            i.parent.timeStamps = i.parent.timeStamps + i.timeStamps\n            del i.parent.children[nodeValue]\n            i = None\n\n    def getTimeStamps(self, alpha):\n        \"\"\"\n        to get all the timestamps related to a node in tree\n\n        :param alpha: node of a tree\n\n        :return: timestamps of a node\n        \"\"\"\n        temp = []\n        for i in self.summaries[alpha]:\n            temp += i.timeStamps\n        return temp\n\n    def generatePatterns(self, prefix, patterns):\n        \"\"\"\n            To generate the maximal periodic frequent patterns\n\n            :param prefix: an empty list of itemSet to form the combinations\n\n            :return: maximal periodic frequent patterns\n        \"\"\"\n        for i in sorted(self.summaries, key=lambda x: (self.info.get(x), -x)):\n            pattern = prefix[:]\n            pattern.append(i)\n            condPattern, timeStamps, info = self.getConditionalPatterns(i)\n            conditionalTree = _Tree()\n            conditionalTree.info = info.copy()\n            head = pattern[:]\n            tail = []\n            for k in info:\n                tail.append(k)\n            sub = head + tail\n            if self.maximalTree.checkerSub(sub) == 1:\n                for pat in range(len(condPattern)):\n                    conditionalTree.addTransaction(condPattern[pat], timeStamps[pat])\n                if len(condPattern) >= 1:\n                    conditionalTree.generatePatterns(pattern, patterns)\n                else:\n                    self.maximalTree.addTransaction(pattern)\n                    #s = convert(pattern)\n                    patterns[tuple(pattern)] = self.info[i]\n            self.removeNode(i)\n\n\nclass _MNode(object):\n    \"\"\"\n    A class used to represent the node of frequentPatternTree\n\n        ...\n\n        Attributes:\n        ----------\n            item : int\n                storing item of a node\n            children : list\n                To maintain the children of node\n\n        Methods:\n        -------\n            addChild(itemName)\n                storing the children to their respective parent nodes\n    \"\"\"\n    def __init__(self, item, children):\n        self.item = item\n        self.children = children\n\n    def addChild(self, node):\n        \"\"\"\n        To add the children details to parent node children variable\n\n        :param node: children node\n\n        :return: adding children node to parent node\n        \"\"\"\n        self.children[node.item] = node\n        node.parent = self\n\n\nclass _MPTree(object):\n    \"\"\"\n    A class used to represent the node of frequentPatternTree\n\n        ...\n\n        Attributes:\n        ----------\n            root : node\n                the root of a tree\n            summaries : dict\n                to store the items with same name into dictionary\n\n        Methods:\n        -------\n            addTransaction(itemSet)\n                the generated periodic-frequent pattern is added into maximal-tree\n            checkerSub(itemSet)\n                to check of subset of itemSet is present in tree\n    \"\"\"\n    def __init__(self):\n        self.root = _MNode(None, {})\n        self.summaries = {}\n\n    def addTransaction(self, transaction):\n        \"\"\"\n        to add the transaction in maximal tree\n        :param transaction: resultant periodic frequent pattern\n        :return: maximal tree\n        \"\"\"\n        currentNode = self.root\n        transaction.sort()\n        for i in range(len(transaction)):\n            if transaction[i] not in currentNode.children:\n                newNode = _MNode(transaction[i], {})\n                currentNode.addChild(newNode)\n                if transaction[i] in self.summaries:\n                    self.summaries[transaction[i]].insert(0, newNode)\n                else:\n                    self.summaries[transaction[i]] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i]]\n\n    def checkerSub(self, items):\n        \"\"\"\n        To check subset present of items in the maximal tree\n        :param items: the pattern to check for subsets\n        :return: 1\n        \"\"\"\n        items.sort(reverse=True)\n        item = items[0]\n        if item not in self.summaries:\n            return 1\n        else:\n            if len(items) == 1:\n                return 0\n        for t in self.summaries[item]:\n            cur = t.parent\n            i = 1\n            while cur.item is not None:\n                if items[i] == cur.item:\n                    i += 1\n                    if i == len(items):\n                        return 0\n                cur = cur.parent\n        return 1\n\n\n#maximalTree = MPTree()\n\n\ndef _getPeriodAndSupport(timeStamps):\n    \"\"\"\n    To calculate the periodicity and support of a pattern with their respective timeStamps\n    :param timeStamps: timeStamps\n    :return: Support and periodicity\n    \"\"\"\n    timeStamps.sort()\n    cur = 0\n    per = 0\n    sup = 0\n    for j in range(len(timeStamps)):\n        per = max(per, timeStamps[j] - cur)\n        if per > _maxPer:\n            return [0, 0]\n        cur = timeStamps[j]\n        sup += 1\n    per = max(per, abs(_lno - cur))\n    return [sup, per]\n\n\ndef _conditionalTransactions(condPatterns, condTimeStamps):\n    \"\"\"\n    To calculate the timestamps of conditional items in conditional patterns\n    :param condPatterns: conditional patterns of node\n    :param condTimeStamps: timeStamps of a conditional patterns\n    :return: removing items with low minSup or periodicity and sort the conditional transactions\n    \"\"\"\n    pat = []\n    timeStamps = []\n    data1 = {}\n    for i in range(len(condPatterns)):\n        for j in condPatterns[i]:\n            if j in data1:\n                data1[j] = data1[j] + condTimeStamps[i]\n            else:\n                data1[j] = condTimeStamps[i]\n    updatedDict = {}\n    for m in data1:\n        updatedDict[m] = _getPeriodAndSupport(data1[m])\n    updatedDict = {k: v for k, v in updatedDict.items() if v[0] >= _minSup and v[1] <= _maxPer}\n    count = 0\n    for p in condPatterns:\n        p1 = [v for v in p if v in updatedDict]\n        trans = sorted(p1, key=lambda x: (updatedDict.get(x)[0], -x), reverse=True)\n        if len(trans) > 0:\n            pat.append(trans)\n            timeStamps.append(condTimeStamps[count])\n        count += 1\n    return pat, timeStamps, updatedDict\n\n\nclass MaxPFGrowth(_ab._periodicFrequentPatterns):\n    \"\"\" MaxPF-Growth is one of the fundamental algorithm to discover maximal periodic-frequent\n        patterns in a temporal database.\n\n        Reference:\n        --------\n            R. Uday Kiran, Yutaka Watanobe, Bhaskar Chaudhury, Koji Zettsu, Masashi Toyoda, Masaru Kitsuregawa,\n            \"Discovering Maximal Periodic-Frequent Patterns in Very Large Temporal Databases\",\n            IEEE 2020, https://ieeexplore.ieee.org/document/9260063\n\n        Attributes:\n        ----------\n            iFile : file\n                Name of the Input file or path of the input file\n            oFile : file\n                Name of the output file or path of the output file\n            minSup: int or float or str\n                The user can specify minSup either in count or proportion of database size.\n                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.\n                Otherwise, it will be treated as float.\n                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float\n            maxPer: int or float or str\n                The user can specify maxPer either in count or proportion of database size.\n                If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.\n                Otherwise, it will be treated as float.\n                Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float\n            sep : str\n                This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \\t.\n                However, the users can override their default separator.\n            memoryUSS : float\n                To store the total amount of USS memory consumed by the program\n            memoryRSS : float\n                To store the total amount of RSS memory consumed by the program\n            startTime:float\n                To record the start time of the mining process\n            endTime:float\n                To record the completion time of the mining process\n            Database : list\n                To store the transactions of a database in list\n            mapSupport : Dictionary\n                To maintain the information of item and their frequency\n            lno : int\n                it represents the total no of transaction\n            tree : class\n                it represents the Tree class\n            itemSetCount : int\n                it represents the total no of patterns\n            finalPatterns : dict\n                it represents to store the patterns\n\n        Methods:\n        -------\n            startMine()\n                Mining process will start from here\n            getPatterns()\n                Complete set of patterns will be retrieved with this function\n            savePatterns(oFile)\n                Complete set of periodic-frequent patterns will be loaded in to a output file\n            getPatternsAsDataFrame()\n                Complete set of periodic-frequent patterns will be loaded in to a dataframe\n            getMemoryUSS()\n                Total amount of USS memory consumed by the mining process will be retrieved from this function\n            getMemoryRSS()\n                Total amount of RSS memory consumed by the mining process will be retrieved from this function\n            getRuntime()\n                Total amount of runtime taken by the mining process will be retrieved from this function\n            creatingItemSets(fileName)\n                Scans the dataset or dataframes and stores in list format\n            PeriodicFrequentOneItem()\n                Extracts the one-periodic-frequent patterns from Databases\n            updateDatabases()\n                update the Databases by removing aperiodic items and sort the Database by item decreased support\n            buildTree()\n                after updating the Databases ar added into the tree by setting root node as null\n            startMine()\n                the main method to run the program\n\n        Executing the code on terminal:\n        -------\n            Format:\n            ------\n            python3 maxpfrowth.py <inputFile> <outputFile> <minSup> <maxPer>\n\n            Examples:\n            --------\n            python3 maxpfrowth.py sampleTDB.txt patterns.txt 0.3 0.4  (minSup will be considered in percentage of database\n            transactions)\n            python3 maxpfrowth.py sampleTDB.txt patterns.txt 3 4  (minSup will be considered in support count or frequency)\n            \n            \n        Sample run of the imported code:\n        --------------\n            from PAMI.periodicFrequentPattern.maximal import MaxPFGrowth as alg\n\n            obj = alg.MaxPFGrowth(\"../basic/sampleTDB.txt\", \"2\", \"6\")\n\n            obj.startMine()\n\n            Patterns = obj.getPatterns()\n\n            print(\"Total number of Frequent Patterns:\", len(Patterns))\n\n            obj.savePatterns(\"patterns\")\n\n            Df = obj.getPatternsAsDataFrame()\n    \n            memUSS = obj.getMemoryUSS()\n\n            print(\"Total Memory in USS:\", memUSS)\n\n            memRSS = obj.getMemoryRSS()\n\n            print(\"Total Memory in RSS\", memRSS)\n\n            run = obj.getRuntime()\n\n            print(\"Total ExecutionTime in seconds:\", run)\n\n            Credits:\n            -------\n            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\\n\n\n        \"\"\"\n    _startTime = float()\n    _endTime = float()\n    _minSup = str()\n    _maxPer = float()\n    _finalPatterns = {}\n    _iFile = \" \"\n    _oFile = \" \"\n    _sep = \" \"\n    _memoryUSS = float()\n    _memoryRSS = float()\n    _Database = []\n    _rank = {}\n    _rankedUp = {}\n    _lno = 0\n    _patterns = {}\n\n    def __init__(self, iFile, minSup, maxPer, sep='\\t'):\n        super().__init__(iFile, minSup, maxPer, sep)\n\n    def _creatingItemSets(self):\n        \"\"\" Storing the complete Databases of the database/input file in a database variable\n            :rtype: storing transactions into Database variable\n        \"\"\"\n        self._Database = []\n        if isinstance(self._iFile, _ab._pd.DataFrame):\n            data, ts = [], []\n            if self._iFile.empty:\n                print(\"its empty..\")\n            i = self._iFile.columns.values.tolist()\n            if 'TS' in i:\n                ts = self._iFile['TS'].tolist()\n            if 'Transactions' in i:\n                data = self._iFile['Transactions'].tolist()\n            for i in range(len(data)):\n                tr = [ts[i][0]] + data[i]\n                self._Database.append(tr)\n        if isinstance(self._iFile, str):\n            if _ab._validators.url(self._iFile):\n                data = _ab._urlopen(self._iFile)\n                for line in data:\n                    line.strip()\n                    line = line.decode(\"utf-8\")\n                    temp = [i.rstrip() for i in line.split(self._sep)]\n                    temp = [x for x in temp if x]\n                    self._Database.append(temp)\n            else:\n                try:\n                    with open(self._iFile, 'r', encoding='utf-8') as f:\n                        for line in f:\n                            line.strip()\n                            temp = [i.rstrip() for i in line.split(self._sep)]\n                            temp = [x for x in temp if x]\n                            self._Database.append(temp)\n                except IOError:\n                    print(\"File Not Found\")\n                    quit()\n\n    def _periodicFrequentOneItem(self):\n        \"\"\"\n            calculates the support of each item in the dataset and assign the ranks to the items\n            by decreasing support and returns the frequent items list\n            :rtype: return the one-length periodic frequent patterns\n\n\n            \"\"\"\n        data = {}\n        for tr in self._Database:\n            for i in range(1, len(tr)):\n                if tr[i] not in data:\n                    data[tr[i]] = [int(tr[0]), int(tr[0]), 1]\n                else:\n                    data[tr[i]][0] = max(data[tr[i]][0], (int(tr[0]) - data[tr[i]][1]))\n                    data[tr[i]][1] = int(tr[0])\n                    data[tr[i]][2] += 1\n        for key in data:\n            data[key][0] = max(data[key][0], abs(len(self._Database) - data[key][1]))\n        data = {k: [v[2], v[0]] for k, v in data.items() if v[0] <= self._maxPer and v[2] >= self._minSup}\n        pfList = [k for k, v in sorted(data.items(), key=lambda x: (x[1][0], x[0]), reverse=True)]\n        self._rank = dict([(index, item) for (item, index) in enumerate(pfList)])\n        return data\n\n    def _updateDatabases(self, dict1):\n        \"\"\" Remove the items which are not frequent from Databases and updates the Databases with rank of items\n\n            :param dict1: frequent items with support\n            :type dict1: dictionary\n            :rtype: sorted and updated transactions\n            \"\"\"\n        list1 = []\n        for tr in self._Database:\n            list2 = [int(tr[0])]\n            for i in range(1, len(tr)):\n                if tr[i] in dict1:\n                    list2.append(self._rank[tr[i]])\n            if len(list2) >= 2:\n                basket = list2[1:]\n                basket.sort()\n                list2[1:] = basket[0:]\n                list1.append(list2)\n        return list1\n\n    @staticmethod\n    def _buildTree(data, info):\n        \"\"\" it takes the Databases and support of each item and construct the main tree with setting root node as null\n\n            :param data: it represents the one Databases in database\n            :type data: list\n            :param info: it represents the support of each item\n            :type info: dictionary\n            :rtype: returns root node of tree\n        \"\"\"\n\n        rootNode = _Tree()\n        rootNode.info = info.copy()\n        for i in range(len(data)):\n            set1 = [data[i][0]]\n            rootNode.addTransaction(data[i][1:], set1)\n        return rootNode\n\n    def _savePeriodic(self, itemSet):\n        \"\"\"\n        To convert the ranks of items in to their original item names\n        :param itemSet: frequent pattern\n        :return: frequent pattern with original item names\n        \"\"\"\n        t1 = []\n        for i in itemSet:\n            t1.append(self._rankedUp[i])\n        return t1\n\n    def _convert(self, value):\n        \"\"\"\n        To convert the given user specified value\n\n        :param value: user specified value\n        :return: converted value\n        \"\"\"\n        if type(value) is int:\n            value = int(value)\n        if type(value) is float:\n            value = (len(self._Database) * value)\n        if type(value) is str:\n            if '.' in value:\n                value = float(value)\n                value = (len(self._Database) * value)\n            else:\n                value = int(value)\n        return value\n\n    def startMine(self):\n        \"\"\" Mining process will start from this function\n        \"\"\"\n\n        global _minSup, _maxPer, _lno\n        self._patterns = {}\n        self._startTime = _ab._time.time()\n        if self._iFile is None:\n            raise Exception(\"Please enter the file path or file name:\")\n        if self._minSup is None:\n            raise Exception(\"Please enter the Minimum Support\")\n        self._creatingItemSets()\n        self._minSup = self._convert(self._minSup)\n        self._maxPer = self._convert(self._maxPer)\n        _minSup, _maxPer, _lno = self._minSup, self._maxPer, len(self._Database)\n        if self._minSup > len(self._Database):\n            raise Exception(\"Please enter the minSup in range between 0 to 1\")\n        _generatedItems = self._periodicFrequentOneItem()\n        _updatedDatabases = self._updateDatabases(_generatedItems)\n        for x, y in self._rank.items():\n            self._rankedUp[y] = x\n        _info = {self._rank[k]: v for k, v in _generatedItems.items()}\n        _Tree = self._buildTree(_updatedDatabases, _info)\n        self._finalPatterns = {}\n        _Tree.generatePatterns([], self._patterns)\n        for x, y in self._patterns.items():\n            pattern = str()\n            x = self._savePeriodic(x)\n            for i in x:\n                pattern = pattern + i + \" \"\n            self._finalPatterns[pattern] = y\n        self._endTime = _ab._time.time()\n        _process = _ab._psutil.Process(_ab._os.getpid())\n        self._memoryUSS = float()\n        self._memoryRSS = float()\n        self._memoryUSS = _process.memory_full_info().uss\n        self._memoryRSS = _process.memory_info().rss\n        print(\"Maximal Periodic Frequent patterns were generated successfully using MAX-PFPGrowth algorithm \")\n\n    def getMemoryUSS(self):\n        \"\"\"Total amount of USS memory consumed by the mining process will be retrieved from this function\n\n        :return: returning USS memory consumed by the mining process\n        :rtype: float\n        \"\"\"\n\n        return self._memoryUSS\n\n    def getMemoryRSS(self):\n        \"\"\"Total amount of RSS memory consumed by the mining process will be retrieved from this function\n\n        :return: returning RSS memory consumed by the mining process\n        :rtype: float\n        \"\"\"\n\n        return self._memoryRSS\n\n    def getRuntime(self):\n        \"\"\"Calculating the total amount of runtime taken by the mining process\n\n\n        :return: returning total amount of runtime taken by the mining process\n        :rtype: float\n        \"\"\"\n\n        return self._endTime - self._startTime\n\n    def getPatternsAsDataFrame(self):\n        \"\"\"Storing final periodic-frequent patterns in a dataframe\n\n        :return: returning periodic-frequent patterns in a dataframe\n        :rtype: pd.DataFrame\n        \"\"\"\n\n        dataFrame = {}\n        data = []\n        for a, b in self._finalPatterns.items():\n            data.append([a, b[0], b[1]])\n            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])\n        return dataFrame\n\n    def savePatterns(self, outFile):\n        \"\"\"Complete set of periodic-frequent patterns will be loaded in to a output file\n\n        :param outFile: name of the output file\n        :type outFile: file\n        \"\"\"\n        self._oFile = outFile\n        writer = open(self._oFile, 'w+')\n        for x, y in self._finalPatterns.items():\n            s1 = x + \":\" + str(y[0]) + \":\" + str(y[1])\n            writer.write(\"%s \\n\" % s1)\n\n    def getPatterns(self):\n        \"\"\" Function to send the set of periodic-frequent patterns after completion of the mining process\n\n        :return: returning periodic-frequent patterns\n        :rtype: dict\n        \"\"\"\n        return self._finalPatterns\n\n\nif __name__ == \"__main__\":\n    _ap = str()\n    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:\n        if len(_ab._sys.argv) == 6:\n            _ap = MaxPFGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])\n        if len(_ab._sys.argv) == 5:\n            _ap = MaxPFGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])\n        _ap.startMine()\n        _Patterns = _ap.getPatterns()\n        print(\"Total number of  Patterns:\", len(_Patterns))\n        _ap.savePatterns(_ab._sys.argv[2])\n        _memUSS = _ap.getMemoryUSS()\n        print(\"Total Memory in USS:\", _memUSS)\n        _memRSS = _ap.getMemoryRSS()\n        print(\"Total Memory in RSS\", _memRSS)\n        _run = _ap.getRuntime()\n        print(\"Total ExecutionTime in ms:\", _run)\n    else:\n        '''ap = MaxPFGrowth('/Users/Likhitha/Downloads/Datasets/BMS1_itemset_mining.txt', 90, 10000, ' ')\n        ap.startMine()\n        Patterns = ap.getPatterns()\n        print(\"Total number of  Patterns:\", len(Patterns))\n        ap.savePatterns('/Users/Likhitha/Downloads/output')\n        memUSS = ap.getMemoryUSS()\n        print(\"Total Memory in USS:\", memUSS)\n        memRSS = ap.getMemoryRSS()\n        print(\"Total Memory in RSS\", memRSS)\n        run = ap.getRuntime()\n        print(\"Total ExecutionTime in ms:\", run)'''\n        print(\"Error! The number of input parameters do not match the total number of parameters provided\")        \n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/periodicFrequentPattern/maximal/MaxPFGrowth.py b/PAMI/periodicFrequentPattern/maximal/MaxPFGrowth.py
--- a/PAMI/periodicFrequentPattern/maximal/MaxPFGrowth.py	(revision 13e95f8a76f333a1a390dbc39efe0767be0b94b4)
+++ b/PAMI/periodicFrequentPattern/maximal/MaxPFGrowth.py	(date 1656441065324)
@@ -750,15 +750,17 @@
         _run = _ap.getRuntime()
         print("Total ExecutionTime in ms:", _run)
     else:
-        '''ap = MaxPFGrowth('/Users/Likhitha/Downloads/Datasets/BMS1_itemset_mining.txt', 90, 10000, ' ')
+        ap = MaxPFGrowth('/Users/Likhitha/Downloads/PSGrowth/sample.txt', 0.2, 10000, ' ')
         ap.startMine()
         Patterns = ap.getPatterns()
         print("Total number of  Patterns:", len(Patterns))
+        for x, y in Patterns.items():
+            print(x, y)
         ap.savePatterns('/Users/Likhitha/Downloads/output')
         memUSS = ap.getMemoryUSS()
         print("Total Memory in USS:", memUSS)
         memRSS = ap.getMemoryRSS()
         print("Total Memory in RSS", memRSS)
         run = ap.getRuntime()
-        print("Total ExecutionTime in ms:", run)'''
+        print("Total ExecutionTime in ms:", run)
         print("Error! The number of input parameters do not match the total number of parameters provided")        
Index: PAMI/extras/dbStats/temporalDatabaseStats.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import statistics\nimport pandas as pd\nimport validators\nimport numpy as np\nfrom urllib.request import urlopen\n\n\nclass temporalDatabaseStats:\n    \"\"\"\n    temporalDatabaseStats is class to get stats of database.\n\n        Attributes:\n        ----------\n        inputFile : file\n            input file path\n        database : dict\n            store time stamp and its transaction\n        lengthList : list\n            store size of all transaction\n        timeStampCount : dict\n            number of transactions per time stamp\n        periodList : list\n            all period list in the database\n        sep : str\n            separator in file. Default is tab space.\n\n        Methods:\n        -------\n        run()\n            execute readDatabase function\n        readDatabase()\n            read database from input file\n        getDatabaseSize()\n            get the size of database\n        getMinimumTransactionLength()\n            get the minimum transaction length\n        getAverageTransactionLength()\n            get the average transaction length. It is sum of all transaction length divided by database length.\n        getMaximumTransactionLength()\n            get the maximum transaction length\n        getStandardDeviationTransactionLength()\n            get the standard deviation of transaction length\n        getSortedListOfItemFrequencies()\n            get sorted list of item frequencies\n        getSortedListOfTransactionLength()\n            get sorted list of transaction length\n        save(data, outputFile)\n            store data into outputFile\n        getMinimumPeriod()\n            get the minimum period\n        getAveragePeriod()\n            get the average period\n        getMaximumPeriod()\n            get the maximum period\n        getStandardDeviationPeriod()\n            get the standard deviation period\n        getNumberOfTransactionsPerTimestamp()\n            get number of transactions per time stamp. This time stamp range is 1 to max period.\n    \"\"\"\n\n    def __init__(self, inputFile, sep='\\t'):\n        \"\"\"\n        :param inputFile: input file name or path\n        :type inputFile: str\n        :param sep:\n        \"\"\"\n        self.inputFile = inputFile\n        self.database = {}\n        self.lengthList = []\n        self.timeStampCount = {}\n        self.periodList = []\n        self.sep = sep\n\n    def run(self):\n        self.readDatabase()\n\n    def readDatabase(self):\n        \"\"\"\n        read database from input file and store into database and size of each transaction.\n        And store the period between transactions as list\n        \"\"\"\n        numberOfTransaction = 0\n        if isinstance(self.inputFile, pd.DataFrame):\n            if self.inputFile.empty:\n                print(\"its empty..\")\n            i = self.inputFile.columns.values.tolist()\n            if 'ts' in i and 'Transactions' in i:\n                self.database = self.inputFile.set_index('ts').T.to_dict(orient='records')[0]\n            if 'ts' in i and 'Patterns' in i:\n                self.database = self.inputFile.set_index('ts').T.to_dict(orient='records')[0]\n            self.timeStampCount = self.inputFile.groupby('ts').count().T.to_dict(orient='records')[0]\n\n        if isinstance(self.inputFile, str):\n            if validators.url(self.inputFile):\n                data = urlopen(self.inputFile)\n                for line in data:\n                    numberOfTransaction += 1\n                    line.strip()\n                    line = line.decode(\"utf-8\")\n                    temp = [i.rstrip() for i in line.split(self.sep)]\n                    temp = [x for x in temp if x]\n                    self.database[numberOfTransaction] = temp[1:]\n                    self.timeStampCount[int(temp[0])] = self.timeStampCount.get(int(line[0]), 0)\n                    self.timeStampCount[int(temp[0])] += 1\n            else:\n                try:\n                    with open(self.inputFile, 'r', encoding='utf-8') as f:\n                        for line in f:\n                            numberOfTransaction += 1\n                            line.strip()\n                            temp = [i.rstrip() for i in line.split(self.sep)]\n                            temp = [x for x in temp if x]\n                            if len(temp) > 0:\n                                self.database[numberOfTransaction] = temp[1:]\n                                self.timeStampCount[int(temp[0])] = self.timeStampCount.get(int(line[0]), 0)\n                                self.timeStampCount[int(temp[0])] += 1\n                except IOError:\n                    print(\"File Not Found\")\n                    quit()\n        self.lengthList = [len(s) for s in self.database.values()]\n        timeStampList = sorted(list(self.database.keys()))\n        preTimeStamp = 0\n        for ts in timeStampList:\n            self.periodList.append(int(ts) - preTimeStamp)\n            preTimeStamp = ts\n\n        # for line in self.Database:\n        #     numberOfTransaction += 1\n        #     self.database[numberOfTransaction] = line[1:]\n        #     self.timeStampCount[int(line[0])] = self.timeStampCount.get(int(line[0]), 0)\n        #     self.timeStampCount[int(line[0])] += 1\n        # self.lengthList = [len(s) for s in self.database.values()]\n        # timeStampList = sorted(list(self.timeStampCount.keys()))\n        # preTimeStamp = 0\n        # for ts in timeStampList:\n        #     self.periodList.append(int(ts)-preTimeStamp)\n        #     preTimeStamp = ts\n\n    def getDatabaseSize(self):\n        \"\"\"\n        get the size of database\n        :return: data base size\n        \"\"\"\n        return len(self.database)\n\n    def getMinimumTransactionLength(self):\n        \"\"\"\n        get the minimum transaction length\n        :return: minimum transaction length\n        \"\"\"\n        return min(self.lengthList)\n\n    def getAverageTransactionLength(self):\n        \"\"\"\n        get the average transaction length. It is sum of all transaction length divided by database length.\n        :return: average transaction length\n        \"\"\"\n        totalLength = sum(self.lengthList)\n        return totalLength / len(self.database)\n\n    def getMaximumTransactionLength(self):\n        \"\"\"\n        get the maximum transaction length\n        :return: maximum transaction length\n        \"\"\"\n        return max(self.lengthList)\n\n    def getStandardDeviationTransactionLength(self):\n        \"\"\"\n        get the standard deviation transaction length\n        :return: standard deviation transaction length\n        \"\"\"\n        return statistics.pstdev(self.lengthList)\n\n    def getVarianceTransactionLength(self):\n        \"\"\"\n        get the variance transaction length\n        :return: variance transaction length\n        \"\"\"\n        return statistics.variance(self.lengthList)\n\n    def convertDataIntoMatrix(self):\n        big_array = np.zeros((self.getDatabaseSize(), self.getMaximumTransactionLength()))\n        k = [i for i in self.database.values()]\n        for i in range(len(k)):\n            for j in range(len(k[i])):\n                big_array[i, j] = k[i][j]\n        return big_array\n\n    def getSparsity(self):\n        \"\"\"\n        get the sparsity of database. sparsity is percentage of 0 of database.\n        :return: database sparsity\n        \"\"\"\n        big_array = self.convertDataIntoMatrix()\n        n_zeros = np.count_nonzero(big_array == 0)\n        return (n_zeros / big_array.size)\n\n    def getDensity(self):\n        \"\"\"\n        get the sparsity of database. sparsity is percentage of 0 of database.\n        :return: database sparsity\n        \"\"\"\n        big_array = self.convertDataIntoMatrix()\n        n_zeros = np.count_nonzero(big_array != 0)\n        return (n_zeros / big_array.size)\n\n    def getTotalNumberOfItems(self):\n        \"\"\"\n        get the number of items in database.\n        :return: number of items\n        \"\"\"\n        return len(self.getSortedListOfItemFrequencies())\n\n    def getSortedListOfItemFrequencies(self):\n        \"\"\"\n        get sorted list of item frequencies\n        :return: item frequencies\n        \"\"\"\n        itemFrequencies = {}\n        for tid in self.database:\n            for item in self.database[tid]:\n                itemFrequencies[item] = itemFrequencies.get(item, 0)\n                itemFrequencies[item] += 1\n        return {k: v for k, v in sorted(itemFrequencies.items(), key=lambda x: x[1], reverse=True)}\n\n    def getTransanctionalLengthDistribution(self):\n        \"\"\"\n        get transaction length\n        :return: transaction length\n        \"\"\"\n        transactionLength = {}\n        for length in self.lengthList:\n            transactionLength[length] = transactionLength.get(length, 0)\n            transactionLength[length] += 1\n        return {k: v for k, v in sorted(transactionLength.items(), key=lambda x: x[0])}\n\n    def save(self, data, outputFile):\n        \"\"\"\n        store data into outputFile\n        :param data: input data\n        :type data: dict\n        :param outputFile: output file name or path to store\n        :type outputFile: str\n        \"\"\"\n        with open(outputFile, 'w') as f:\n            for key, value in data.items():\n                f.write(f'{key}\\t{value}\\n')\n\n    def getMinimumPeriod(self):\n        \"\"\"\n        get the minimum period\n        :return: minimum period\n        \"\"\"\n        return min(self.periodList)\n\n    def getAveragePeriod(self):\n        \"\"\"\n        get the average period. It is sum of all period divided by number of period.\n        :return: average period\n        \"\"\"\n        totalPeriod = sum(self.periodList)\n        return totalPeriod / len(self.periodList)\n\n    def getMaximumPeriod(self):\n        \"\"\"\n        get the maximum period\n        :return: maximum period\n        \"\"\"\n        return max(self.periodList)\n\n    def getStandardDeviationPeriod(self):\n        \"\"\"\n        get the standard deviation period\n        :return: standard deviation period\n        \"\"\"\n        return statistics.pstdev(self.periodList)\n\n    def getNumberOfTransactionsPerTimestamp(self):\n        \"\"\"\n        get number of transactions per time stamp\n        :return: number of transactions per time stamp as dict\n        \"\"\"\n        maxTS = max(list(self.timeStampCount.keys()))\n        return {ts: self.timeStampCount.get(ts, 0) for ts in range(1, maxTS + 1)}\n\n\nif __name__ == '__main__':\n    data = {'ts': [1, 1, 3, 4, 5, 6, 7],\n\n            'Transactions': [['a', 'd', 'e'], ['b', 'a', 'f', 'g', 'h'], ['b', 'a', 'd', 'f'], ['b', 'a', 'c'],\n                             ['a', 'd', 'g', 'k'],\n\n                             ['b', 'd', 'g', 'c', 'i'], ['b', 'd', 'g', 'e', 'j']]}\n\n    data = pd.DataFrame.from_dict(data)\n    obj = temporalDatabaseStats('https://www.u-aizu.ac.jp/~udayrage/datasets/temporalDatabases/temporal_T10I4D100K.csv')\n    import PAMI.extras.graph.plotLineGraphFromDictionary as plt\n\n    obj.run()\n    print(f'Database size : {obj.getDatabaseSize()}')\n    print(f'Minimum Transaction Size : {obj.getMinimumTransactionLength()}')\n    print(f'Average Transaction Size : {obj.getAverageTransactionLength()}')\n    print(f'Maximum Transaction Size : {obj.getMaximumTransactionLength()}')\n    print(f'Standard Deviation Transaction Size : {obj.getStandardDeviationTransactionLength()}')\n    print(f'Variance : {obj.getVarianceTransactionLength()}')\n    print(f'Sparsity : {obj.getSparsity()}')\n    print(f'Density : {obj.getDensity()}')\n    print(f'Number of items : {obj.getTotalNumberOfItems()}')\n    print(f'Minimum period : {obj.getMinimumPeriod()}')\n    print(f'Average period : {obj.getAveragePeriod()}')\n    print(f'Maximum period : {obj.getMaximumPeriod()}')\n    itemFrequencies = obj.getSortedListOfItemFrequencies()\n    transactionLength = obj.getTransanctionalLengthDistribution()\n    numberOfTransactionPerTimeStamp = obj.getNumberOfTransactionsPerTimestamp()\n    # obj.save(itemFrequencies, 'itemFrequency.csv')\n    # obj.save(transactionLength, 'transactionSize.csv')\n    # obj.save(numberOfTransactionPerTimeStamp, 'numberOfTransaction.csv')\n    plt.plotLineGraphFromDictionary(itemFrequencies, 100, 'itemFrequencies', 'item rank', 'frequency')\n    plt.plotLineGraphFromDictionary(transactionLength, 100, 'transaction length', 'transaction length', 'frequency')\n    plt.plotLineGraphFromDictionary(numberOfTransactionPerTimeStamp, 100)\n\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/extras/dbStats/temporalDatabaseStats.py b/PAMI/extras/dbStats/temporalDatabaseStats.py
--- a/PAMI/extras/dbStats/temporalDatabaseStats.py	(revision 13e95f8a76f333a1a390dbc39efe0767be0b94b4)
+++ b/PAMI/extras/dbStats/temporalDatabaseStats.py	(date 1656441065341)
@@ -180,12 +180,23 @@
         return statistics.variance(self.lengthList)
 
     def convertDataIntoMatrix(self):
-        big_array = np.zeros((self.getDatabaseSize(), self.getMaximumTransactionLength()))
-        k = [i for i in self.database.values()]
-        for i in range(len(k)):
-            for j in range(len(k[i])):
-                big_array[i, j] = k[i][j]
-        return big_array
+        singleItems = self.getSortedListOfItemFrequencies()
+        big_array = np.zeros((self.getDatabaseSize(), len(self.getSortedListOfItemFrequencies())))
+        itemsets = {}
+        for tid in self.database:
+            for item in singleItems:
+                if item in itemsets:
+                    if item in self.database[tid]:
+                        itemsets[item].append(1)
+                    else:
+                        itemsets[item].append(0)
+                else:
+                    if item in self.database[tid]:
+                        itemsets[item] = [1]
+                    else:
+                        itemsets[item] = [0]
+        new = pd.DataFrame.from_dict(itemsets)
+        return new.to_numpy()
 
     def getSparsity(self):
         """
@@ -202,7 +213,7 @@
         :return: database sparsity
         """
         big_array = self.convertDataIntoMatrix()
-        n_zeros = np.count_nonzero(big_array != 0)
+        n_zeros = np.count_nonzero(big_array == 1)
         return (n_zeros / big_array.size)
 
     def getTotalNumberOfItems(self):
Index: PAMI/frequentPattern/basic/FPGrowth.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#  Copyright (C)  2021 Rage Uday Kiran\n#\n#      This program is free software: you can redistribute it and/or modify\n#      it under the terms of the GNU General Public License as published by\n#      the Free Software Foundation, either version 3 of the License, or\n#      (at your option) any later version.\n#\n#      This program is distributed in the hope that it will be useful,\n#      but WITHOUT ANY WARRANTY; without even the implied warranty of\n#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#      GNU General Public License for more details.\n#\n#      You should have received a copy of the GNU General Public License\n#      along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nfrom PAMI.frequentPattern.basic import abstract as _fp\n\n_minSup = str()\n_fp._sys.setrecursionlimit(20000)\n\n\nclass _Node:\n    \"\"\"\n        A class used to represent the node of frequentPatternTree\n\n    Attributes:\n    ----------\n        itemId: int\n            storing item of a node\n        counter: int\n            To maintain the support of node\n        parent: node\n            To maintain the parent of node\n        children: list\n            To maintain the children of node\n\n    Methods:\n    -------\n\n        addChild(node)\n            Updates the nodes children list and parent for the given node\n\n    \"\"\"\n\n    def __init__(self, item, children):\n        self.itemId = item\n        self.counter = 1\n        self.parent = None\n        self.children = children\n\n    def addChild(self, node):\n        \"\"\"\n            Retrieving the child from the tree\n\n            :param node: Children node\n            :type node: Node\n            :return: Updates the children nodes and parent nodes\n\n        \"\"\"\n        self.children[node.itemId] = node\n        node.parent = self\n\n\nclass _Tree:\n    \"\"\"\n    A class used to represent the frequentPatternGrowth tree structure\n\n    Attributes:\n    ----------\n        root : Node\n            The first node of the tree set to Null.\n        summaries : dictionary\n            Stores the nodes itemId which shares same itemId\n        info : dictionary\n            frequency of items in the transactions\n\n    Methods:\n    -------\n        addTransaction(transaction, freq)\n            adding items of  transactions into the tree as nodes and freq is the count of nodes\n        getFinalConditionalPatterns(node)\n            getting the conditional patterns from fp-tree for a node\n        getConditionalPatterns(patterns, frequencies)\n            sort the patterns by removing the items with lower minSup\n        generatePatterns(prefix)\n            generating the patterns from fp-tree\n    \"\"\"\n\n    def __init__(self):\n        self.root = _Node(None, {})\n        self.summaries = {}\n        self.info = {}\n\n    def addTransaction(self, transaction, count):\n        \"\"\"adding transaction into tree\n\n        :param transaction: it represents the one transactions in database\n\n        :type transaction: list\n\n        :param count: frequency of item\n\n        :type count: int\n        \"\"\"\n\n        # This method takes transaction as input and returns the tree\n        currentNode = self.root\n        for i in range(len(transaction)):\n            if transaction[i] not in currentNode.children:\n                newNode = _Node(transaction[i], {})\n                newNode.freq = count\n                currentNode.addChild(newNode)\n                if transaction[i] in self.summaries:\n                    self.summaries[transaction[i]].append(newNode)\n                else:\n                    self.summaries[transaction[i]] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i]]\n                currentNode.freq += count\n\n    def getFinalConditionalPatterns(self, alpha):\n        \"\"\"\n        generates the conditional patterns for a node\n\n        Parameters:\n        ----------\n            alpha: node to generate conditional patterns\n\n        Returns\n        -------\n            returns conditional patterns, frequency of each item in conditional patterns\n\n        \"\"\"\n        finalPatterns = []\n        finalFreq = []\n        for i in self.summaries[alpha]:\n            set1 = i.freq\n            set2 = []\n            while i.parent.itemId is not None:\n                set2.append(i.parent.itemId)\n                i = i.parent\n            if len(set2) > 0:\n                set2.reverse()\n                finalPatterns.append(set2)\n                finalFreq.append(set1)\n        finalPatterns, finalFreq, info = self.getConditionalTransactions(finalPatterns, finalFreq)\n        return finalPatterns, finalFreq, info\n\n    @staticmethod\n    def getConditionalTransactions(ConditionalPatterns, conditionalFreq):\n        \"\"\"\n        To calculate the frequency of items in conditional patterns and sorting the patterns\n        Parameters\n        ----------\n        ConditionalPatterns: paths of a node\n        conditionalFreq: frequency of each item in the path\n\n        Returns\n        -------\n            conditional patterns and frequency of each item in transactions\n        \"\"\"\n        global _minSup\n        pat = []\n        freq = []\n        data1 = {}\n        for i in range(len(ConditionalPatterns)):\n            for j in ConditionalPatterns[i]:\n                if j in data1:\n                    data1[j] += conditionalFreq[i]\n                else:\n                    data1[j] = conditionalFreq[i]\n        up_dict = {k: v for k, v in data1.items() if v >= _minSup}\n        count = 0\n        for p in ConditionalPatterns:\n            p1 = [v for v in p if v in up_dict]\n            trans = sorted(p1, key=lambda x: (up_dict.get(x), -x), reverse=True)\n            if len(trans) > 0:\n                pat.append(trans)\n                freq.append(conditionalFreq[count])\n            count += 1\n        return pat, freq, up_dict\n\n    def generatePatterns(self, prefix):\n        \"\"\"\n        To generate the frequent patterns\n        Parameters\n        ----------\n        prefix: an empty list\n\n        Returns\n        -------\n        Frequent patterns that are extracted from fp-tree\n\n        \"\"\"\n        for i in sorted(self.summaries, key=lambda x: (self.info.get(x), -x)):\n            pattern = prefix[:]\n            pattern.append(i)\n            yield pattern, self.info[i]\n            patterns, freq, info = self.getFinalConditionalPatterns(i)\n            conditionalTree = _Tree()\n            conditionalTree.info = info.copy()\n            for pat in range(len(patterns)):\n                conditionalTree.addTransaction(patterns[pat], freq[pat])\n            if len(patterns) > 0:\n                for q in conditionalTree.generatePatterns(pattern):\n                    yield q\n\n\nclass FPGrowth(_fp._frequentPatterns):\n    \"\"\"\n       FPGrowth is one of the fundamental algorithm to discover frequent patterns in a transactional database.\n       It stores the database in compressed fp-tree decreasing the memory usage and extracts the\n       patterns from tree.It employs employs downward closure property to  reduce the search space effectively.\n\n    Reference :\n    ---------\n           Han, J., Pei, J., Yin, Y. et al. Mining Frequent Patterns without Candidate Generation: A Frequent-Pattern\n           Tree Approach. Data  Mining and Knowledge Discovery 8, 5387 (2004). https://doi.org/10.1023\n\n    Attributes :\n    ----------\n        iFile : file\n            Input file name or path of the input file\n        minSup: float or int or str\n            The user can specify minSup either in count or proportion of database size.\n            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.\n            Otherwise, it will be treated as float.\n            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float\n        sep : str\n            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \\t.\n            However, the users can override their default separator.\n        oFile : file\n            Name of the output file or the path of the output file\n        startTime:float\n            To record the start time of the mining process\n        endTime:float\n            To record the completion time of the mining process\n        memoryUSS : float\n            To store the total amount of USS memory consumed by the program\n        memoryRSS : float\n            To store the total amount of RSS memory consumed by the program\n        Database : list\n            To store the transactions of a database in list\n        mapSupport : Dictionary\n            To maintain the information of item and their frequency\n        lno : int\n            it represents the total no of transactions\n        tree : class\n            it represents the Tree class\n        finalPatterns : dict\n            it represents to store the patterns\n\n    Methods :\n    -------\n        startMine()\n            Mining process will start from here\n        getPatterns()\n            Complete set of patterns will be retrieved with this function\n        savePatterns(oFile)\n            Complete set of frequent patterns will be loaded in to a output file\n        getPatternsAsDataFrame()\n            Complete set of frequent patterns will be loaded in to a dataframe\n        getMemoryUSS()\n            Total amount of USS memory consumed by the mining process will be retrieved from this function\n        getMemoryRSS()\n            Total amount of RSS memory consumed by the mining process will be retrieved from this function\n        getRuntime()\n            Total amount of runtime taken by the mining process will be retrieved from this function\n        creatingItemSets()\n            Scans the dataset or dataframes and stores in list format\n        frequentOneItem()\n            Extracts the one-frequent patterns from transactions\n            \n    Executing the code on terminal:\n    -------\n        Format:\n        -------\n            python3 FPGrowth.py <inputFile> <outputFile> <minSup>\n\n        Examples:\n        ---------\n            python3 FPGrowth.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)\n\n            python3 FPGrowth.py sampleDB.txt patterns.txt 10     (minSup will be considered in support count or frequency) (it will consider \"\\t\" as a separator)\n\n            python3 FPGrowth.py sampleTDB.txt output.txt sampleN.txt 3 ',' (it will consider \",\" as a separator)\n\n\n    Sample run of the importing code:\n    -----------\n\n\n        from PAMI.frequentPattern.basic import FPGrowth as alg\n\n        obj = alg.FPGrowth(iFile, minSup)\n\n        obj.startMine()\n\n        frequentPatterns = obj.getPatterns()\n\n        print(\"Total number of Frequent Patterns:\", len(frequentPatterns))\n\n        obj.savePatterns(oFile)\n\n        Df = obj.getPatternInDataFrame()\n\n        memUSS = obj.getMemoryUSS()\n\n        print(\"Total Memory in USS:\", memUSS)\n\n        memRSS = obj.getMemoryRSS()\n\n        print(\"Total Memory in RSS\", memRSS)\n\n        run = obj.getRuntime()\n\n        print(\"Total ExecutionTime in seconds:\", run)\n\n        Credits:\n        -------\n        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\\n\n\n        \"\"\"\n\n    __startTime = float()\n    __endTime = float()\n    _minSup = str()\n    __finalPatterns = {}\n    _iFile = \" \"\n    _oFile = \" \"\n    _sep = \" \"\n    __memoryUSS = float()\n    __memoryRSS = float()\n    __Database = []\n    __mapSupport = {}\n    __lno = 0\n    __tree = _Tree()\n    __rank = {}\n    __rankDup = {}\n\n    def __init__(self, iFile, minSup, sep='\\t'):\n        super().__init__(iFile, minSup, sep)\n\n    def __creatingItemSets(self):\n        \"\"\"\n            Storing the complete transactions of the database/input file in a database variable\n\n\n        \"\"\"\n        self.__Database = []\n        if isinstance(self._iFile, _fp._pd.DataFrame):\n            if self._iFile.empty:\n                print(\"its empty..\")\n            i = self._iFile.columns.values.tolist()\n            if 'Transactions' in i:\n                self.__Database = self._iFile['Transactions'].tolist()\n\n            #print(self.Database)\n        if isinstance(self._iFile, str):\n            if _fp._validators.url(self._iFile):\n                data = _fp._urlopen(self._iFile)\n                for line in data:\n                    line.strip()\n                    line = line.decode(\"utf-8\")\n                    temp = [i.rstrip() for i in line.split(self._sep)]\n                    temp = [x for x in temp if x]\n                    self.__Database.append(temp)\n            else:\n                try:\n                    with open(self._iFile, 'r', encoding='utf-8') as f:\n                        for line in f:\n                            line.strip()\n                            temp = [i.rstrip() for i in line.split(self._sep)]\n                            temp = [x for x in temp if x]\n                            self.__Database.append(temp)\n                except IOError:\n                    print(\"File Not Found\")\n                    quit()\n\n    def __convert(self, value):\n        \"\"\"\n        to convert the type of user specified minSup value\n\n        :param value: user specified minSup value\n\n        :return: converted type\n        \"\"\"\n        if type(value) is int:\n            value = int(value)\n        if type(value) is float:\n            value = (len(self.__Database) * value)\n        if type(value) is str:\n            if '.' in value:\n                value = float(value)\n                value = (len(self.__Database) * value)\n            else:\n                value = int(value)\n        return value\n\n    def __frequentOneItem(self):\n        \"\"\"\n        Generating One frequent items sets\n\n        \"\"\"\n        self.__mapSupport = {}\n        for tr in self.__Database:\n            for i in range(0, len(tr)):\n                if tr[i] not in self.__mapSupport:\n                    self.__mapSupport[tr[i]] = 1\n                else:\n                    self.__mapSupport[tr[i]] += 1\n        self.__mapSupport = {k: v for k, v in self.__mapSupport.items() if v >= self._minSup}\n        genList = [k for k, v in sorted(self.__mapSupport.items(), key=lambda x: x[1], reverse=True)]\n        self.__rank = dict([(index, item) for (item, index) in enumerate(genList)])\n        return genList\n\n    def __updateTransactions(self, itemSet):\n        \"\"\"\n        Updates the items in transactions with rank of items according to their support\n\n        :Example: oneLength = {'a':7, 'b': 5, 'c':'4', 'd':3}\n                    rank = {'a':0, 'b':1, 'c':2, 'd':3}\n\n        Parameters\n        ----------\n        itemSet: list of one-frequent items\n\n        -------\n\n        \"\"\"\n        list1 = []\n        for tr in self.__Database:\n            list2 = []\n            for i in range(len(tr)):\n                if tr[i] in itemSet:\n                    list2.append(self.__rank[tr[i]])\n            if len(list2) >= 1:\n                list2.sort()\n                list1.append(list2)\n        return list1\n\n    @staticmethod\n    def __buildTree(transactions, info):\n        \"\"\"\n        Builds the tree with updated transactions\n        Parameters:\n        ----------\n            transactions: updated transactions\n            info: support details of each item in transactions\n\n        Returns:\n        -------\n            transactions compressed in fp-tree\n\n        \"\"\"\n        rootNode = _Tree()\n        rootNode.info = info.copy()\n        for i in range(len(transactions)):\n            rootNode.addTransaction(transactions[i], 1)\n        return rootNode\n\n    def __savePeriodic(self, itemSet):\n        \"\"\"\n        The duplication items and their ranks\n        Parameters:\n        ----------\n            itemSet: frequent itemSet that generated\n\n        Returns:\n        -------\n            patterns with original item names.\n\n        \"\"\"\n        temp = str()\n        for i in itemSet:\n            temp = temp + self.__rankDup[i] + \" \"\n        return temp\n\n    def startMine(self):\n        \"\"\"\n            main program to start the operation\n\n        \"\"\"\n        global _minSup\n        self.__startTime = _fp._time.time()\n        if self._iFile is None:\n            raise Exception(\"Please enter the file path or file name:\")\n        if self._minSup is None:\n            raise Exception(\"Please enter the Minimum Support\")\n        self.__creatingItemSets()\n        self._minSup = self.__convert(self._minSup)\n        _minSup = self._minSup\n        itemSet = self.__frequentOneItem()\n        updatedTransactions = self.__updateTransactions(itemSet)\n        for x, y in self.__rank.items():\n            self.__rankDup[y] = x\n        info = {self.__rank[k]: v for k, v in self.__mapSupport.items()}\n        __Tree = self.__buildTree(updatedTransactions, info)\n        patterns = __Tree.generatePatterns([])\n        self.__finalPatterns = {}\n        for k in patterns:\n            s = self.__savePeriodic(k[0])\n            self.__finalPatterns[str(s)] = k[1]\n        print(\"Frequent patterns were generated successfully using frequentPatternGrowth algorithm\")\n        self.__endTime = _fp._time.time()\n        self.__memoryUSS = float()\n        self.__memoryRSS = float()\n        process = _fp._psutil.Process(_fp._os.getpid())\n        self.__memoryUSS = process.memory_full_info().uss\n        self.__memoryRSS = process.memory_info().rss\n\n    def getMemoryUSS(self):\n        \"\"\"Total amount of USS memory consumed by the mining process will be retrieved from this function\n\n        :return: returning USS memory consumed by the mining process\n\n        :rtype: float\n        \"\"\"\n\n        return self.__memoryUSS\n\n    def getMemoryRSS(self):\n        \"\"\"Total amount of RSS memory consumed by the mining process will be retrieved from this function\n\n        :return: returning RSS memory consumed by the mining process\n\n        :rtype: float\n        \"\"\"\n\n        return self.__memoryRSS\n\n    def getRuntime(self):\n        \"\"\"Calculating the total amount of runtime taken by the mining process\n\n\n        :return: returning total amount of runtime taken by the mining process\n\n        :rtype: float\n        \"\"\"\n\n        return self.__endTime - self.__startTime\n\n    def getPatternsAsDataFrame(self):\n        \"\"\"Storing final frequent patterns in a dataframe\n\n        :return: returning frequent patterns in a dataframe\n\n        :rtype: pd.DataFrame\n        \"\"\"\n\n        dataframe = {}\n        data = []\n        for a, b in self.__finalPatterns.items():\n            data.append([a, b])\n            dataframe = _fp._pd.DataFrame(data, columns=['Patterns', 'Support'])\n        return dataframe\n\n    def savePatterns(self, outFile):\n        \"\"\"Complete set of frequent patterns will be loaded in to a output file\n\n        :param outFile: name of the output file\n\n        :type outFile: file\n        \"\"\"\n        self._oFile = outFile\n        writer = open(self._oFile, 'w+')\n        for x, y in self.__finalPatterns.items():\n            s1 = x + \":\" + str(y)\n            writer.write(\"%s \\n\" % s1)\n\n    def getPatterns(self):\n        \"\"\" Function to send the set of frequent patterns after completion of the mining process\n\n        :return: returning frequent patterns\n\n        :rtype: dict\n        \"\"\"\n        return self.__finalPatterns\n\n\nif __name__ == \"__main__\":\n    _ap = str()\n    if len(_fp._sys.argv) == 4 or len(_fp._sys.argv) == 5:\n        if len(_fp._sys.argv) == 5:\n            _ap = FPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4])\n        if len(_fp._sys.argv) == 4:\n            _ap = FPGrowth(_fp._sys.argv[1], _fp._sys.argv[3])\n        _ap.startMine()\n        _Patterns = _ap.getPatterns()\n        print(\"Total number of Frequent Patterns:\", len(_Patterns))\n        _ap.savePatterns(_fp._sys.argv[2])\n        _memUSS = _ap.getMemoryUSS()\n        print(\"Total Memory in USS:\", _memUSS)\n        _memRSS = _ap.getMemoryRSS()\n        print(\"Total Memory in RSS\", _memRSS)\n        _run = _ap.getRuntime()\n        print(\"Total ExecutionTime in ms:\", _run)\n    else:\n        '''_ap = FPGrowth('/Users/Likhitha/Downloads/dense_DB_3.csv', 23, ',')\n        _ap.startMine()\n        _Patterns = _ap.getPatterns()\n        print(\"Total number of Patterns:\", len(_Patterns))\n        _ap.savePatterns('/Users/Likhitha/Downloads/output.txt')\n        _memUSS = _ap.getMemoryUSS()\n        print(\"Total Memory in USS:\", _memUSS)\n        _memRSS = _ap.getMemoryRSS()\n        print(\"Total Memory in RSS\", _memRSS)\n        _run = _ap.getRuntime()\n        print(\"Total ExecutionTime in ms:\", _run)'''\n        print(\"Error! The number of input parameters do not match the total number of parameters provided\")\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/frequentPattern/basic/FPGrowth.py b/PAMI/frequentPattern/basic/FPGrowth.py
--- a/PAMI/frequentPattern/basic/FPGrowth.py	(revision 13e95f8a76f333a1a390dbc39efe0767be0b94b4)
+++ b/PAMI/frequentPattern/basic/FPGrowth.py	(date 1656441065352)
@@ -597,15 +597,17 @@
         _run = _ap.getRuntime()
         print("Total ExecutionTime in ms:", _run)
     else:
-        '''_ap = FPGrowth('/Users/Likhitha/Downloads/dense_DB_3.csv', 23, ',')
-        _ap.startMine()
-        _Patterns = _ap.getPatterns()
-        print("Total number of Patterns:", len(_Patterns))
-        _ap.savePatterns('/Users/Likhitha/Downloads/output.txt')
-        _memUSS = _ap.getMemoryUSS()
-        print("Total Memory in USS:", _memUSS)
-        _memRSS = _ap.getMemoryRSS()
-        print("Total Memory in RSS", _memRSS)
-        _run = _ap.getRuntime()
-        print("Total ExecutionTime in ms:", _run)'''
+        l = [0.2]
+        for i in l:
+            ap = FPGrowth('/Users/Likhitha/Downloads/gurgaonNote0.6.txt', i, ' ')
+            ap.startMine()
+            Patterns = ap.getPatterns()
+            print("Total number of Closed Frequent Patterns:", len(Patterns))
+            ap.savePatterns('/Users/Likhitha/Downloads/outputFP.txt')
+            memUSS = ap.getMemoryUSS()
+            print("Total Memory in USS:", memUSS)
+            memRSS = ap.getMemoryRSS()
+            print("Total Memory in RSS", memRSS)
+            run = ap.getRuntime()
+            print("Total ExecutionTime in ms:", run)
         print("Error! The number of input parameters do not match the total number of parameters provided")
Index: PAMI/partialPeriodicPattern/maximal/Max3PGrowth.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#  Copyright (C)  2021 Rage Uday Kiran\n#\n#      This program is free software: you can redistribute it and/or modify\n#      it under the terms of the GNU General Public License as published by\n#      the Free Software Foundation, either version 3 of the License, or\n#      (at your option) any later version.\n#\n#      This program is distributed in the hope that it will be useful,\n#      but WITHOUT ANY WARRANTY; without even the implied warranty of\n#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#      GNU General Public License for more details.\n#\n#      You should have received a copy of the GNU General Public License\n#      along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nimport sys as _sys\nimport validators as _validators\nfrom urllib.request import urlopen as _urlopen\nfrom PAMI.partialPeriodicPattern.maximal import abstract as _abstract\n\n_periodicSupport = float()\n_period = float()\n_lno = int()\n\n\n\nclass _Node(object):\n    \"\"\"\n    A class used to represent the node of frequentPatternTree\n\n    ...\n\n    Attributes:\n    ----------\n        item : int\n            storing item of a node\n        timeStamps : list\n            To maintain the timestamps of Database at the end of the branch\n        parent : node\n            To maintain the parent of every node\n        children : list\n            To maintain the children of node\n\n    Methods:\n    -------\n\n        addChild(itemName)\n            storing the children to their respective parent nodes\n    \"\"\"\n\n    def __init__(self, item, children):\n        self.item = item\n        self.children = children\n        self.parent = None\n        self.timeStamps = []\n\n    def _addChild(self, node):\n        \"\"\"\n        To add the children details to the parent node children list\n\n        :param node: children node\n\n        :return: adding to parent node children\n        \"\"\"\n        self.children[node.item] = node\n        node.parent = self\n\n\nclass _Tree(object):\n    \"\"\"\n    A class used to represent the frequentPatternGrowth tree structure\n\n    ...\n\n    Attributes:\n    ----------\n        root : Node\n            Represents the root node of the tree\n        summaries : dictionary\n            storing the nodes with same item name\n        info : dictionary\n            stores the support of items\n\n\n    Methods:\n    -------\n        addTransaction(Database)\n            creating Database as a branch in frequentPatternTree\n        getConditionPatterns(Node)\n            generates the conditional patterns from tree for specific node\n        conditionalTransaction(prefixPaths,Support)\n            takes the prefixPath of a node and support at child of the path and extract the frequent items from\n            prefixPaths and generates prefixPaths with items which are frequent\n        remove(Node)\n            removes the node from tree once after generating all the patterns respective to the node\n        generatePatterns(Node)\n            starts from the root node of the tree and mines the frequent patterns\n    \"\"\"\n\n    def __init__(self):\n        self.root = _Node(None, {})\n        self.summaries = {}\n        self.info = {}\n        self.maximalTree = _MPTree()\n\n    def _addTransaction(self, transaction, tid):\n        \"\"\"\n        adding transaction into database\n\n        :param transaction: transactions in a database\n\n        :param tid: timestamp of the transaction in database\n\n        :return: pftree\n        \"\"\"\n        currentNode = self.root\n        for i in range(len(transaction)):\n            if transaction[i] not in currentNode.children:\n                newNode = _Node(transaction[i], {})\n                currentNode._addChild(newNode)\n                if transaction[i] in self.summaries:\n                    self.summaries[transaction[i]].append(newNode)\n                else:\n                    self.summaries[transaction[i]] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i]]\n        currentNode.timeStamps = currentNode.timeStamps + tid\n\n    def _getConditionalPatterns(self, alpha):\n        \"\"\"\n        to get the conditional patterns of a node\n\n        :param alpha: node in the tree\n\n        :return: conditional patterns of a node\n        \"\"\"\n        finalPatterns = []\n        finalSets = []\n        for i in self.summaries[alpha]:\n            set1 = i.timeStamps\n            set2 = []\n            while i.parent.item is not None:\n                set2.append(i.parent.item)\n                i = i.parent\n            if len(set2) > 0:\n                set2.reverse()\n                finalPatterns.append(set2)\n                finalSets.append(set1)\n        finalPatterns, finalSets, info = _conditionalTransactions(finalPatterns, finalSets)\n        return finalPatterns, finalSets, info\n\n    def _removeNode(self, nodeValue):\n        \"\"\"\n        removes the leaf node by pushing its timestamps to parent node\n\n        :param nodeValue: node of a tree\n\n        :return:\n        \"\"\"\n        for i in self.summaries[nodeValue]:\n            i.parent.timeStamps = i.parent.timeStamps + i.timeStamps\n            del i.parent.children[nodeValue]\n            i = None\n\n    def _getTimeStamps(self, alpha):\n        \"\"\"\n        to get all the timestamps related to a node in tree\n\n        :param alpha: node of a tree\n\n        :return: timestamps of a node\n        \"\"\"\n        temp = []\n        for i in self.summaries[alpha]:\n            temp += i.timeStamps\n        return temp\n\n    def _generatePatterns(self, prefix, _patterns):\n        \"\"\"\n            To generate the maximal periodic frequent patterns\n\n            :param prefix: an empty list of itemSet to form the combinations\n\n            :return: maximal periodic frequent patterns\n        \"\"\"\n\n        for i in sorted(self.summaries, key=lambda x: (self.info.get(x), -x)):\n            pattern = prefix[:]\n            pattern.append(i)\n            condPattern, timeStamps, info = self._getConditionalPatterns(i)\n            conditionalTree = _Tree()\n            conditionalTree.info = info.copy()\n            head = pattern[:]\n            tail = []\n            for k in info:\n                tail.append(k)\n            sub = head + tail\n            if self.maximalTree._checkerSub(sub) == 1:\n                for pat in range(len(condPattern)):\n                    conditionalTree._addTransaction(condPattern[pat], timeStamps[pat])\n                if len(condPattern) >= 1:\n                    conditionalTree._generatePatterns(pattern, _patterns)\n                else:\n                    self.maximalTree._addTransaction(pattern)\n                    _patterns[tuple(pattern)] = self.info[i]\n            self._removeNode(i)\n\n\nclass _MNode(object):\n    \"\"\"\n    A class used to represent the node of frequentPatternTree\n\n    ...\n\n    Attributes:\n    ----------\n        item : int\n            storing item of a node\n        children : list\n            To maintain the children of node\n\n    Methods:\n    -------\n\n        addChild(itemName)\n            storing the children to their respective parent nodes\n    \"\"\"\n\n    def __init__(self, item, children):\n        self.item = item\n        self.children = children\n\n    def _addChild(self, node):\n        \"\"\"\n        To add the children details to parent node children variable\n\n        :param node: children node\n\n        :return: adding children node to parent node\n        \"\"\"\n        self.children[node.item] = node\n        node.parent = self\n\n\nclass _MPTree(object):\n    \"\"\"\n    A class used to represent the node of frequentPatternTree\n\n    ...\n\n    Attributes:\n    ----------\n        root : node\n            the root of a tree\n        summaries : dict\n            to store the items with same name into dictionary\n\n    Methods:\n    -------\n        checkerSub(itemSet)\n            to check of subset of itemSet is present in tree\n    \"\"\"\n\n    def __init__(self):\n        self.root = _Node(None, {})\n        self.summaries = {}\n\n    def _addTransaction(self, transaction):\n        \"\"\"\n        to add the transaction in maximal tree\n\n        :param transaction: resultant periodic frequent pattern\n\n        :return: maximal tree\n        \"\"\"\n        currentNode = self.root\n        transaction.sort()\n        for i in range(len(transaction)):\n            if transaction[i] not in currentNode.children:\n                newNode = _MNode(transaction[i], {})\n                currentNode._addChild(newNode)\n                if transaction[i] in self.summaries:\n                    self.summaries[transaction[i]].insert(0, newNode)\n                else:\n                    self.summaries[transaction[i]] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i]]\n\n    def _checkerSub(self, items):\n        \"\"\"\n        To check subset present of items in the maximal tree\n\n        :param items: the pattern to check for subsets\n\n        :return: 1\n        \"\"\"\n        items.sort(reverse=True)\n        item = items[0]\n        if item not in self.summaries:\n            return 1\n        else:\n            if len(items) == 1:\n                return 0\n        for t in self.summaries[item]:\n            cur = t.parent\n            i = 1\n            while cur.item is not None:\n                if items[i] == cur.item:\n                    i += 1\n                    if i == len(items):\n                        return 0\n                cur = cur.parent\n        return 1\n\n\n#_maximalTree = _MPTree()\n\n\ndef _getPeriodAndSupport(timeStamps):\n    \"\"\"\n    To calculate the periodicity and support of a pattern with their respective timeStamps\n\n    :param timeStamps: timeStamps\n\n    :return: Support and periodicity\n    \"\"\"\n    timeStamps.sort()\n    per = 0\n    for i in range(len(timeStamps) - 1):\n        j = i + 1\n        if abs(timeStamps[j] - timeStamps[i]) <= _period:\n            per += 1\n    return per\n\n\ndef _conditionalTransactions(condPatterns, condTimeStamps):\n    \"\"\"\n    To calculate the timestamps of conditional items in conditional patterns\n\n    :param condPatterns: conditional patterns of node\n\n    :param condTimeStamps: timeStamps of a conditional patterns\n\n    :return: removing items with low periodicSupport or periodicity and sort the conditional transactions\n    \"\"\"\n    pat = []\n    timeStamps = []\n    data1 = {}\n    for i in range(len(condPatterns)):\n        for j in condPatterns[i]:\n            if j in data1:\n                data1[j] = data1[j] + condTimeStamps[i]\n            else:\n                data1[j] = condTimeStamps[i]\n    updatedDict = {}\n    for m in data1:\n        updatedDict[m] = _getPeriodAndSupport(data1[m])\n    updatedDict = {k: v for k, v in updatedDict.items() if v >= _periodicSupport}\n    count = 0\n    for p in condPatterns:\n        p1 = [v for v in p if v in updatedDict]\n        trans = sorted(p1, key=lambda x: (updatedDict.get(x), -x), reverse=True)\n        if len(trans) > 0:\n            pat.append(trans)\n            timeStamps.append(condTimeStamps[count])\n        count += 1\n    return pat, timeStamps, updatedDict\n\n\nclass Max3PGrowth(_abstract._partialPeriodicPatterns):\n    \"\"\" Max3p-Growth algorithm IS to discover maximal periodic-frequent patterns in a temporal database.\n        It extract the partial periodic patterns from 3p-tree and checks for the maximal property and stores\n        all the maximal patterns in max3p-tree and extracts the maximal periodic patterns.\n\n        Reference:\n        --------\n        R. Uday Kiran, Yutaka Watanobe, Bhaskar Chaudhury, Koji Zettsu, Masashi Toyoda, Masaru Kitsuregawa,\n        \"Discovering Maximal Periodic-Frequent Patterns in Very Large Temporal Databases\",\n        IEEE 2020, https://ieeexplore.ieee.org/document/9260063\n\n        Attributes:\n        ----------\n            iFile : file\n                Name of the Input file or path of the input file\n            oFile : file\n                Name of the output file or path of the output file\n            periodicSupport: float or int or str\n                The user can specify periodicSupport either in count or proportion of database size.\n                If the program detects the data type of periodicSupport is integer, then it treats periodicSupport is expressed in count.\n                Otherwise, it will be treated as float.\n                Example: periodicSupport=10 will be treated as integer, while periodicSupport=10.0 will be treated as float\n            period: float or int or str\n                The user can specify period either in count or proportion of database size.\n                If the program detects the data type of period is integer, then it treats period is expressed in count.\n                Otherwise, it will be treated as float.\n                Example: period=10 will be treated as integer, while period=10.0 will be treated as float\n            sep : str\n                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \\t.\n                However, the users can override their default separator.\n            memoryUSS : float\n                To store the total amount of USS memory consumed by the program\n            memoryRSS : float\n                To store the total amount of RSS memory consumed by the program\n            startTime:float\n                To record the start time of the mining process\n            endTime:float\n                To record the completion time of the mining process\n            periodicSupport : int/float\n                The user given minimum support\n            period : int/float\n                The user given maximum period\n            Database : list\n                To store the transactions of a database in list\n            mapSupport : Dictionary\n                To maintain the information of item and their frequency\n            lno : int\n                it represents the total no of transaction\n            tree : class\n                it represents the Tree class\n            itemSetCount : int\n                it represents the total no of patterns\n            finalPatterns : dict\n                it represents to store the patterns\n\n        Methods:\n        -------\n            startMine()\n                Mining process will start from here\n            getFrequentPatterns()\n                Complete set of patterns will be retrieved with this function\n            savePatterns(oFile)\n                Complete set of periodic-frequent patterns will be loaded in to a output file\n            getPatternsAsDataFrame()\n                Complete set of periodic-frequent patterns will be loaded in to a dataframe\n            getMemoryUSS()\n                Total amount of USS memory consumed by the mining process will be retrieved from this function\n            getMemoryRSS()\n                Total amount of RSS memory consumed by the mining process will be retrieved from this function\n            getRuntime()\n                Total amount of runtime taken by the mining process will be retrieved from this function\n            creatingitemSets(fileName)\n                Scans the dataset or dataframes and stores in list format\n            PeriodicFrequentOneItem()\n                Extracts the one-periodic-frequent patterns from Databases\n            updateDatabases()\n                update the Databases by removing aperiodic items and sort the Database by item decreased support\n            buildTree()\n                after updating the Databases ar added into the tree by setting root node as null\n            startMine()\n                the main method to run the program\n\n        Executing the code on terminal:\n        -------\n            Format:\n            ------\n                python3 max3prowth.py <inputFile> <outputFile> <periodicSupport> <period>\n\n            Examples:\n            --------\n                python3 Max3PGrowth.py sampleTDB.txt patterns.txt 0.3 0.4  (periodicSupport will be considered in percentage of database\n                transactions)\n\n                python3 Max3PGrowth.py sampleTDB.txt patterns.txt 3 4  (periodicSupport will be considered in count)\n\n        Sample run of the importing code:\n        -----------\n            from PAMI.periodicFrequentPattern.maximal import ThreePGrowth as alg\n\n            obj = alg.ThreePGrowth(iFile, periodicSupport, period)\n\n            obj.startMine()\n\n            partialPeriodicPatterns = obj.partialPeriodicPatterns()\n\n            print(\"Total number of partial periodic Patterns:\", len(partialPeriodicPatterns))\n\n            obj.savePatterns(oFile)\n\n            Df = obj.getPatternInDf()\n\n            memUSS = obj.getMemoryUSS()\n\n            print(\"Total Memory in USS:\", memUSS)\n\n            memRSS = obj.getMemoryRSS()\n\n            print(\"Total Memory in RSS\", memRSS)\n\n            run = obj.getRuntime()\n\n            print(\"Total ExecutionTime in seconds:\", run)\n\n\n        Credits:\n        -------\n            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\\n\n\n        \"\"\"\n    _startTime = float()\n    _endTime = float()\n    _periodicSupport = str()\n    _period = float()\n    _finalPatterns = {}\n    _iFile = \" \"\n    _oFile = \" \"\n    _sep = \" \"\n    _memoryUSS = float()\n    _memoryRSS = float()\n    _Database = []\n    _rank = {}\n    _rankDup = {}\n    _lno = 0\n    _patterns = {}\n    _pfList = {}\n\n    def _creatingitemSets(self):\n        \"\"\" Storing the complete Databases of the database/input file in a database variable\n            :rtype: storing transactions into Database variable\n        \"\"\"\n\n        self._Database = []\n        if isinstance(self._iFile, _abstract._pd.DataFrame):\n            timeStamp, data = [], []\n            if self._iFile.empty:\n                print(\"its empty..\")\n            i = self._iFile.columns.values.tolist()\n            if 'TS' in i:\n                timeStamp = self._iFile['TS'].tolist()\n            if 'Transactions' in i:\n                data = self._iFile['Transactions'].tolist()\n            for i in range(len(data)):\n                tr = [timeStamp[i]]\n                tr = tr + data[i]\n                self._Database.append(tr)\n            self._lno = len(self._Database)\n            # print(self.Database)\n        if isinstance(self._iFile, str):\n            if _validators.url(self._iFile):\n                data = _urlopen(self._iFile)\n                for line in data:\n                    self._lno += 1\n                    line = line.decode(\"utf-8\")\n                    temp = [i.rstrip() for i in line.split(self._sep)]\n                    temp = [x for x in temp if x]\n                    self._Database.append(temp)\n            else:\n                try:\n                    with open(self._iFile, 'r', encoding='utf-8') as f:\n                        for line in f:\n                            self._lno += 1\n                            temp = [i.rstrip() for i in line.split(self._sep)]\n                            temp = [x for x in temp if x]\n                            self._Database.append(temp)\n                except IOError:\n                    print(\"File Not Found\")\n                    quit()\n\n    def _periodicFrequentOneItem(self):\n        \"\"\"\n            calculates the support of each item in the dataset and assign the ranks to the items\n            by decreasing support and returns the frequent items list\n            :rtype: return the one-length periodic frequent patterns\n\n\n            \"\"\"\n        self._pfList = {}\n        data = {}\n        for tr in self._Database:\n            for i in range(1, len(tr)):\n                if tr[i] not in data:\n                    data[tr[i]] = [0, int(tr[0]), 1]\n                else:\n                    lp = abs(int(tr[0]) - data[tr[i]][1])\n                    if lp <= _period:\n                        data[tr[i]][0] += 1\n                    data[tr[i]][1] = int(tr[0])\n                    data[tr[i]][2] += 1\n        data = {k: v[0] for k, v in data.items() if v[0] >= self._periodicSupport}\n        self._pfList = [k for k, v in sorted(data.items(), key=lambda x: x[1], reverse=True)]\n        self._rank = dict([(index, item) for (item, index) in enumerate(self._pfList)])\n        return data\n\n    def _updateDatabases(self, dict1):\n        \"\"\" Remove the items which are not frequent from Databases and updates the Databases with rank of items\n\n            :param dict1: frequent items with support\n            :type dict1: dictionary\n            :rtype: sorted and updated transactions\n            \"\"\"\n        list1 = []\n        for tr in self._Database:\n            list2 = [int(tr[0])]\n            for i in range(1, len(tr)):\n                if tr[i] in dict1:\n                    list2.append(self._rank[tr[i]])\n            if len(list2) >= 2:\n                basket = list2[1:]\n                basket.sort()\n                list2[1:] = basket[0:]\n                list1.append(list2)\n        return list1\n\n    @staticmethod\n    def _buildTree(data, info):\n        \"\"\" it takes the Databases and support of each item and construct the main tree with setting root node as null\n\n            :param data: it represents the one Databases in database\n            :type data: list\n            :param info: it represents the support of each item\n            :type info: dictionary\n            :rtype: returns root node of tree\n        \"\"\"\n\n        rootNode = _Tree()\n        rootNode.info = info.copy()\n        for i in range(len(data)):\n            set1 = [data[i][0]]\n            rootNode._addTransaction(data[i][1:], set1)\n        return rootNode\n\n    def _convert(self, value):\n        \"\"\"\n        To convert the given user specified value\n\n        :param value: user specified value\n        :return: converted value\n        \"\"\"\n        if type(value) is int:\n            value = int(value)\n        if type(value) is float:\n            value = (len(self._Database) * value)\n        if type(value) is str:\n            if '.' in value:\n                value = float(value)\n                value = (len(self._Database) * value)\n            else:\n                value = int(value)\n        return value\n\n    def _convertItems(self, itemSet):\n        \"\"\"\n\n        to convert the maximal pattern items with their original item names\n\n        :param itemSet: maximal periodic frequent pattern\n\n        :return: pattern with original item names\n        \"\"\"\n        t1 = []\n        for i in itemSet:\n            t1.append(self._pfList[i])\n        return t1\n\n    def startMine(self):\n        \"\"\" Mining process will start from this function\n        \"\"\"\n\n        global _periodicSupport, _period, _lno\n        self._startTime = _abstract._time.time()\n        if self._iFile is None:\n            raise Exception(\"Please enter the file path or file name:\")\n        if self._periodicSupport is None:\n            raise Exception(\"Please enter the Minimum Support\")\n        self._creatingitemSets()\n        self._periodicSupport = self._convert(self._periodicSupport)\n        self._period = self._convert(self._period)\n        _periodicSupport, _period, _lno = self._periodicSupport, self._period, len(self._Database)\n        if self._periodicSupport > len(self._Database):\n            raise Exception(\"Please enter the periodicSupport in range between 0 to 1\")\n        generatedItems = self._periodicFrequentOneItem()\n        updatedDatabases = self._updateDatabases(generatedItems)\n        for x, y in self._rank.items():\n            self._rankDup[y] = x\n        info = {self._rank[k]: v for k, v in generatedItems.items()}\n        Tree = self._buildTree(updatedDatabases, info)\n        self._patterns = {}\n        Tree._generatePatterns([], self._patterns)\n        self._finalPatterns = {}\n        for x, y in self._patterns.items():\n            st = str()\n            x = self._convertItems(x)\n            for k in x:\n                st = st + k + \" \"\n            self._finalPatterns[st] = y\n        self._endTime = _abstract._time.time()\n        process = _abstract._psutil.Process(_abstract._os.getpid())\n        self._memoryUSS = float()\n        self._memoryRSS = float()\n        self._memoryUSS = process.memory_full_info().uss\n        self._memoryRSS = process.memory_info().rss\n        print(\"Maximal Partial Periodic Frequent patterns were generated successfully using MAX-3PGrowth algorithm \")\n\n    def getMemoryUSS(self):\n        \"\"\"Total amount of USS memory consumed by the mining process will be retrieved from this function\n\n        :return: returning USS memory consumed by the mining process\n        :rtype: float\n        \"\"\"\n\n        return self._memoryUSS\n\n    def getMemoryRSS(self):\n        \"\"\"Total amount of RSS memory consumed by the mining process will be retrieved from this function\n\n        :return: returning RSS memory consumed by the mining process\n        :rtype: float\n        \"\"\"\n\n        return self._memoryRSS\n\n    def getRuntime(self):\n        \"\"\"Calculating the total amount of runtime taken by the mining process\n\n\n        :return: returning total amount of runtime taken by the mining process\n        :rtype: float\n        \"\"\"\n\n        return self._endTime - self._startTime\n\n    def getPatternsAsDataFrame(self):\n        \"\"\"Storing final periodic-frequent patterns in a dataframe\n\n        :return: returning periodic-frequent patterns in a dataframe\n        :rtype: pd.DataFrame\n        \"\"\"\n\n        dataFrame = {}\n        data = []\n        for a, b in self._finalPatterns.items():\n            data.append([a, b])\n            dataFrame = _abstract._pd.DataFrame(data, columns=['Patterns', 'periodicSupport'])\n        return dataFrame\n\n    def savePatterns(self, outFile):\n        \"\"\"Complete set of periodic-frequent patterns will be loaded in to a output file\n\n        :param outFile: name of the output file\n        :type outFile: file\n        \"\"\"\n        self._oFile = outFile\n        writer = open(self._oFile, 'w+')\n        for x, y in self._finalPatterns.items():\n            s1 = x + \":\" + str(y)\n            writer.write(\"%s \\n\" % s1)\n\n    def getPatterns(self):\n        \"\"\" Function to send the set of periodic-frequent patterns after completion of the mining process\n\n        :return: returning periodic-frequent patterns\n        :rtype: dict\n        \"\"\"\n        return self._finalPatterns\n\n\nif __name__ == \"__main__\":\n    _ap = str()\n    if len(_sys.argv) == 5 or len(_sys.argv) == 6:\n        if len(_sys.argv) == 6:\n            _ap = Max3PGrowth(_sys.argv[1], _sys.argv[3], _sys.argv[4], _sys.argv[5])\n        if len(_sys.argv) == 5:\n            _ap = Max3PGrowth(_sys.argv[1], _sys.argv[3], _sys.argv[4])\n        _ap.startMine()\n        _Patterns = _ap.getPatterns()\n        print(\"Total number of Maximal Partial Periodic Patterns:\", len(_Patterns))\n        _ap.savePatterns(_sys.argv[2])\n        _memUSS = _ap.getMemoryUSS()\n        print(\"Total Memory in USS:\", _memUSS)\n        _memRSS = _ap.getMemoryRSS()\n        print(\"Total Memory in RSS\", _memRSS)\n        _run = _ap.getRuntime()\n        print(\"Total ExecutionTime in ms:\", _run)\n    else:\n        l = [0.001, 0.002, 0.003, 0.004, 0.005]\n        for i in l:\n            ap = Max3PGrowth('/Users/Likhitha/Downloads/Datasets/BMS1_itemset_mining.txt', i, 100, ' ')\n            ap.startMine()\n            Patterns = ap.getPatterns()\n            print(\"Total number of  Patterns:\", len(Patterns))\n            ap.savePatterns('/Users/Likhitha/Downloads/output')\n            memUSS = ap.getMemoryUSS()\n            print(\"Total Memory in USS:\", memUSS)\n            memRSS = ap.getMemoryRSS()\n            print(\"Total Memory in RSS\", memRSS)\n            run = ap.getRuntime()\n            print(\"Total ExecutionTime in ms:\", run)\n        print(\"Error! The number of input parameters do not match the total number of parameters provided\")\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/partialPeriodicPattern/maximal/Max3PGrowth.py b/PAMI/partialPeriodicPattern/maximal/Max3PGrowth.py
--- a/PAMI/partialPeriodicPattern/maximal/Max3PGrowth.py	(revision 13e95f8a76f333a1a390dbc39efe0767be0b94b4)
+++ b/PAMI/partialPeriodicPattern/maximal/Max3PGrowth.py	(date 1656441065358)
@@ -773,17 +773,17 @@
         _run = _ap.getRuntime()
         print("Total ExecutionTime in ms:", _run)
     else:
-        l = [0.001, 0.002, 0.003, 0.004, 0.005]
-        for i in l:
-            ap = Max3PGrowth('/Users/Likhitha/Downloads/Datasets/BMS1_itemset_mining.txt', i, 100, ' ')
-            ap.startMine()
-            Patterns = ap.getPatterns()
-            print("Total number of  Patterns:", len(Patterns))
-            ap.savePatterns('/Users/Likhitha/Downloads/output')
-            memUSS = ap.getMemoryUSS()
-            print("Total Memory in USS:", memUSS)
-            memRSS = ap.getMemoryRSS()
-            print("Total Memory in RSS", memRSS)
-            run = ap.getRuntime()
-            print("Total ExecutionTime in ms:", run)
+        ap = Max3PGrowth('/Users/Likhitha/Downloads/PSGrowth/sample.txt', 0.2, 10000, ' ')
+        ap.startMine()
+        Patterns = ap.getPatterns()
+        print("Total number of  Patterns:", len(Patterns))
+        for x, y in Patterns.items():
+            print(x, y)
+        ap.savePatterns('/Users/Likhitha/Downloads/output')
+        memUSS = ap.getMemoryUSS()
+        print("Total Memory in USS:", memUSS)
+        memRSS = ap.getMemoryRSS()
+        print("Total Memory in RSS", memRSS)
+        run = ap.getRuntime()
+        print("Total ExecutionTime in ms:", run)
         print("Error! The number of input parameters do not match the total number of parameters provided")
Index: PAMI/frequentPattern/maximal/MaxFPGrowth.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#  Copyright (C)  2021 Rage Uday Kiran\n#\n#      This program is free software: you can redistribute it and/or modify\n#      it under the terms of the GNU General Public License as published by\n#      the Free Software Foundation, either version 3 of the License, or\n#      (at your option) any later version.\n#\n#      This program is distributed in the hope that it will be useful,\n#      but WITHOUT ANY WARRANTY; without even the implied warranty of\n#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#      GNU General Public License for more details.\n#\n#      You should have received a copy of the GNU General Public License\n#      along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\n\nfrom PAMI.frequentPattern.maximal import abstract as _ab\n\n\n_minSup = str()\nglobal maximalTree\n\n\nclass _Node(object):\n    \"\"\" A class used to represent the node of frequentPatternTree\n\n\n        Attributes:\n        ----------\n            item : int\n                storing item of a node\n            counter : list\n                To maintain the support of the node\n            parent : node\n                To maintain the parent of every node\n            children : list\n                To maintain the children of node\n\n        Methods:\n        -------\n            addChild(itemName)\n                storing the children to their respective parent nodes\n    \"\"\"\n\n    def __init__(self, item, children):\n        \"\"\" Initializing the Node class\n\n        :param item: Storing the item of a node\n\n        :type item: int or None\n\n        :param children: To maintain the children of a node\n\n        :type children: dict\n        \"\"\"\n        self.item = item\n        self.children = children\n        self.counter = int()\n        self.parent = None\n\n    def addChild(self, node):\n        \"\"\"Adding a child to the created node\n\n        :param node: node object\n\n        :type node: Node\n        \"\"\"\n        self.children[node.item] = node\n        node.parent = self\n\n\nclass _Tree(object):\n    \"\"\"\n        A class used to represent the frequentPatternGrowth tree structure\n\n\n        Attributes:\n        ----------\n            root : Node\n                Represents the root node of the tree\n            summaries : dictionary\n                storing the nodes with same item name\n            info : dictionary\n                stores the support of items\n\n\n        Methods:\n        -------\n            addTransaction(transaction)\n                creating transaction as a branch in frequentPatternTree\n            addConditionalTransaction(prefixPaths, supportOfItems)\n                construct the conditional tree for prefix paths\n            condPatterns(Node)\n                generates the conditional patterns from tree for specific node\n            conditionalTransaction(prefixPaths,Support)\n                takes the prefixPath of a node and support at child of the path and extract the frequent items from\n                prefixPaths and generates prefixPaths with items which are frequent\n            remove(Node)\n                removes the node from tree once after generating all the patterns respective to the node\n            generatePatterns(Node)\n                starts from the root node of the tree and mines the frequent patterns\n    \"\"\"\n\n    def __init__(self):\n        self.root = _Node(None, {})\n        self.summaries = {}\n        self.info = {}\n        #self.maximalTree = _MPTree()\n\n    def addTransaction(self, transaction):\n        \"\"\"\n        adding transactions into tree\n\n        :param transaction: represents the transaction in a database\n\n        :return: tree\n        \"\"\"\n        currentNode = self.root\n        for i in range(len(transaction)):\n            if transaction[i] not in currentNode.children:\n                newNode = _Node(transaction[i], {})\n                newNode.counter = 1\n                currentNode.addChild(newNode)\n                if transaction[i] in self.summaries:\n                    self.summaries[transaction[i]].append(newNode)\n                else:\n                    self.summaries[transaction[i]] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i]]\n                currentNode.counter += 1\n\n    def addConditionalTransaction(self, transaction, count):\n        \"\"\"\n            Loading the database into a tree\n\n        :param transaction: conditional transaction of a node\n\n        :param count: the support of conditional transaction\n\n        :return: conditional tree\n        \"\"\"\n        currentNode = self.root\n        for i in range(len(transaction)):\n            if transaction[i] not in currentNode.children:\n                newNode = _Node(transaction[i], {})\n                newNode.counter = count\n                currentNode.addChild(newNode)\n                if transaction[i] in self.summaries:\n                    self.summaries[transaction[i]].append(newNode)\n                else:\n                    self.summaries[transaction[i]] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i]]\n                currentNode.counter += count\n\n    def getConditionalPatterns(self, alpha):\n        \"\"\"\n        generates all the conditional patterns of respective node\n\n        :param alpha: it represents the Node in tree\n\n        :return: conditional patterns of a node\n        \"\"\"\n        finalPatterns = []\n        finalSets = []\n        for i in self.summaries[alpha]:\n            set1 = i.counter\n            set2 = []\n            while i.parent.item is not None:\n                set2.append(i.parent.item)\n                i = i.parent\n            if len(set2) > 0:\n                set2.reverse()\n                finalPatterns.append(set2)\n                finalSets.append(set1)\n        finalPatterns, finalSets, info = self.conditionalTransactions(finalPatterns, finalSets)\n        return finalPatterns, finalSets, info\n\n    def conditionalTransactions(self, condPatterns, condFreq):\n        \"\"\"\n        sorting and removing the items from conditional transactions which don't satisfy minSup\n\n        :param condPatterns: conditional patterns if a node\n\n        :param condFreq: frequency at leaf node of conditional transaction\n\n        :return: conditional patterns and their frequency respectively\n        \"\"\"\n        global _minSup\n        pat = []\n        tids = []\n        data1 = {}\n        for i in range(len(condPatterns)):\n            for j in condPatterns[i]:\n                if j not in data1:\n                    data1[j] = condFreq[i]\n                else:\n                    data1[j] += condFreq[i]\n        updatedDict = {}\n        updatedDict = {k: v for k, v in data1.items() if v >= _minSup}\n        count = 0\n        for p in condPatterns:\n            p1 = [v for v in p if v in updatedDict]\n            trans = sorted(p1, key=lambda x: (updatedDict.get(x), -x), reverse=True)\n            if len(trans) > 0:\n                pat.append(trans)\n                tids.append(condFreq[count])\n            count += 1\n        return pat, tids, updatedDict\n\n    def removeNode(self, nodeValue):\n        \"\"\"\n        to remove the node from the original tree\n\n        :param nodeValue: leaf node of tree\n\n        :return: tree after deleting node\n        \"\"\"\n        for i in self.summaries[nodeValue]:\n            del i.parent.children[nodeValue]\n            i = None\n\n    def generatePatterns(self, prefix, patterns):\n        \"\"\"\n        generates the patterns\n\n        :param prefix: forms the combination of items\n\n        :return: the maximal frequent patterns\n        \"\"\"\n        global maximalTree\n        for i in sorted(self.summaries, key=lambda x: (self.info.get(x), -x)):\n            pattern = prefix[:]\n            pattern.append(i)\n            condPatterns, tids, info = self.getConditionalPatterns(i)\n            conditional_tree = _Tree()\n            conditional_tree.info = info.copy()\n            head = pattern[:]\n            tail = []\n            for la in info:\n                tail.append(la)\n            sub = head + tail\n            if maximalTree.checkerSub(sub) == 1:\n                for pat in range(len(condPatterns)):\n                    conditional_tree.addConditionalTransaction(condPatterns[pat], tids[pat])\n                if len(condPatterns) >= 1:\n                    conditional_tree.generatePatterns(pattern, patterns)\n                else:\n                    maximalTree.addTransaction(pattern)\n                    patterns[tuple(pattern)] = self.info[i]\n            self.removeNode(i)\n\n\nclass _MNode(object):\n    \"\"\"\n        A class used to represent the node in maximal tree\n\n        Attributes:\n        ----------\n            item : int\n                storing item of a node\n            children : list\n                To maintain the children of node\n\n        Methods:\n        -------\n            addChild(itemName)\n                storing the children to their respective parent nodes\n    \"\"\"\n\n    def __init__(self, item, children):\n        self.item = item\n        self.children = children\n\n    def addChild(self, node):\n        \"\"\"\n        To add the children details to a parent node\n\n        :param node: children node\n\n        :return: adding children details to parent node\n        \"\"\"\n        self.children[node.item] = node\n        node.parent = self\n\n\nclass _MPTree(object):\n    \"\"\"\n        A class used to represent the frequentPatternGrowth tree structure\n\n        Attributes:\n        ----------\n            root : Node\n                Represents the root node of the tree\n            summaries : dictionary\n                storing the nodes with same item name\n\n\n            Methods\n            -------\n            addTransaction(transaction)\n                creating transaction as a branch in frequentPatternTree\n            addConditionalTransaction(prefixPaths, supportOfItems)\n                construct the conditional tree for prefix paths\n            checkerSub(items):\n                Given a set of items to the subset of them is present or not\n    \"\"\"\n\n    def __init__(self):\n        self.root = _MNode(None, {})\n        self.summaries = {}\n\n    def addTransaction(self, transaction):\n        \"\"\"\n        To construct the maximal frequent pattern into maximal tree\n\n        :param transaction: the maximal frequent patterns extracted till now\n\n        :return: the maximal tree\n        \"\"\"\n        currentNode = self.root\n        transaction.sort()\n        for i in range(len(transaction)):\n            if transaction[i] not in currentNode.children:\n                newNode = _MNode(transaction[i], {})\n                currentNode.addChild(newNode)\n                if transaction[i] in self.summaries:\n                    self.summaries[transaction[i]].insert(0, newNode)\n                else:\n                    self.summaries[transaction[i]] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i]]\n\n    def checkerSub(self, items):\n        \"\"\"\n        To check the subset of pattern present in tree\n\n        :param items: the sub frequent pattern\n\n        :return: checks if subset present in the tree\n        \"\"\"\n        items.sort(reverse=True)\n        item = items[0]\n        if item not in self.summaries:\n            return 1\n        else:\n            if len(items) == 1:\n                return 0\n        for t in self.summaries[item]:\n            cur = t.parent\n            i = 1\n            while cur.item is not None:\n                if items[i] == cur.item:\n                    i += 1\n                    if i == len(items):\n                        return 0\n                cur = cur.parent\n        return 1\n\n\n# Initialising the  variable for maximal tree\nmaximalTree = MPTree()\n\n\nclass MaxFPGrowth(_ab._frequentPatterns):\n    \"\"\"\n    MaxFP-Growth is one of the fundamental algorithm to discover maximal frequent patterns in a transactional database.\n\n    Reference:\n    ---------\n        Grahne, G. and Zhu, J., \"High Performance Mining of Maximal Frequent itemSets\",\n        http://users.encs.concordia.ca/~grahne/papers/hpdm03.pdf\n\n    Attributes:\n    ----------\n        iFile : file\n            Name of the Input file to mine complete set of frequent patterns\n        oFile : file\n            Name of the output file to store complete set of frequent patterns\n        minSup: float or int or str\n            The user can specify minSup either in count or proportion of database size.\n            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.\n            Otherwise, it will be treated as float.\n            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float\n        sep : str\n            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \\t.\n            However, the users can override their default separator.\n        memoryUSS : float\n            To store the total amount of USS memory consumed by the program\n        memoryRSS : float\n            To store the total amount of RSS memory consumed by the program\n        startTime:float\n            To record the start time of the mining process\n        endTime:float\n            To record the completion time of the mining process\n        Database : list\n            To store the transactions of a database in list\n        mapSupport : Dictionary\n            To maintain the information of item and their frequency\n        lno : int\n            it represents the total no of transaction\n        tree : class\n            it represents the Tree class\n        finalPatterns : dict\n            it represents to store the patterns\n\n    Methods:\n    -------\n        startMine()\n            Mining process will start from here\n        getPatterns()\n            Complete set of patterns will be retrieved with this function\n        savePatterns(oFile)\n            Complete set of frequent patterns will be loaded in to a output file\n        getPatternsAsDataFrame()\n            Complete set of frequent patterns will be loaded in to a dataframe\n        getMemoryUSS()\n            Total amount of USS memory consumed by the mining process will be retrieved from this function\n        getMemoryRSS()\n            Total amount of RSS memory consumed by the mining process will be retrieved from this function\n        getRuntime()\n            Total amount of runtime taken by the mining process will be retrieved from this function\n        creatingItemSets()\n            Scans the dataset or dataframes and stores in list format\n        frequentOneItem()\n            Extracts the one-frequent patterns from Databases\n        updateTransactions()\n            update the Databases by removing aperiodic items and sort the Database by item decreased support\n        buildTree()\n            after updating the Databases ar added into the tree by setting root node as null\n        startMine()\n            the main method to run the program\n\n    Executing the code on terminal:\n    -------\n        Format:\n        ------\n            python3 MaxFPGrowth.py <inputFile> <outputFile> <minSup>\n\n        Examples:\n        -------\n            python3 MaxFPGrowth.py sampleDB.txt patterns.txt 0.3   (minSup will be considered in percentage of database transactions)\n\n            python3 MaxFPGrowth.py sampleDB.txt patterns.txt 3     (minSup will be considered in support count or frequency)\n\n    Sample run of the imported code:\n    --------------\n        from PAMI.frequentPattern.maximal import MaxFPGrowth as alg\n\n        obj = alg.MaxFPGrowth(\"../basic/sampleTDB.txt\", \"2\")\n\n        obj.startMine()\n\n        frequentPatterns = obj.getPatterns()\n\n        print(\"Total number of Frequent Patterns:\", len(frequentPatterns))\n\n        obj.savePatterns(\"patterns\")\n\n        Df = obj.getPatternsAsDataFrame()\n\n        memUSS = obj.getMemoryUSS()\n\n        print(\"Total Memory in USS:\", memUSS)\n\n        memRSS = obj.getMemoryRSS()\n\n        print(\"Total Memory in RSS\", memRSS)\n\n        run = obj.getRuntime()\n\n        print(\"Total ExecutionTime in seconds:\", run)\n\n    Credits:\n    -------\n        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\\n\n\n    \"\"\"\n    _startTime = float()\n    _endTime = float()\n    _minSup = str()\n    _maxPer = float()\n    _finalPatterns = {}\n    _iFile = \" \"\n    _oFile = \" \"\n    _sep = \" \"\n    _memoryUSS = float()\n    _memoryRSS = float()\n    _Database = []\n    _rank = {}\n    _rankdup = {}\n    _lno = 0\n\n    def _creatingItemSets(self):\n        \"\"\"\n            Storing the complete transactions of the database/input file in a database variable\n\n\n        \"\"\"\n        self._Database = []\n        if isinstance(self._iFile, _ab._pd.DataFrame):\n            if self._iFile.empty:\n                print(\"its empty..\")\n            i = self._iFile.columns.values.tolist()\n            if 'Transactions' in i:\n                self._Database = self._iFile['Transactions'].tolist()\n        if isinstance(self._iFile, str):\n            if _ab._validators.url(self._iFile):\n                data = _ab._urlopen(self._iFile)\n                for line in data:\n                    line.strip()\n                    line = line.decode(\"utf-8\")\n                    temp = [i.rstrip() for i in line.split(self._sep)]\n                    temp = [x for x in temp if x]\n                    self._Database.append(temp)\n            else:\n                try:\n                    with open(self._iFile, 'r', encoding='utf-8') as f:\n                        for line in f:\n                            line.strip()\n                            temp = [i.rstrip() for i in line.split(self._sep)]\n                            temp = [x for x in temp if x]\n                            #print(line)\n                            self._Database.append(temp)\n                except IOError:\n                    print(\"File Not Found\")\n                    quit()\n\n    def _frequentOneItem(self):\n        \"\"\" To extract the one-length frequent itemSets\n\n        :return: 1-length frequent items\n        \"\"\"\n        _mapSupport = {}\n        k = 0\n        for tr in self._Database:\n            k += 1\n            for i in range(0, len(tr)):\n                if tr[i] not in _mapSupport:\n                    _mapSupport[tr[i]] = 1\n                else:\n                    _mapSupport[tr[i]] += 1\n        _mapSupport = {k: v for k, v in _mapSupport.items() if v >= self._minSup}\n        #print(len(mapSupport), self.minSup)\n        genList = [k for k, v in sorted(_mapSupport.items(), key=lambda x: x[1], reverse=True)]\n        self._rank = dict([(index, item) for (item, index) in enumerate(genList)])\n        return _mapSupport, genList\n\n    def _updateTransactions(self, oneLength):\n        \"\"\" To sort the transactions in their support descending order and allocating ranks respectively\n\n        :param oneLength: 1-length frequent items in dictionary\n\n        :return: returning the sorted list\n\n        :Example: oneLength = {'a':7, 'b': 5, 'c':'4', 'd':3}\n                    rank = {'a':0, 'b':1, 'c':2, 'd':3}\n        \"\"\"\n        list1 = []\n        for tr in self._Database:\n            list2 = []\n            for i in range(0, len(tr)):\n                if tr[i] in oneLength:\n                    list2.append(self._rank[tr[i]])\n            if len(list2) >= 2:\n                list2.sort()\n                list1.append(list2)\n        return list1\n\n    @staticmethod\n    def _buildTree(data, info):\n        \"\"\"\n        creating the root node as null in fp-tree and and adding all transactions into tree.\n        :param data: updated transactions\n        :param info: rank of items in transactions\n        :return: fp-tree\n        \"\"\"\n        rootNode = _Tree()\n        rootNode.info = info.copy()\n        for i in range(len(data)):\n            rootNode.addTransaction(data[i])\n        return rootNode\n\n\n    def _convert(self, value):\n        \"\"\"\n        to convert the type of user specified minSup value\n        :param value: user specified minSup value\n        :return: converted type\n        \"\"\"\n        if type(value) is int:\n            value = int(value)\n        if type(value) is float:\n            value = (len(self._Database) * value)\n        if type(value) is str:\n            if '.' in value:\n                value = float(value)\n                value = ((len(self._Database)) * value)\n            else:\n                value = int(value)\n        return value\n\n    def _convertItems(self, itemSet):\n        \"\"\"\n            To convert the item ranks into their original item names\n\n            :param itemSet: itemSet or a pattern\n\n            :return: original pattern\n        \"\"\"\n        t1 = []\n        for i in itemSet:\n            t1.append(self._rankdup[i])\n        return t1\n\n    def startMine(self):\n        \"\"\"\n                Mining process will start from this function\n        \"\"\"\n\n        global _minSup\n        self._startTime = _ab._time.time()\n        if self._iFile is None:\n            raise Exception(\"Please enter the file path or file name:\")\n        if self._minSup is None:\n            raise Exception(\"Please enter the Minimum Support\")\n        self._creatingItemSets()\n        self._minSup = self._convert(self._minSup)\n        _minSup = self._minSup\n        generatedItems, pfList = self._frequentOneItem()\n        updatedTransactions = self._updateTransactions(generatedItems)\n        for x, y in self._rank.items():\n            self._rankdup[y] = x\n        info = {self._rank[k]: v for k, v in generatedItems.items()}\n        patterns = {}\n        self._finalPatterns = {}\n        Tree = self._buildTree(updatedTransactions, info)\n        Tree.generatePatterns([], patterns)\n        for x, y in patterns.items():\n            pattern = str()\n            x = self._convertItems(x)\n            for i in x:\n                pattern = pattern + i + \" \"\n            self._finalPatterns[pattern] = y\n        self._endTime = _ab._time.time()\n        process = _ab._psutil.Process(_ab._os.getpid())\n        self._memoryUSS = float()\n        self._memoryRSS = float()\n        self._memoryUSS = process.memory_full_info().uss\n        self._memoryRSS = process.memory_info().rss\n        print(\"Maximal Frequent patterns were generated successfully using MaxFp-Growth algorithm \")\n\n    def getMemoryUSS(self):\n        \"\"\"Total amount of USS memory consumed by the mining process will be retrieved from this function\n\n        :return: returning USS memory consumed by the mining process\n\n        :rtype: float\n        \"\"\"\n\n        return self._memoryUSS\n\n    def getMemoryRSS(self):\n        \"\"\"Total amount of RSS memory consumed by the mining process will be retrieved from this function\n\n        :return: returning RSS memory consumed by the mining process\n\n        :rtype: float\n        \"\"\"\n\n        return self._memoryRSS\n\n    def getRuntime(self):\n        \"\"\"Calculating the total amount of runtime taken by the mining process\n\n        :return: returning total amount of runtime taken by the mining process\n\n        :rtype: float\n        \"\"\"\n\n        return self._endTime - self._startTime\n\n    def getPatternsAsDataFrame(self):\n        \"\"\"Storing final frequent patterns in a dataframe\n\n        :return: returning frequent patterns in a dataframe\n\n        :rtype: pd.DataFrame\n        \"\"\"\n\n        dataFrame = {}\n        data = []\n        for a, b in self._finalPatterns.items():\n            data.append([a, b])\n            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])\n        return dataFrame\n\n    def savePatterns(self, outFile):\n        \"\"\"Complete set of frequent patterns will be loaded in to a output file\n\n        :param outFile: name of the output file\n\n        :type outFile: file\n        \"\"\"\n        self._oFile = outFile\n        writer = open(self._oFile, 'w+')\n        for x, y in self._finalPatterns.items():\n            s1 = x + \":\" + str(y)\n            writer.write(\"%s \\n\" % s1)\n\n    def getPatterns(self):\n        \"\"\" Function to send the set of frequent patterns after completion of the mining process\n\n        :return: returning frequent patterns\n\n        :rtype: dict\n        \"\"\"\n        return self._finalPatterns\n\n\nif __name__ == \"__main__\":\n    _ap = str()\n    if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:\n        if len(_ab._sys.argv) == 5:\n            _ap = MaxFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])\n        if len(_ab._sys.argv) == 4:\n            _ap = MaxFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3])\n        _ap.startMine()\n        _Patterns = _ap.getPatterns()\n        print(\"Total number of Maximal Frequent Patterns:\", len(_Patterns))\n        _ap.savePatterns(_ab._sys.argv[2])\n        _memUSS = _ap.getMemoryUSS()\n        print(\"Total Memory in USS:\", _memUSS)\n        _memRSS = _ap.getMemoryRSS()\n        print(\"Total Memory in RSS\", _memRSS)\n        _run = _ap.getRuntime()\n        print(\"Total ExecutionTime in ms:\", _run)\n    else:\n        '''l = [0.001, 0.002, 0.003, 0.004, 0.005]\n        for i in l:\n            ap = MaxFPGrowth('https://www.u-aizu.ac.jp/~udayrage/datasets/temporalDatabases/temporal_T10I4D100K.csv',\n                       i)\n            ap.startMine()\n            Patterns = ap.getPatterns()\n            print(\"Total number of Closed Frequent Patterns:\", len(Patterns))\n            ap.savePatterns('/Users/Likhitha/Downloads/output')\n            memUSS = ap.getMemoryUSS()\n            print(\"Total Memory in USS:\", memUSS)\n            memRSS = ap.getMemoryRSS()\n            print(\"Total Memory in RSS\", memRSS)\n            run = ap.getRuntime()\n            print(\"Total ExecutionTime in ms:\", run)'''\n        print(\"Error! The number of input parameters do not match the total number of parameters provided\")\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/frequentPattern/maximal/MaxFPGrowth.py b/PAMI/frequentPattern/maximal/MaxFPGrowth.py
--- a/PAMI/frequentPattern/maximal/MaxFPGrowth.py	(revision 13e95f8a76f333a1a390dbc39efe0767be0b94b4)
+++ b/PAMI/frequentPattern/maximal/MaxFPGrowth.py	(date 1656441228426)
@@ -362,7 +362,7 @@
 
 
 # Initialising the  variable for maximal tree
-maximalTree = MPTree()
+maximalTree = _MPTree()
 
 
 class MaxFPGrowth(_ab._frequentPatterns):
@@ -739,12 +739,13 @@
         _run = _ap.getRuntime()
         print("Total ExecutionTime in ms:", _run)
     else:
-        '''l = [0.001, 0.002, 0.003, 0.004, 0.005]
+        l = [0.2]
         for i in l:
-            ap = MaxFPGrowth('https://www.u-aizu.ac.jp/~udayrage/datasets/temporalDatabases/temporal_T10I4D100K.csv',
-                       i)
+            ap = MaxFPGrowth('/Users/Likhitha/Downloads/gurgaonNote0.6.txt',i, ' ')
             ap.startMine()
             Patterns = ap.getPatterns()
+            for x,y in Patterns.items():
+                print(x, y)
             print("Total number of Closed Frequent Patterns:", len(Patterns))
             ap.savePatterns('/Users/Likhitha/Downloads/output')
             memUSS = ap.getMemoryUSS()
@@ -752,5 +753,5 @@
             memRSS = ap.getMemoryRSS()
             print("Total Memory in RSS", memRSS)
             run = ap.getRuntime()
-            print("Total ExecutionTime in ms:", run)'''
+            print("Total ExecutionTime in ms:", run)
         print("Error! The number of input parameters do not match the total number of parameters provided")
Index: PAMI/geoReferencedUncertainFrequentPattern/abstract.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/geoReferencedUncertainFrequentPattern/abstract.py b/PAMI/geoReferencedUncertainFrequentPattern/abstract.py
new file mode 100644
--- /dev/null	(date 1656441096545)
+++ b/PAMI/geoReferencedUncertainFrequentPattern/abstract.py	(date 1656441096545)
@@ -0,0 +1,137 @@
+
+from abc import ABC as _ABC, abstractmethod as _abstractmethod
+import time as _time
+import csv as _csv
+import pandas as _pd
+from collections import defaultdict as _defaultdict
+from itertools import combinations as _c
+import os as _os
+import os.path as _ospath
+import psutil as _psutil
+import sys as _sys
+import validators as _validators
+from urllib.request import urlopen as _urlopen
+
+
+class _spatialFrequentPatterns(_ABC):
+    """ This abstract base class defines the variables and methods that every frequent pattern mining algorithm must
+    employ in PAMI
+
+    ...
+
+    Attributes:
+    ----------
+        iFile : str
+            Input file name or path of the input file
+        minSup: float or int or str
+            The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+            However, the users can override their default separator.
+        startTime:float
+            To record the start time of the algorithm
+        endTime:float
+            To record the completion time of the algorithm
+        finalPatterns: dict
+            Storing the complete set of patterns in a dictionary variable
+        oFile : str
+            Name of the output file to store complete set of frequent patterns
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+
+    Methods:
+    -------
+        startMine()
+            Mining process will start from here
+        getPatterns()
+            Complete set of patterns will be retrieved with this function
+        savePatterns(oFile)
+            Complete set of frequent patterns will be loaded in to a output file
+        getPatternsAsDataFrame()
+            Complete set of frequent patterns will be loaded in to data frame
+        getMemoryUSS()
+            Total amount of USS memory consumed by the program will be retrieved from this function
+        getMemoryRSS()
+            Total amount of RSS memory consumed by the program will be retrieved from this function
+        getRuntime()
+            Total amount of runtime taken by the program will be retrieved from this function
+    """
+
+    def __init__(self, iFile, nFile, minSup, sep = '\t'):
+        """
+        :param iFile: Input file name or path of the input file
+        :type iFile: str
+        :param nFile: Input file name or path of the neighbour file
+        :type nFile: str
+        :param minSup: The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        :type minSup: int or float or str
+        :param sep: separator used to distinguish items from each other. The default separator is tab space. However, users can override the default separator
+        :type sep: str
+        """
+
+        self._iFile = iFile
+        self._nFile = nFile
+        self._minSup = minSup
+        self._sep = sep
+        self._oFile = " "
+        self._finalPatterns = {}
+        self._startTime = float()
+        self._endTime = float()
+        self._memoryUSS = float()
+        self._memoryRSS = float()
+
+    @_abstractmethod
+    def startMine(self):
+        """Code for the mining process will start from this function"""
+
+        pass
+
+    @_abstractmethod
+    def getPatterns(self):
+        """Complete set of patterns generated will be retrieved from this function"""
+
+        pass
+
+    @_abstractmethod
+    def savePatterns(self, oFile):
+        """Complete set of frequent patterns will be saved in to an output file from this function
+
+        :param oFile: Name of the output file
+        :type oFile: file
+        """
+
+        pass
+
+    @_abstractmethod
+    def getPatternsAsDataFrame(self):
+        """Complete set of frequent patterns will be loaded in to data frame from this function"""
+
+        pass
+
+    @_abstractmethod
+    def getMemoryUSS(self):
+        """Total amount of USS memory consumed by the program will be retrieved from this function"""
+
+        pass
+
+    @_abstractmethod
+    def getMemoryRSS(self):
+        """Total amount of RSS memory consumed by the program will be retrieved from this function"""
+        pass
+
+    @_abstractmethod
+    def getRuntime(self):
+        """Total amount of runtime taken by the program will be retrieved from this function"""
+
+        pass
+
+
+
Index: PAMI/faultTolerantFrequentPattern/FTApriori.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import sys\nimport time\nimport resource\nimport math\nimport itertools\npath=sys.argv[1]\noutput = sys.argv[2]\nminSup = int(sys.argv[3])\nitemSup = int(sys.argv[4])\nminLength = int(sys.argv[5])\nfaultTolerance = int(sys.argv[6])\nmapSupport = {}\nfinalPatterns = {}\nDatabase = []\n\ndef Count(k):\n    count = 0\n    items = []\n    k = list(k)\n    n = len(k)-faultTolerance\n    c = itertools.combinations(k, n)\n    count = 0\n    for j in c: \n        j = list(j)\n        for i in Database:\n            if set(j).issubset(i):\n                count += 1\n                items.append(i)\n    items =  list(set(map(tuple,items)))\n    print(k, items, count)\n    return len(items), items\n            \n    \ndef countItemSupport(itemset, transactions):\n    tids = {}\n    res = True\n    for i in itemset:\n        for k in transactions:\n            if i in k:\n                if i not in tids:\n                    tids[i] = 1\n                else:\n                    tids[i] += 1\n    #print(itemset, transactions, tids)\n    for x, y in tids.items():\n        if y < itemSup:\n            res = False\n    return res\n\ndef getFaultPatterns():\n    \n    l = [k for k,v in mapSupport.items()]\n    for i in range(2, len(l)+1):\n        c = itertools.combinations(l,i)\n        for j in c:\n            support, items = Count(j)\n            res = countItemSupport(j, items)\n            if len(j)> minLength and len(j)>=faultTolerance and support >= minSup and res == True:\n                finalPatterns[tuple(j)] = support\n                    \n\nwith open(path, 'r') as f:\n    for line in f:\n        li = line.split()\n        Database.append(li)\n        for i in li:\n            if i not in mapSupport:\n                mapSupport[i] = 1\n            else:\n                mapSupport[i] +=1\nl = [k for k, v in mapSupport.items()]\nfor i in range(len(l)):\n    for j in range(i+1, len(l)):\n        x, y = l[i], l[j]\n        li = [x, y]\n        count = 0\n        tids = {x:0, y:0}\n        for k in Database:\n            if x in k and y in k:\n                count += 1\n                tids[x] += 1\n                tids[y] += 1\n            if x in k and y not in k:\n                count += 1\n                tids[x] = 1\n            if x not in k and y in k:\n                count += 1\n                tids[y] += 1\n        re = True\n        for x, y in tids.items():\n            if y< itemSup:\n                re = False\n        finalPatterns[tuple(li)] = count\n\ngetFaultPatterns() \n\nprint(\"...\")\nwith open(output, 'w+') as f:\n    for x,y in finalPatterns.items():\n        s = str(x) + \":\" + str(y)\n        f.write(\"%s \\n\" % s)\nfor x,y in finalPatterns.items():\n    print(x,y)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/faultTolerantFrequentPattern/FTApriori.py b/PAMI/faultTolerantFrequentPattern/FTApriori.py
--- a/PAMI/faultTolerantFrequentPattern/FTApriori.py	(revision 13e95f8a76f333a1a390dbc39efe0767be0b94b4)
+++ b/PAMI/faultTolerantFrequentPattern/FTApriori.py	(date 1656441096500)
@@ -1,8 +1,5 @@
-import sys
-import time
-import resource
-import math
-import itertools
+from PAMI.faultTolerantFrequentPattern import abstract as _ab
+
 path=sys.argv[1]
 output = sys.argv[2]
 minSup = int(sys.argv[3])
Index: PAMI/geoReferencedUncertainFrequentPattern/GUFPGrowth.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/geoReferencedUncertainFrequentPattern/GUFPGrowth.py b/PAMI/geoReferencedUncertainFrequentPattern/GUFPGrowth.py
new file mode 100644
--- /dev/null	(date 1656441096563)
+++ b/PAMI/geoReferencedUncertainFrequentPattern/GUFPGrowth.py	(date 1656441096563)
@@ -0,0 +1,701 @@
+#  Copyright (C)  2021 Rage Uday Kiran
+#
+#      This program is free software: you can redistribute it and/or modify
+#      it under the terms of the GNU General Public License as published by
+#      the Free Software Foundation, either version 3 of the License, or
+#      (at your option) any later version.
+#
+#      This program is distributed in the hope that it will be useful,
+#      but WITHOUT ANY WARRANTY; without even the implied warranty of
+#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+#      GNU General Public License for more details.
+#
+#      You should have received a copy of the GNU General Public License
+#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+
+from PAMI.geoReferencedUncertainFrequentPattern import abstract as _ab
+
+_minSup = str()
+_neighbourList = {}
+_ab._sys.setrecursionlimit(20000)
+_finalPatterns = {}
+
+
+class _Item:
+    """
+    A class used to represent the item with probability in transaction of dataset
+    ...
+    Attributes:
+    __________
+        item : int or word
+            Represents the name of the item
+        probability : float
+            Represent the existential probability(likelihood presence) of an item
+    """
+
+    def __init__(self, item, probability):
+        self.item = item
+        self.probability = probability
+
+
+class _Node(object):
+    """
+    A class used to represent the node of frequentPatternTree
+        ...
+    Attributes:
+    ----------
+        item : int
+            storing item of a node
+        probability : int
+            To maintain the expected support of node
+        parent : node
+            To maintain the parent of every node
+        children : list
+            To maintain the children of node
+    Methods:
+    -------
+        addChild(itemName)
+            storing the children to their respective parent nodes
+    """
+
+    def __init__(self, item, children):
+        self.item = item
+        self.probability = 1
+        self.children = children
+        self.parent = None
+
+    def addChild(self, node):
+        self.children[node.item] = node
+        node.parent = self
+
+
+class _Tree(object):
+    """
+    A class used to represent the frequentPatternGrowth tree structure
+    ...
+    Attributes:
+    ----------
+        root : Node
+            Represents the root node of the tree
+        summaries : dictionary
+            storing the nodes with same item name
+        info : dictionary
+            stores the support of items
+    Methods:
+    -------
+        addTransaction(transaction)
+            creating transaction as a branch in frequentPatternTree
+        addConditionalPattern(prefixPaths, supportOfItems)
+            construct the conditional tree for prefix paths
+        conditionalPatterns(Node)
+            generates the conditional patterns from tree for specific node
+        conditionalTransactions(prefixPaths,Support)
+            takes the prefixPath of a node and support at child of the path and extract the frequent items from
+            prefixPaths and generates prefixPaths with items which are frequent
+        remove(Node)
+            removes the node from tree once after generating all the patterns respective to the node
+        generatePatterns(Node)
+            starts from the root node of the tree and mines the frequent patterns
+    """
+
+    def __init__(self):
+        self.root = _Node(None, {})
+        self.summaries = {}
+        self.info = {}
+
+    def addTransaction(self, transaction):
+        """adding transaction into tree
+            :param transaction : it represents the one self.Database in database
+            :type transaction : list
+        """
+
+        currentNode = self.root
+        for i in range(len(transaction)):
+            if transaction[i].item not in currentNode.children:
+                newNode = _Node(transaction[i].item, {})
+                l1 = i - 1
+                lp = []
+                while l1 >= 0:
+                    lp.append(transaction[l1].probability)
+                    l1 -= 1
+                if len(lp) == 0:
+                    newNode.probability = transaction[i].probability
+                else:
+                    newNode.probability = max(lp) * transaction[i].probability
+                currentNode.addChild(newNode)
+                if transaction[i].item in self.summaries:
+                    self.summaries[transaction[i].item].append(newNode)
+                else:
+                    self.summaries[transaction[i].item] = [newNode]
+                currentNode = newNode
+            else:
+                currentNode = currentNode.children[transaction[i].item]
+                l1 = i - 1
+                lp = []
+                while l1 >= 0:
+                    lp.append(transaction[l1].probability)
+                    l1 -= 1
+                if len(lp) == 0:
+                    currentNode.probability += transaction[i].probability
+                else:
+                    currentNode.probability += max(lp) * transaction[i].probability
+
+    def addConditionalPattern(self, transaction, sup):
+        """constructing conditional tree from prefixPaths
+            :param transaction : it represents the one self.Database in database
+            :type transaction : list
+            :param sup : support of prefixPath taken at last child of the path
+            :type sup : int
+        """
+
+        # This method takes transaction, support and constructs the conditional tree
+        currentNode = self.root
+        for i in range(len(transaction)):
+            if transaction[i] not in currentNode.children:
+                newNode = _Node(transaction[i], {})
+                newNode.probability = sup
+                currentNode.addChild(newNode)
+                if transaction[i] in self.summaries:
+                    self.summaries[transaction[i]].append(newNode)
+                else:
+                    self.summaries[transaction[i]] = [newNode]
+                currentNode = newNode
+            else:
+                currentNode = currentNode.children[transaction[i]]
+                currentNode.probability += sup
+
+    def conditionalPatterns(self, alpha):
+        """generates all the conditional patterns of respective node
+            :param alpha : it represents the Node in tree
+            :type alpha : _Node
+        """
+
+        # This method generates conditional patterns of node by traversing the tree
+        global _neighbourList
+        finalPatterns = []
+        sup = []
+        for i in self.summaries[alpha]:
+            j = i.item
+            s = i.probability
+            set2 = []
+            while i.parent.item is not None:
+                if i.parent.item in _neighbourList[j]:
+                    set2.append(i.parent.item)
+                i = i.parent
+            if len(set2) > 0:
+                set2.reverse()
+                finalPatterns.append(set2)
+                sup.append(s)
+        finalPatterns, support, info = self.conditionalTransactions(finalPatterns, sup)
+        return finalPatterns, support, info
+
+    def removeNode(self, nodeValue):
+        """removing the node from tree
+            :param nodeValue : it represents the node in tree
+            :type nodeValue : node
+        """
+
+        for i in self.summaries[nodeValue]:
+            del i.parent.children[nodeValue]
+
+    def conditionalTransactions(self, condPatterns, support):
+        """ It generates the conditional patterns with frequent items
+                :param condPatterns : conditionalPatterns generated from conditionalPattern method for respective node
+                :type condPatterns : list
+                :support : the support of conditional pattern in tree
+                :support : int
+        """
+
+        global minSup
+        pat = []
+        sup = []
+        count = {}
+        for i in range(len(condPatterns)):
+            for j in condPatterns[i]:
+                if j in count:
+                    count[j] += support[i]
+                else:
+                    count[j] = support[i]
+        updatedDict = {}
+        updatedDict = {k: v for k, v in count.items() if v >= minSup}
+        count = 0
+        for p in condPatterns:
+            p1 = [v for v in p if v in updatedDict]
+            trans = sorted(p1, key=lambda x: updatedDict[x], reverse=True)
+            if len(trans) > 0:
+                pat.append(trans)
+                sup.append(support[count])
+                count += 1
+        return pat, sup, updatedDict
+
+    def generatePatterns(self, prefix):
+        """generates the patterns
+            :param prefix : forms the combination of items
+            :type prefix : list
+        """
+
+        global _finalPatterns, minSup
+        for i in sorted(self.summaries, key=lambda x: (self.info.get(x))):
+            pattern = prefix[:]
+            pattern.append(i)
+            s = 0
+            for x in self.summaries[i]:
+                s += x.probability
+            _finalPatterns[tuple(pattern)] = self.info[i]
+            if s >= minSup:
+                patterns, support, info = self.conditionalPatterns(i)
+                conditionalTree = _Tree()
+                conditionalTree.info = info.copy()
+                for pat in range(len(patterns)):
+                    conditionalTree.addConditionalPattern(patterns[pat], support[pat])
+                if len(patterns) > 0:
+                    conditionalTree.generatePatterns(pattern)
+            self.removeNode(i)
+
+
+class GUFPGrowth(_ab._spatialFrequentPatterns):
+    """
+        It is one of the fundamental algorithm to discover frequent patterns in a uncertain transactional database
+        using PUF-Tree.
+    Reference:
+    --------
+        Carson Kai-Sang Leung, Syed Khairuzzaman Tanbeer, "PUF-Tree: A Compact Tree Structure for Frequent Pattern Mining of Uncertain Data",
+        Pacific-Asia Conference on Knowledge Discovery and Data Mining(PAKDD 2013), https://link.springer.com/chapter/10.1007/978-3-642-37453-1_2
+    Attributes:
+    ----------
+        iFile : file
+            Name of the Input file or path of the input file
+        oFile : file
+            Name of the output file or path of the output file
+        minSup: float or int or str
+            The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+            However, the users can override their default separator.
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+        startTime:float
+            To record the start time of the mining process
+        endTime:float
+            To record the completion time of the mining process
+        Database : list
+            To store the transactions of a database in list
+        mapSupport : Dictionary
+            To maintain the information of item and their frequency
+        lno : int
+            To represent the total no of transaction
+        tree : class
+            To represents the Tree class
+        itemSetCount : int
+            To represents the total no of patterns
+        finalPatterns : dict
+            To store the complete patterns
+    Methods:
+    -------
+        startMine()
+            Mining process will start from here
+        getPatterns()
+            Complete set of patterns will be retrieved with this function
+        savePatterns(oFile)
+            Complete set of frequent patterns will be loaded in to a output file
+        getPatternsAsDataFrame()
+            Complete set of frequent patterns will be loaded in to a dataframe
+        getMemoryUSS()
+            Total amount of USS memory consumed by the mining process will be retrieved from this function
+        getMemoryRSS()
+            Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        getRuntime()
+            Total amount of runtime taken by the mining process will be retrieved from this function
+        creatingItemSets(fileName)
+            Scans the dataset and stores in a list format
+        frequentOneItem()
+            Extracts the one-length frequent patterns from database
+        updateTransactions()
+            Update the transactions by removing non-frequent items and sort the Database by item decreased support
+        buildTree()
+            After updating the Database, remaining items will be added into the tree by setting root node as null
+        convert()
+            to convert the user specified value
+        startMine()
+            Mining process will start from this function
+    Executing the code on terminal:
+    -------
+        Format:
+        ------
+        python3 PUFGrowth.py <inputFile> <outputFile> <minSup>
+        Examples:
+        --------
+        python3 PUFGrowth.py sampleTDB.txt patterns.txt 3    (minSup  will be considered in support count or frequency)
+    Sample run of importing the code:
+    -------------------
+        from PAMI.uncertainFrequentPattern.basic import puf as alg
+        obj = alg.PUFGrowth(iFile, minSup)
+        obj.startMine()
+        Patterns = obj.getPatterns()
+        print("Total number of  Patterns:", len(Patterns))
+        obj.savePatterns(oFile)
+        Df = obj.getPatternsAsDataFrame()
+        memUSS = obj.getMemoryUSS()
+        print("Total Memory in USS:", memUSS)
+        memRSS = obj.getMemoryRSS()
+        print("Total Memory in RSS", memRSS)
+        run = obj.getRuntime()
+        print("Total ExecutionTime in seconds:", run)
+    Credits:
+    -------
+        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+    """
+    _startTime = float()
+    _endTime = float()
+    _minSup = str()
+    _finalPatterns = {}
+    _iFile = " "
+    _oFile = " "
+    _nFile  = " "
+    _sep = " "
+    _memoryUSS = float()
+    _memoryRSS = float()
+    _Database = []
+    _rank = {}
+
+    def __init__(self, iFile, nFile, minSup, sep='\t'):
+        super().__init__(iFile, nFile, minSup, sep)
+
+    def _creatingItemSets(self):
+        """
+            Scans the uncertain transactional dataset
+        """
+        self._Database = []
+        if isinstance(self._iFile, _ab._pd.DataFrame):
+            uncertain, data = [], []
+            if self._iFile.empty:
+                print("its empty..")
+            i = self._iFile.columns.values.tolist()
+            if 'Transactions' in i:
+                self._Database = self._iFile['Transactions'].tolist()
+            if 'uncertain' in i:
+                uncertain = self._iFile['uncertain'].tolist()
+            for k in range(len(data)):
+                tr = []
+                for j in range(len(data[k])):
+                    product = _Item(data[k][j], uncertain[k][j])
+                    tr.append(product)
+                self._Database.append(tr)
+
+            # print(self.Database)
+        if isinstance(self._iFile, str):
+            if _ab._validators.url(self._iFile):
+                data = _ab._urlopen(self._iFile)
+                for line in data:
+                    line.strip()
+                    line = line.decode("utf-8")
+                    temp = [i.rstrip() for i in line.split(self._sep)]
+                    temp = [x for x in temp if x]
+                    tr = []
+                    for i in temp:
+                        i1 = i.index('(')
+                        i2 = i.index(')')
+                        item = i[0:i1]
+                        probability = float(i[i1 + 1:i2])
+                        product = _Item(item, probability)
+                        tr.append(product)
+                    self._Database.append(temp)
+            else:
+                try:
+                    with open(self._iFile, 'r') as f:
+                        for line in f:
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
+                            tr = []
+                            for i in temp:
+                                i1 = i.index('(')
+                                i2 = i.index(')')
+                                item = i[0:i1]
+                                probability = float(i[i1 + 1:i2])
+                                product = _Item(item, probability)
+                                tr.append(product)
+                            self._Database.append(tr)
+                except IOError:
+                    print("File Not Found")
+
+    def _scanNeighbours(self):
+        """
+            Scans the uncertain transactional dataset
+        """
+        global _neighbourList
+        _neighbourList = {}
+        if isinstance(self._nFile, _ab._pd.DataFrame):
+            neighbours, items = [], []
+            if self._nFile.empty:
+                print("its empty..")
+            i = self._nFile.columns.values.tolist()
+            if 'items' in i:
+                self._Database = self._nFile['items'].tolist()
+            if 'neighbours' in i:
+                neighbours = self._nFile['neighbours'].tolist()
+            for k in range(len(items)):
+                _neighbourList[items[k]] = neighbours[k]
+
+            # print(self.Database)
+        if isinstance(self._nFile, str):
+            if _ab._validators.url(self._nFile):
+                data = _ab._urlopen(self._nFile)
+                for line in data:
+                    line.strip()
+                    line = line.decode("utf-8")
+                    temp = [i.rstrip() for i in line.split(self._sep)]
+                    temp = [x for x in temp if x]
+                    _neighbourList[temp[0]] = temp[1:]
+            else:
+                try:
+                    with open(self._nFile, 'r') as f:
+                        for line in f:
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
+                            _neighbourList[temp[0]] = temp[1:]
+
+                except IOError:
+                    print("File Not Found")
+
+
+    def _frequentOneItem(self):
+        """takes the self.Database and calculates the support of each item in the dataset and assign the
+            ranks to the items by decreasing support and returns the frequent items list
+                :param self.Database : it represents the one self.Database in database
+                :type self.Database : list
+        """
+
+        mapSupport = {}
+        for i in self._Database:
+            for j in i:
+                if j.item not in mapSupport:
+                    mapSupport[j.item] = j.probability
+                else:
+                    mapSupport[j.item] += j.probability
+        mapSupport = {k: v for k, v in mapSupport.items() if v >= self._minSup}
+        plist = [k for k, v in sorted(mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        self.rank = dict([(index, item) for (item, index) in enumerate(plist)])
+        return mapSupport, plist
+
+    @staticmethod
+    def _buildTree(data, info):
+        """it takes the self.Database and support of each item and construct the main tree with setting root
+            node as null
+                :param data : it represents the one self.Database in database
+                :type data : list
+                :param info : it represents the support of each item
+                :type info : dictionary
+        """
+
+        rootNode = _Tree()
+        rootNode.info = info.copy()
+        for i in range(len(data)):
+            rootNode.addTransaction(data[i])
+        return rootNode
+
+    def _updateTransactions(self, dict1):
+        """remove the items which are not frequent from self.Database and updates the self.Database with rank of items
+            :param dict1 : frequent items with support
+            :type dict1 : dictionary
+        """
+
+        list1 = []
+        for tr in self._Database:
+            list2 = []
+            for i in range(0, len(tr)):
+                if tr[i].item in dict1:
+                    list2.append(tr[i])
+            if len(list2) >= 2:
+                basket = list2
+                basket.sort(key=lambda val: self.rank[val.item])
+                list2 = basket
+                list1.append(list2)
+        return list1
+
+    @staticmethod
+    def _check(i, x):
+        """To check the presence of item or pattern in transaction
+                :param x: it represents the pattern
+                :type x : list
+                :param i : represents the uncertain self.Database
+                :type i : list
+        """
+
+        # This method taken a transaction as input and returns the tree
+        for m in x:
+            k = 0
+            for n in i:
+                if m == n.item:
+                    k += 1
+            if k == 0:
+                return 0
+        return 1
+
+    def _convert(self, value):
+        """
+        To convert the type of user specified minSup value
+            :param value: user specified minSup value
+            :return: converted type minSup value
+        """
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = (len(self._Database) * value)
+        if type(value) is str:
+            if '.' in value:
+                value = (len(self._Database) * value)
+            else:
+                value = int(value)
+        return value
+
+    def _removeFalsePositives(self):
+        """
+            To remove the false positive patterns generated in frequent patterns
+            :return: patterns with accurate probability
+        """
+        global _finalPatterns
+        periods = {}
+        for i in self._Database:
+            for x, y in _finalPatterns.items():
+                if len(x) == 1:
+                    periods[x] = y
+                else:
+                    s = 1
+                    check = self._check(i, x)
+                    if check == 1:
+                        for j in i:
+                            if j.item in x:
+                                s *= j.probability
+                        if x in periods:
+                            periods[x] += s
+                        else:
+                            periods[x] = s
+        for x, y in periods.items():
+            if y >= self._minSup:
+                sample = str()
+                for i in x:
+                    sample = sample + i + " "
+                self._finalPatterns[sample] = y
+
+    def startMine(self):
+        """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
+            by counting the original support of a patterns
+        """
+        global minSup, _neighbourList
+        print(self._nFile)
+        self._startTime = _ab._time.time()
+        self._creatingItemSets()
+        self._scanNeighbours()
+        #print(_neighbourList)
+        #self._minSup = self._convert(self._minSup)
+        self._minSup = float(self._minSup)
+        minSup = self._minSup
+        print(self._minSup)
+        self._finalPatterns = {}
+        mapSupport, plist = self._frequentOneItem()
+        _neighbourList = {k: v for k, v in _neighbourList.items() if k in plist}
+        self.Database1 = self._updateTransactions(mapSupport)
+        info = {k: v for k, v in mapSupport.items()}
+        Tree1 = self._buildTree(self.Database1, info)
+        Tree1.generatePatterns([])
+        self._removeFalsePositives()
+        print("Frequent patterns were generated from uncertain databases successfully using PUF algorithm")
+        self._endTime = _ab._time.time()
+        process = _ab._psutil.Process(_ab._os.getpid())
+        self._memoryUSS = float()
+        self.memoryRSS = float()
+        self._memoryUSS = process.memory_full_info().uss
+        self.memoryRSS = process.memory_info().rss
+
+    def getMemoryUSS(self):
+        """Total amount of USS memory consumed by the mining process will be retrieved from this function
+        :return: returning USS memory consumed by the mining process
+        :rtype: float
+        """
+
+        return self._memoryUSS
+
+    def getMemoryRSS(self):
+        """Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        :return: returning RSS memory consumed by the mining process
+        :rtype: float
+        """
+
+        return self.memoryRSS
+
+    def getRuntime(self):
+        """Calculating the total amount of runtime taken by the mining process
+        :return: returning total amount of runtime taken by the mining process
+        :rtype: float
+        """
+
+        return self._endTime - self._startTime
+
+    def getPatternsAsDataFrame(self):
+        """Storing final frequent patterns in a dataframe
+        :return: returning frequent patterns in a dataframe
+        :rtype: pd.DataFrame
+        """
+
+        dataframe = {}
+        data = []
+        for a, b in self._finalPatterns.items():
+            data.append([a, b])
+            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
+        return dataframe
+
+    def savePatterns(self, outFile):
+        """Complete set of frequent patterns will be loaded in to a output file
+        :param outFile: name of the output file
+        :type outFile: file
+        """
+        self.oFile = outFile
+        writer = open(self.oFile, 'w+')
+        for x, y in self._finalPatterns.items():
+            s1 = x + ":" + str(y)
+            writer.write("%s \n" % s1)
+
+    def getPatterns(self):
+        """ Function to send the set of frequent patterns after completion of the mining process
+        :return: returning frequent patterns
+        :rtype: dict
+        """
+        return self._finalPatterns
+
+
+if __name__ == "__main__":
+    _ap = str()
+    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
+        if len(_ab._sys.argv) == 6:
+            _ap = GUFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
+        if len(_ab._sys.argv) == 5:
+            _ap = GUFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+        _ap.startMine()
+        _Patterns = _ap.getPatterns()
+        print("Total number of Patterns:", len(_Patterns))
+        _ap.savePatterns(_ab._sys.argv[2])
+        _memUSS = _ap.getMemoryUSS()
+        print("Total Memory in USS:", _memUSS)
+        _memRSS = _ap.getMemoryRSS()
+        print("Total Memory in RSS", _memRSS)
+        _run = _ap.getRuntime()
+        print("Total ExecutionTime in ms:", _run)
+    else:
+        ap = GUFPGrowth("/Users/likhitha/Downloads/Nighbours_gen/uncertainSpatailFrequent/sample.txt",
+                        "/Users/likhitha/Downloads/Nighbours_gen/uncertainSpatailFrequent/sampleNeighbours.txt", 0.1, ' ')
+        ap.startMine()
+        Patterns = ap.getPatterns()
+        print("Total number of Patterns:", len(Patterns))
+        ap.savePatterns("patterns.txt")
+        memUSS = ap.getMemoryUSS()
+        print("Total Memory in USS:", memUSS)
+        memRSS = ap.getMemoryRSS()
+        print("Total Memory in RSS", memRSS)
+        run = ap.getRuntime()
+        print("Total ExecutionTime in ms:", run)
+        print("Error! The number of input parameters do not match the total number of parameters provided")
\ No newline at end of file
Index: PAMI/geoReferencedPeriodicPattern/abstract.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/geoReferencedPeriodicPattern/abstract.py b/PAMI/faultTolerantFrequentPattern/abstract.py
rename from PAMI/geoReferencedPeriodicPattern/abstract.py
rename to PAMI/faultTolerantFrequentPattern/abstract.py
--- a/PAMI/geoReferencedPeriodicPattern/abstract.py	(revision 13e95f8a76f333a1a390dbc39efe0767be0b94b4)
+++ b/PAMI/faultTolerantFrequentPattern/abstract.py	(date 1656441096571)
@@ -12,7 +12,21 @@
 #
 #      You should have received a copy of the GNU General Public License
 #      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#
+#      This program is free software: you can redistribute it and/or modify
+#      it under the terms of the GNU General Public License as published by
+#      the Free Software Foundation, either version 3 of the License, or
+#      (at your option) any later version.
+#
+#      This program is distributed in the hope that it will be useful,
+#      but WITHOUT ANY WARRANTY; without even the implied warranty of
+#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+#      GNU General Public License for more details.
+#
+#      You should have received a copy of the GNU General Public License
+#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
 
+# from abc import ABC as _ABC, abstractmethod as _abstractmethod
 from abc import ABC as _ABC, abstractmethod as _abstractmethod
 import time as _time
 import csv as _csv
@@ -25,29 +39,26 @@
 import sys as _sys
 import validators as _validators
 from urllib.request import urlopen as _urlopen
+import functools as _functools
+import itertools as _itertools
 
 
-class _spatialPeriodicFrequentPatterns(_ABC):
+class _frequentPatterns(_ABC):
     """ This abstract base class defines the variables and methods that every frequent pattern mining algorithm must
         employ in PAMI
-    Attributes :
-    ----------
+
+
+       Attributes:
+       ----------
         iFile : str
             Input file name or path of the input file
-        nFile: str
-            Neighbourhoof file name
         minSup: integer or float or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
             Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-        maxPer: integer or float or str
-            The user can specify maxPer either in count or proportion of database size.
-            If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: maxPer = 10 will be treated as integer, while minSup=10.0 will be treated as float
         sep : str
-            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
             However, the users can override their default separator
         startTime:float
             To record the start time of the algorithm
@@ -61,8 +72,9 @@
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
-    Methods :
-    -------
+
+       Methods:
+       -------
         startMine()
             Calling this function will start the actual mining process
         getPatterns()
@@ -77,85 +89,35 @@
             This function outputs the total amount of RSS memory consumed by a mining algorithm
         getRuntime()
             This function outputs the total runtime of a mining algorithm
+
     """
 
-    def __init__(self, iFile, nFile, minSup, maxPer, sep="\t"):
+    def __init__(self, iFile, minSup, sep="\t"):
         """
         :param iFile: Input file name or path of the input file
-        :type iFile: str
-        :param nFile: Neighbourhood name of the input
-        :type nFile: str
+        :type iFile: str or DataFrame
         :param minSup: The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
             Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
         :type minSup: int or float or str
-        :param maxPer: The user can specify maxPer either in count or proportion of database size.
-            If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
-        :type maxPer: int or float or str
         :param sep: separator used to distinguish items from each other. The default separator is tab space. However, users can override the default separator
         :type sep: str
         """
 
         self._iFile = iFile
-        self._nFile = nFile
         self._sep = sep
         self._minSup = minSup
-        self._maxPer = maxPer
-        self._startTime = float()
-        self._endTime = float()
         self._finalPatterns = {}
         self._oFile = str()
         self._memoryUSS = float()
         self._memoryRSS = float()
+        self._startTime = float()
+        self._endTime = float()
 
-
-    '''@abstractmethod
-    def iFile(self):
-        """Variable to store the input file path/file name"""
-        pass
-    @abstractmethod
-    def nFile(self):
-        """Variable to store the neighbourhood file path/file name"""
-        pass
-    @abstractmethod
-    def minSup(self):
-        """Variable to store the user-specified minimum support value"""
-        pass
-    @abstractmethod
-    def maxPer(self):
-        """Variable to store the user-specified minimum support value"""
-        pass
-    @abstractmethod
-    def sep(self):
-        """Variable to store the user-specified minimum support value"""
-        pass
-    @abstractmethod
-    def startTime(self):
-        """Variable to store the start time of the mining process"""
-        pass
-    @abstractmethod
-    def endTime(self):
-        """Variable to store the end time of the complete program"""
-        pass
-    @abstractmethod
-    def memoryUSS(self):
         """Variable to store USS memory consumed by the program"""
-        pass
-    @abstractmethod
-    def memoryRSS(self):
-        """Variable to store RSS memory consumed by the program"""
-        pass
-    @abstractmethod
-    def finalPatterns(self):
-        """Variable to store the complete set of patterns in a dictionary"""
-        pass
-    @abstractmethod
-    def oFile(self):
-        """Variable to store the name of the output file to store the complete set of frequent patterns"""
-        pass'''
+
+
 
     @_abstractmethod
     def startMine(self):
@@ -172,6 +134,7 @@
     @_abstractmethod
     def savePatterns(self, oFile):
         """Complete set of frequent patterns will be saved in to an output file from this function
+
         :param oFile: Name of the output file
         :type oFile: file
         """
@@ -196,7 +159,6 @@
 
         pass
 
-
     @_abstractmethod
     def getRuntime(self):
         """Total amount of runtime taken by the program will be retrieved from this function"""
Index: PAMI/extras/neighbours/findNeighboursUsingEuclidean.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import sys\nimport re\nfrom math import sqrt\n\nclass createNeighborhoodFileUsingEuclideanDistance:\n    \"\"\"\n    This class create a neighbourhood file using euclid distance.\n\n    Attribute:\n    ----------\n        iFile : file\n            Input file name or path of the input file\n        oFile : file\n            Output file name or path pf the output file\n        maxEucledianDistace : int\n            The user can specify maxEucledianDistace.\n            This program find pairs of values whose Euclidean distance is less than or equal to maxEucledianDistace\n            and store the pairs.\n\n    Methods:\n    -------\n        startMine()\n            find and store the pairs of values whose Euclidean distance is less than or equal to maxEucledianDistace.\n        getFileName()\n            This function returns output file name.\n    \"\"\"\n\n    def __init__(self,iFile,oFile,maxEucledianDistace, seperator='\\t'):\n        self.iFile = iFile\n        self.oFile = oFile\n        self.maxEucledianDistace = maxEucledianDistace\n\n        coordinates = []\n        result = {}\n        with open(self.iFile,\"r\") as f:\n            for line in f:\n                l = line.rstrip().split(seperator)\n                l[0] = re.sub(r'[^0-9. ]', '', l[0])\n                coordinates.append(l[0].rstrip().split(' '))\n                print(l[0])\n        for i in range(len(coordinates)):\n            for j in range(len(coordinates)):\n                if i != j:\n                    firstCoordinate = coordinates[i]\n                    secondCoordinate = coordinates[j]\n                    x1 = float(firstCoordinate[0])\n                    y1 = float(firstCoordinate[1])\n                    x2 = float(secondCoordinate[0])\n                    y2 = float(secondCoordinate[1])\n                    ansX = x2-x1\n                    ansY = y2-y1\n                    dist = abs(pow(ansX,2) - pow(ansY,2))\n                    norm = sqrt(dist)\n                    if norm <= float(self.maxEucledianDistace):\n                        result[tuple(firstCoordinate)] = result.get(tuple(firstCoordinate),[])\n                        result[tuple(firstCoordinate)].append(secondCoordinate)\n\n        with open(self.oFile,\"w\") as f:\n            for i in result:\n                string = \"Point(\" +i[0]+\" \"+i[1] + \")\"+ seperator\n                f.write(string)\n                for j in result[i]:\n                    string = \"Point(\" + j[0] + \" \" + j[1] + \")\"+ seperator\n                    f.write(string)\n                f.write(\"\\n\")\n\n\n    def getFileName(self):\n        return self.oFile\n\nif __name__ == \"__main__\":\n    createNeighborhoodFileUsingEuclideanDistance('/Users/Likhitha/Downloads/Nighbours_gen/points','/Users/Likhitha/Downloads/Nighbours_gen/inputOutput.txt',\n                                                 10, ',')\n\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/extras/neighbours/findNeighboursUsingEuclidean.py b/PAMI/extras/neighbours/findNeighboursUsingEuclidean.py
--- a/PAMI/extras/neighbours/findNeighboursUsingEuclidean.py	(revision 13e95f8a76f333a1a390dbc39efe0767be0b94b4)
+++ b/PAMI/extras/neighbours/findNeighboursUsingEuclidean.py	(date 1656441096522)
@@ -35,6 +35,7 @@
         with open(self.iFile,"r") as f:
             for line in f:
                 l = line.rstrip().split(seperator)
+                print(l)
                 l[0] = re.sub(r'[^0-9. ]', '', l[0])
                 coordinates.append(l[0].rstrip().split(' '))
                 print(l[0])
@@ -55,7 +56,7 @@
                         result[tuple(firstCoordinate)] = result.get(tuple(firstCoordinate),[])
                         result[tuple(firstCoordinate)].append(secondCoordinate)
 
-        with open(self.oFile,"w") as f:
+        with open(self.oFile,"w+") as f:
             for i in result:
                 string = "Point(" +i[0]+" "+i[1] + ")"+ seperator
                 f.write(string)
@@ -69,6 +70,6 @@
         return self.oFile
 
 if __name__ == "__main__":
-    createNeighborhoodFileUsingEuclideanDistance('/Users/Likhitha/Downloads/Nighbours_gen/points','/Users/Likhitha/Downloads/Nighbours_gen/inputOutput.txt',
+    createNeighborhoodFileUsingEuclideanDistance('/Users/Likhitha/Downloads/Nighbours_gen/temp_roads.txt', '/Users/Likhitha/Downloads/Nighbours_gen/road_points.txt',
                                                  10, ',')
 
Index: PAMI/weightedFrequentNeighbourhoodPattern/abstract.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/weightedFrequentNeighbourhoodPattern/abstract.py b/PAMI/weightedFrequentNeighbourhoodPattern/abstract.py
new file mode 100644
--- /dev/null	(date 1656441096541)
+++ b/PAMI/weightedFrequentNeighbourhoodPattern/abstract.py	(date 1656441096541)
@@ -0,0 +1,152 @@
+#  Copyright (C)  2021 Rage Uday Kiran
+#
+#      This program is free software: you can redistribute it and/or modify
+#      it under the terms of the GNU General Public License as published by
+#      the Free Software Foundation, either version 3 of the License, or
+#      (at your option) any later version.
+#
+#      This program is distributed in the hope that it will be useful,
+#      but WITHOUT ANY WARRANTY; without even the implied warranty of
+#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+#      GNU General Public License for more details.
+#
+#      You should have received a copy of the GNU General Public License
+#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+
+from abc import ABC as _ABC, abstractmethod as _abstractmethod
+import time as _time
+import csv as _csv
+import pandas as _pd
+from collections import defaultdict as _defaultdict
+from itertools import combinations as _c
+import os as _os
+import os.path as _ospath
+import psutil as _psutil
+import sys as _sys
+import validators as _validators
+from urllib.request import urlopen as _urlopen
+
+
+class _partialPeriodicSpatialPatterns(_ABC):
+    """ This abstract base class defines the variables and methods that every frequent pattern mining algorithm must
+        employ in PAMI
+    Attributes :
+    ----------
+        iFile : str
+            Input file name or path of the input file
+        nFile: str
+            Neighbourhoof file name
+        maxIAT: integer or float or str
+            The user can specify maxIAT either in count or proportion of database size.
+            If the program detects the data type of maxIAT is integer, then it treats maxIAT is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: maxIAT=10 will be treated as integer, while maxIAT=10.0 will be treated as float
+        minPS: integer or float or str
+            The user can specify minPS either in count or proportion of database size.
+            If the program detects the data type of minPS is integer, then it treats minPS is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minPS = 10 will be treated as integer, while minPS=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
+            However, the users can override their default separator
+        startTime:float
+            To record the start time of the algorithm
+        endTime:float
+            To record the completion time of the algorithm
+        finalPatterns: dict
+            Storing the complete set of patterns in a dictionary variable
+        oFile : str
+            Name of the output file to store complete set of frequent patterns
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+    Methods :
+    -------
+        startMine()
+            Calling this function will start the actual mining process
+        getPatterns()
+            This function will output all interesting patterns discovered by an algorithm
+        savePatterns(oFile)
+            This function will store the discovered patterns in an output file specified by the user
+        getPatternsAsDataFrame()
+            The function outputs the patterns generated by an algorithm as a data frame
+        getMemoryUSS()
+            This function outputs the total amount of USS memory consumed by a mining algorithm
+        getMemoryRSS()
+            This function outputs the total amount of RSS memory consumed by a mining algorithm
+        getRuntime()
+            This function outputs the total runtime of a mining algorithm
+    """
+
+    def __init__(self, iFile, nFile, maxIAT, minPS, sep="\t"):
+        """
+        :param iFile: Input file name or path of the input file
+        :type iFile: str
+        :param nFile: Neighbourhood name of the input
+        :type nFile: str
+        :param maxIAT: constraint to prune the itemsets which are < maxIAT
+        :type maxPer: int or float or str
+        :param minPS: constraint to prune the itemsets which are > minPS
+        :type minPS: int or float or str
+        :param sep: separator used to distinguish items from each other. The default separator is tab space. However, users can override the default separator
+        :type sep: str
+        """
+
+        self._iFile = iFile
+        self._nFile = nFile
+        self._sep = sep
+        self._maxIAT = maxIAT
+        self._minPS = minPS
+        self._startTime = float()
+        self._endTime = float()
+        self._finalPatterns = {}
+        self._oFile = str()
+        self._memoryUSS = float()
+        self._memoryRSS = float()
+
+    @_abstractmethod
+    def startMine(self):
+        """Code for the mining process will start from this function"""
+
+        pass
+
+    @_abstractmethod
+    def getPatterns(self):
+        """Complete set of frequent patterns generated will be retrieved from this function"""
+
+        pass
+
+    @_abstractmethod
+    def savePatterns(self, oFile):
+        """Complete set of frequent patterns will be saved in to an output file from this function
+        :param oFile: Name of the output file
+        :type oFile: file
+        """
+
+        pass
+
+    @_abstractmethod
+    def getPatternsAsDataFrame(self):
+        """Complete set of frequent patterns will be loaded in to data frame from this function"""
+
+        pass
+
+    @_abstractmethod
+    def getMemoryUSS(self):
+        """Total amount of USS memory consumed by the program will be retrieved from this function"""
+
+        pass
+
+    @_abstractmethod
+    def getMemoryRSS(self):
+        """Total amount of RSS memory consumed by the program will be retrieved from this function"""
+
+        pass
+
+
+    @_abstractmethod
+    def getRuntime(self):
+        """Total amount of runtime taken by the program will be retrieved from this function"""
+
+        pass
Index: PAMI/uncertainPeriodicFrequentPattern/basic/PTubeS.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#  Copyright (C)  2021 Rage Uday Kiran\n#\n#      This program is free software: you can redistribute it and/or modify\n#      it under the terms of the GNU General Public License as published by\n#      the Free Software Foundation, either version 3 of the License, or\n#      (at your option) any later version.\n#\n#      This program is distributed in the hope that it will be useful,\n#      but WITHOUT ANY WARRANTY; without even the implied warranty of\n#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#      GNU General Public License for more details.\n#\n#      You should have received a copy of the GNU General Public License\n#      along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nfrom PAMI.uncertainPeriodicFrequentPattern.basic import abstract as _ab\n\n_minSup = float()\n__maxPer = float()\n_lno = int()\n_first = int()\n_last = int()\n\n\nclass _Item:\n    \"\"\"\n        A class used to represent the item with probability in transaction of dataset\n\n        ...\n        Attributes:\n        __________\n            item : int or word\n                Represents the name of the item\n            probability : float\n                Represent the existential probability(likelihood presence) of an item\n    \"\"\"\n\n    def __init__(self, item, probability):\n        self.item = item\n        self.probability = probability\n\n\nclass _Node(object):\n    \"\"\"\n        A class used to represent the node of frequentPatternTree\n\n        Attributes:\n        ----------\n            item: int\n                storing item name of a node\n            probability : int\n                To maintain the existence probability of node\n            secondProbability: float\n                To maintain the second probability of a node\n            parent: node\n                To maintain the parent of every node\n            children : list\n                To maintain the children of node\n            timeStamps:\n                To maintain the timeStamps of a node\n\n        Methods:\n        -------\n            addChild(itemName)\n                storing the children to their respective parent nodes\n    \"\"\"\n\n    def __init__(self, item, children):\n        self.item = item\n        self.probability = 1\n        self.secondProbability = 1\n        self.children = children\n        self.parent = None\n        self.timeStamps = []\n\n    def addChild(self, node):\n        \"\"\"\n        To add the children details to the parent node\n\n        :param node: children node\n\n        :return: updated parent node children\n        \"\"\"\n        self.children[node.item] = node\n        node.parent = self\n\n\ndef _Second(transaction, i):\n    \"\"\"\n    To find the secondProbability of a node in transaction by considering second max probability\n    of the prefix items.\n\n    :param transaction: transaction in a database with item and probability\n\n    :param i: index of the item to calculate secondProbability in a transaction\n\n    :return: secondProbability of a node\n    \"\"\"\n    temp = []\n    for j in range(0, i):\n        temp.append(transaction[j].probability)\n    l1 = max(temp)\n    temp.remove(l1)\n    l2 = max(temp)\n    return l2\n\n\ndef _printTree(root):\n    \"\"\"\n    To print the details of nodes in tree\n\n    :param root: root node of tree\n\n    :return: details nodes in depth-first order\n    \"\"\"\n    for x, y in root.children.items():\n        print(x, y.item, y.probability, y.parent.item, y.timeStamps, y.secondProbability)\n        _printTree(y)\n\n\nclass _Tree(object):\n    \"\"\"\n        A class used to represent the frequentPatternGrowth tree structure\n\n        ...\n\n        Attributes:\n        ----------\n            root: Node\n                Represents the root node of the tree\n            summaries: dictionary\n                storing the nodes with same item name\n            info: dictionary\n                stores the support of items\n\n        Methods:\n        -------\n            addTransaction(transaction)\n                creating transaction as a branch in frequentPatternTree\n            addConditionalTransaction(prefixPaths, supportOfItems)\n                construct the conditional tree for prefix paths\n            getConditionalPatterns(Node)\n                generates the conditional patterns from tree for specific node\n            conditionalTransactions(prefixPaths,Support)\n                takes the prefixPath of a node and support at child of the path and extract the frequent items from\n                prefixPaths and generates prefixPaths with items which are frequent\n            removeNode(node)\n                removes the node from tree once after generating all the patterns respective to the node\n            generatePatterns(Node)\n                starts from the root node of the tree and mines the frequent patterns\n\n    \"\"\"\n\n    def __init__(self):\n        self.root = _Node(None, {})\n        self.summaries = {}\n        self.info = {}\n\n    def addTransaction(self, transaction, tid):\n        \"\"\"adding transaction into tree\n\n            :param transaction : it represents the one transactions in database\n\n            :type transaction : list\n\n            :param tid : the timestamp of transaction\n\n            :type tid : list\n        \"\"\"\n        currentNode = self.root\n        k = 0\n        for i in range(len(transaction)):\n            k += 1\n            if transaction[i].item not in currentNode.children:\n                newNode = _Node(transaction[i].item, {})\n                newNode.k = k\n                if k >= 3:\n                    newNode.secondProbability = _Second(transaction, i)\n                l1 = i - 1\n                temp = []\n                while l1 >= 0:\n                    temp.append(transaction[l1].probability)\n                    l1 -= 1\n                if len(temp) == 0:\n                    newNode.probability = round(transaction[i].probability, 2)\n                else:\n                    newNode.probability = round(max(temp) * transaction[i].probability, 2)\n                currentNode.addChild(newNode)\n                if transaction[i].item in self.summaries:\n                    self.summaries[transaction[i].item].append(newNode)\n                else:\n                    self.summaries[transaction[i].item] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i].item]\n                if k >= 3:\n                    currentNode.secondProbability = max(transaction[i].probability, currentNode.secondProbability)\n                currentNode.k = k\n                l1 = i - 1\n                temp = []\n                while l1 >= 0:\n                    temp.append(transaction[l1].probability)\n                    l1 -= 1\n                if len(temp) == 0:\n                    currentNode.probability += round(transaction[i].probability, 2)\n                else:\n                    nn = max(temp) * transaction[i].probability\n                    currentNode.probability += round(nn, 2)\n        currentNode.timeStamps = currentNode.timeStamps + tid\n\n    def addConditionalTransaction(self, transaction, tid, sup, second):\n        \"\"\"constructing conditional tree from prefixPaths\n\n                :param transaction: it represents the one transactions in database\n\n                :type transaction: list\n\n                :param tid: timestamps of a pattern or transaction in tree\n\n                :type tid: list\n\n                :param sup: support of prefixPath taken at last child of the path\n\n                :type sup: list\n\n                :param second: second probability of node stores max second probability\n\n                :type second: float\n        \"\"\"\n        currentNode = self.root\n        k = 0\n        for i in range(len(transaction)):\n            k += 1\n            if transaction[i] not in currentNode.children:\n                newNode = _Node(transaction[i], {})\n                newNode.k = k\n                newNode.secondProbability = second\n                newNode.probability = sup\n                currentNode.addChild(newNode)\n                if transaction[i] in self.summaries:\n                    self.summaries[transaction[i]].append(newNode)\n                else:\n                    self.summaries[transaction[i]] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i]]\n                currentNode.k = k\n                currentNode.secondProbability = max(currentNode.secondProbability, second)\n                currentNode.probability += sup\n        currentNode.timeStamps = currentNode.timeStamps + tid\n\n    def getConditionalPatterns(self, alpha):\n        \"\"\"generates all the conditional patterns of respective node\n\n            :param alpha : it represents the Node in tree\n\n            type alpha : Node\n        \"\"\"\n        finalPatterns = []\n        finalTimeStamps = []\n        sup = []\n        second = []\n        for i in self.summaries[alpha]:\n            set1 = i.timeStamps\n            s = i.probability\n            s1 = i.secondProbability\n            set2 = []\n            while i.parent.item is not None:\n                set2.append(i.parent.item)\n                i = i.parent\n            if len(set2) > 0:\n                set2.reverse()\n                finalPatterns.append(set2)\n                finalTimeStamps.append(set1)\n                second.append(s1)\n                sup.append(s)\n        finalPatterns, finalTimeStamps, support, info = _conditionalTransactions(finalPatterns, finalTimeStamps, sup)\n        return finalPatterns, finalTimeStamps, support, info, second\n\n    def removeNode(self, nodeValue):\n        \"\"\"removing the node from tree\n\n            :param nodeValue : it represents the node in tree\n\n            :type nodeValue : node\n        \"\"\"\n        for i in self.summaries[nodeValue]:\n            i.parent.timeStamps = i.parent.timeStamps + i.timeStamps\n            del i.parent.children[nodeValue]\n\n    def getTimeStamps(self, alpha):\n        \"\"\"\n        To get the timeStamps of a node in tree\n\n            :param alpha: node of a tree\n\n            :return: timeStamps of a node\n        \"\"\"\n        temp = []\n        for i in self.summaries[alpha]:\n            temp += i.timeStamps\n        return temp\n\n    def generatePatterns(self, prefix, periodic):\n        \"\"\"generates the patterns\n\n            :param prefix : forms the combination of items\n\n            :type prefix : list\n\n            :param periodic : to store the patterns\n\n            :type prefix : dictionary\n        \"\"\"\n        global _minSup\n        for i in sorted(self.summaries, key=lambda x: (self.info.get(x)[0])):\n            pattern = prefix[:]\n            pattern.append(i)\n            s = 0\n            for x in self.summaries[i]:\n                if x.k <= 2:\n                    s += x.probability\n                elif x.k >= 3:\n                    n = x.probability * pow(x.secondProbability, (x.k - 2))\n                    s += n\n            periodic[tuple(pattern)] = self.info[i]\n            if s >= _minSup:\n                patterns, timeStamps, support, info, second = self.getConditionalPatterns(i)\n                conditionalTree = _Tree()\n                conditionalTree.info = info.copy()\n                for pat in range(len(patterns)):\n                    conditionalTree.addConditionalTransaction(patterns[pat], timeStamps[pat], support[pat], second[pat])\n                if len(patterns) > 0:\n                    conditionalTree.generatePatterns(pattern, periodic)\n            self.removeNode(i)\n\n\ndef _getPeriodAndSupport(s, timeStamps):\n    \"\"\"\n    To calculate the support and periodicity of timeStamps\n\n    :param s: support\n\n    :param timeStamps: timeStamps\n\n    :return: support and periodicity of timeStamps\n    \"\"\"\n    global _lno, _maxPer\n    timeStamps.sort()\n    cur = 0\n    per = 0\n    sup = s\n    for j in range(len(timeStamps)):\n        per = max(per, timeStamps[j] - cur)\n        if per > _maxPer:\n            return [0, 0]\n        cur = timeStamps[j]\n    per = max(per, _lno - cur)\n    return [sup, per]\n\n\ndef _conditionalTransactions(conditionalPatterns, conditionalTimeStamps, support):\n    \"\"\" It generates the conditional patterns with frequent items\n\n        :param conditionalPatterns : conditional patterns generated from getConditionalPatterns method for respective node\n\n        :type conditionalPatterns : list\n\n        :param conditionalTimeStamps : timestamps of respective conditional timestamps\n\n        :type conditionalTimeStamps : list\n\n        :param support : the support of conditional pattern in tree\n\n        :type support : list\n    \"\"\"\n    global _minSup, _maxPer\n    pat = []\n    timeStamps = []\n    sup = []\n    data1 = {}\n    count = {}\n    for i in range(len(conditionalPatterns)):\n        for j in conditionalPatterns[i]:\n            if j in data1:\n                data1[j] = data1[j] + conditionalTimeStamps[i]\n                count[j] += support[i]\n            else:\n                data1[j] = conditionalTimeStamps[i]\n                count[j] = support[i]\n    updatedDict = {}\n    for m in data1:\n        updatedDict[m] = _getPeriodAndSupport(count[m], data1[m])\n    updatedDict = {k: v for k, v in updatedDict.items() if v[0] >= _minSup and v[1] <= _maxPer}\n    count = 0\n    for p in conditionalPatterns:\n        p1 = [v for v in p if v in updatedDict]\n        trans = sorted(p1, key=lambda x: (updatedDict.get(x)[0]), reverse=True)\n        if len(trans) > 0:\n            pat.append(trans)\n            timeStamps.append(conditionalTimeStamps[count])\n            sup.append(support[count])\n        count += 1\n    return pat, timeStamps, sup, updatedDict\n\n\nclass PTubeS(_ab._periodicFrequentPatterns):\n    \"\"\"\n        Periodic-TubeS is  to discover periodic-frequent patterns in a temporal database.\n\n        Reference:\n        --------\n\n        Attributes:\n        ----------\n            iFile : file\n                Name of the Input file or path of the input file\n            oFile: file\n                Name of the output file or path of the output file\n            minSup: int or float or str\n                The user can specify minSup either in count or proportion of database size.\n                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.\n                Otherwise, it will be treated as float.\n                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float\n            maxPer: int or float or str\n                The user can specify maxPer either in count or proportion of database size.\n                If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.\n                Otherwise, it will be treated as float.\n                Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float\n            sep: str\n                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \\t.\n                However, the users can override their default separator.\n            memoryUSS: float\n                To store the total amount of USS memory consumed by the program\n            memoryRSS: float\n                To store the total amount of RSS memory consumed by the program\n            startTime:float\n                To record the start time of the mining process\n            endTime:float\n                To record the completion time of the mining process\n            Database: list\n                To store the transactions of a database in list\n            mapSupport: Dictionary\n                To maintain the information of item and their frequency\n            lno: int\n                To represent the total no of transaction\n            tree: class\n                To represents the Tree class\n            itemSetCount: int\n                To represents the total no of patterns\n            finalPatterns: dict\n                To store the complete patterns\n        Methods:\n        -------\n            startMine()\n                Mining process will start from here\n            getPatterns()\n                Complete set of patterns will be retrieved with this function\n            savePatterns(oFile)\n                Complete set of periodic-frequent patterns will be loaded in to a output file\n            getPatternsAsDataFrame()\n                Complete set of periodic-frequent patterns will be loaded in to a dataframe\n            getMemoryUSS()\n                Total amount of USS memory consumed by the mining process will be retrieved from this function\n            getMemoryRSS()\n                Total amount of RSS memory consumed by the mining process will be retrieved from this function\n            getRuntime()\n                Total amount of runtime taken by the mining process will be retrieved from this function\n            creatingItemSets(fileName)\n                Scans the dataset and stores in a list format\n            PeriodicFrequentOneItems()\n                Extracts the one-periodic-frequent patterns from database\n            updateDatabases()\n                Update the database by removing aperiodic items and sort the Database by item decreased support\n            buildTree()\n                After updating the Database, remaining items will be added into the tree by setting root node as null\n            convert()\n                to convert the user specified value\n\n        Executing the code on terminal:\n        -------\n            Format:\n            ------\n                python3 PTubeS.py <inputFile> <outputFile> <minSup> <maxPer>\n            Examples:\n            --------\n                python3 PTubeS.py sampleTDB.txt patterns.txt 0.3 4     (minSup and maxPer will be considered in support count or frequency)\n\n        Sample run of importing the code:\n        -------------------\n\n            from PAMI.uncertainPeriodicFrequentPattern.basic import PTubeS as alg\n\n            obj = alg.PTubeS(iFile, minSup, maxPer)\n\n            obj.startMine()\n\n            periodicFrequentPatterns = obj.getPatterns()\n\n            print(\"Total number of Periodic Frequent Patterns:\", len(periodicFrequentPatterns))\n\n            obj.savePatterns(oFile)\n\n            Df = obj.getPatternsAsDataFrame()\n\n            memUSS = obj.getMemoryUSS()\n\n            print(\"Total Memory in USS:\", memUSS)\n\n            memRSS = obj.getMemoryRSS()\n\n            print(\"Total Memory in RSS\", memRSS)\n\n            run = obj.getRuntime()\n\n            print(\"Total ExecutionTime in seconds:\", run)\n\n        Credits:\n        -------\n            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\\n\n\n    \"\"\"\n\n    _rank = {}\n    _startTime = float()\n    _endTime = float()\n    _minSup = float()\n    _maxPer = float()\n    _finalPatterns = {}\n    _iFile = \" \"\n    _oFile = \" \"\n    _sep = \" \"\n    _memoryUSS = float()\n    _memoryRSS = float()\n    _Database = []\n    _lno = 0\n    _periodic = {}\n\n    def _creatingItemSets(self):\n        \"\"\"\n            Storing the complete transactions of the database/input file in a database variable\n\n\n        \"\"\"\n        self._Database = []\n        if isinstance(self._iFile, _ab._pd.DataFrame):\n            uncertain, data, ts = [], [], []\n            if self._iFile.empty:\n                print(\"its empty..\")\n            i = self._iFile.columns.values.tolist()\n            if 'TS' in i:\n                ts = self._iFile['TS'].tolist()\n            if 'Transactions' in i:\n                data = self._iFile['Transactions'].tolist()\n            if 'uncertain' in i:\n                uncertain = self._iFile['uncertain'].tolist()\n            for k in range(len(data)):\n                tr = [ts[k]]\n                for j in range(len(data[k])):\n                    product = _Item(data[k][j], uncertain[k][j])\n                    tr.append(product)\n                self._Database.append(tr)\n                self._lno += 1\n\n        if isinstance(self._iFile, str):\n            if _ab._validators.url(self._iFile):\n                data = _ab._urlopen(self._iFile)\n                for line in data:\n                    line.strip()\n                    line = line.decode(\"utf-8\")\n                    temp = [i.rstrip() for i in line.split(self._sep)]\n                    temp = [x for x in temp if x]\n                    tr = []\n                    for i in temp[1:]:\n                        i1 = i.index('(')\n                        i2 = i.index(')')\n                        item = i[0:i1]\n                        probability = float(i[i1 + 1:i2])\n                        product = _Item(item, probability)\n                        tr.append(product)\n                    self._lno += 1\n                    self._Database.append(temp)\n            else:\n                try:\n                    count = 0\n                    with open(self._iFile, 'r') as f:\n                        for line in f:\n                            #count += 1\n                            temp = [i.rstrip() for i in line.split(self._sep)]\n                            temp = [x for x in temp if x]\n                            tr = [int(temp[0])]\n                            for i in temp[1:]:\n                                i1 = i.index('(')\n                                i2 = i.index(')')\n                                item = i[0:i1]\n                                probability = float(i[i1 + 1:i2])\n                                product = _Item(item, probability)\n                                tr.append(product)\n                            self._lno += 1\n                            self._Database.append(tr)\n                except IOError:\n                    print(\"File Not Found\")\n\n    def _PeriodicFrequentOneItems(self):\n        \"\"\"takes the transactions and calculates the support of each item in the dataset and assign the\n            ranks to the items by decreasing support and returns the frequent items list\n\n        \"\"\"\n        global _first, _last\n        mapSupport = {}\n        for i in self._Database:\n            n = i[0]\n            for j in i[1:]:\n                if j.item not in mapSupport:\n                    mapSupport[j.item] = [round(j.probability, 2), abs(0 - n), n]\n                else:\n                    mapSupport[j.item][0] += round(j.probability, 2)\n                    mapSupport[j.item][1] = max(mapSupport[j.item][1], abs(n - mapSupport[j.item][2]))\n                    mapSupport[j.item][2] = n\n        for key in mapSupport:\n            mapSupport[key][1] = max(mapSupport[key][1], self._lno - mapSupport[key][2])\n        mapSupport = {k: [round(v[0], 2), v[1]] for k, v in mapSupport.items() if\n                      v[1] <= self._maxPer and v[0] >= self._minSup}\n        plist = [k for k, v in sorted(mapSupport.items(), key=lambda x: (x[1][0], x[0]), reverse=True)]\n        self._rank = dict([(index, item) for (item, index) in enumerate(plist)])\n        return mapSupport, plist\n\n    def _buildTree(self, data, info):\n        \"\"\"it takes the transactions and support of each item and construct the main tree with setting root\n                                    node as null\n\n            :param data : it represents the one transactions in database\n\n            :type data : list\n\n            :param info : it represents the support of each item\n\n            :type info : dictionary\n        \"\"\"\n        rootNode = _Tree()\n        rootNode.info = info.copy()\n        for i in range(len(data)):\n            set1 = [data[i][0]]\n            rootNode.addTransaction(data[i][1:], set1)\n        return rootNode\n\n    def _updateTransactions(self, dict1):\n        \"\"\"remove the items which are not frequent from transactions and updates the transactions with rank of items\n\n                :param dict1 : frequent items with support\n\n                :type dict1 : dictionary\n        \"\"\"\n        list1 = []\n        for tr in self._Database:\n            list2 = [int(tr[0])]\n            for i in range(1, len(tr)):\n                if tr[i].item in dict1:\n                    list2.append(tr[i])\n            if (len(list2) >= 2):\n                basket = list2[1:]\n                basket.sort(key=lambda val: self._rank[val.item])\n                list2[1:] = basket[0:]\n                list1.append(list2)\n        return list1\n\n    def _check(self, i, x):\n        \"\"\"To check the presence of item or pattern in transaction\n\n            :param x: it represents the pattern\n\n            :type x: list\n\n            :param i: represents the uncertain transactions\n\n            :type i: list\n        \"\"\"\n        for m in x:\n            k = 0\n            for n in i:\n                if m == n.item:\n                    k += 1\n            if k == 0:\n                return 0\n        return 1\n\n    def _convert(self, value):\n        \"\"\"\n            To convert the given user specified value\n\n            :param value: user specified value\n\n            :return: converted value\n        \"\"\"\n        if type(value) is int:\n            value = int(value)\n        if type(value) is float:\n            value = int(len(self._Database) * value)\n        if type(value) is str:\n            if '.' in value:\n                value = int(len(self._Database) * value)\n            else:\n                value = int(value)\n\n        return value\n\n    def _removeFalsePositives(self):\n        \"\"\"\n        To remove false positives in generated patterns\n\n        :return: original patterns\n        \"\"\"\n        periods = {}\n        for i in self._Database:\n            for x, y in self._periodic.items():\n                if len(x) == 1:\n                    periods[x] = y\n                else:\n                    s = 1\n                    check = self._check(i[1:], x)\n                    if check == 1:\n                        for j in i[1:]:\n                            if j.item in x:\n                                s *= j.probability\n                        if x in periods:\n                            periods[x][0] += s\n                        else:\n                            periods[x] = [s, y[1]]\n        for x, y in periods.items():\n            if y[0] >= _minSup:\n                sample = str()\n                for i in x:\n                    sample = sample + i + \" \"\n                self._finalPatterns[sample] = y\n\n    def startMine(self):\n        \"\"\"Main method where the patterns are mined by constructing tree and remove the remove the false patterns\n                    by counting the original support of a patterns\n\n\n        \"\"\"\n        global _lno, _first, _last, _minSup, _maxPer\n        self._startTime = _ab._time.time()\n        self._creatingItemSets()\n        self._finalPatterns = {}\n        self._minSup = self._convert(self._minSup)\n        self._maxPer = self._convert(self._maxPer)\n        _minSup, _maxPer, _lno = self._minSup, self._maxPer, self._lno\n        mapSupport, plist = self._PeriodicFrequentOneItems()\n        updatedTrans = self._updateTransactions(mapSupport)\n        info = {k: v for k, v in mapSupport.items()}\n        Tree = self._buildTree(updatedTrans, info)\n        self._periodic = {}\n        Tree.generatePatterns([], self._periodic)\n        self._removeFalsePositives()\n        print(\"periodic Frequent patterns were generated successfully using Periodic-TubeS algorithm\")\n        self._endTime = _ab._time.time()\n        process = _ab._psutil.Process(_ab._os.getpid())\n        self._memoryRSS = float()\n        self._memoryUSS = float()\n        self._memoryUSS = process.memory_full_info().uss\n        self._memoryRSS = process.memory_info().rss\n\n    def getMemoryUSS(self):\n        \"\"\"Total amount of USS memory consumed by the mining process will be retrieved from this function\n\n        :return: returning USS memory consumed by the mining process\n\n        :rtype: float\n        \"\"\"\n\n        return self._memoryUSS\n\n    def getMemoryRSS(self):\n        \"\"\"Total amount of RSS memory consumed by the mining process will be retrieved from this function\n\n        :return: returning RSS memory consumed by the mining process\n\n        :rtype: float\n        \"\"\"\n\n        return self._memoryRSS\n\n    def getRuntime(self):\n        \"\"\"Calculating the total amount of runtime taken by the mining process\n\n\n        :return: returning total amount of runtime taken by the mining process\n\n        :rtype: float\n        \"\"\"\n\n        return self._endTime - self._startTime\n\n    def getPatternsAsDataFrame(self):\n        \"\"\"Storing final frequent patterns in a dataframe\n\n        :return: returning frequent patterns in a dataframe\n\n        :rtype: pd.DataFrame\n        \"\"\"\n\n        dataframe = {}\n        data = []\n        for a, b in self._finalPatterns.items():\n            data.append([a, b[0], b[1]])\n            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])\n        return dataframe\n\n    def savePatterns(self, outFile):\n        \"\"\"Complete set of frequent patterns will be loaded in to a output file\n\n        :param outFile: name of the output file\n\n        :type outFile: file\n        \"\"\"\n        self._oFile = outFile\n        writer = open(self._oFile, 'w+')\n        for x, y in self._finalPatterns.items():\n            s1 = x + \":\" + str(y)\n            writer.write(\"%s \\n\" % s1)\n\n    def getPatterns(self):\n        \"\"\" Function to send the set of frequent patterns after completion of the mining process\n\n        :return: returning frequent patterns\n\n        :rtype: dict\n        \"\"\"\n        return self._finalPatterns\n\n\nif __name__ == \"__main__\":\n    _ap = str()\n    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:\n        if len(_ab._sys.argv) == 6:\n            _ap = PTubeS(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])\n        if len(_ab._sys.argv) == 5:\n            _ap = PTubeS(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])\n        _ap.startMine()\n        _Patterns = _ap.getPatterns()\n        print(\"Total number of Patterns:\", len(_Patterns))\n        _ap.savePatterns(_ab._sys.argv[2])\n        # print(ap.getPatternsAsDataFrame())\n        _memUSS = _ap.getMemoryUSS()\n        print(\"Total Memory in USS:\", _memUSS)\n        _memRSS = _ap.getMemoryRSS()\n        print(\"Total Memory in RSS\", _memRSS)\n        _run = _ap.getRuntime()\n        print(\"Total ExecutionTime in ms:\", _run)\n    else:\n        l = [140]\n        for i in l:\n            ap = PTubeS('/home/apiiit-rkv/Desktop/uncertain/congestion_temporal.txt', i, 2000, ' ')\n            ap.startMine()\n            Patterns = ap.getPatterns()\n            print(\"Total number of Patterns:\", len(Patterns))\n            ap.savePatterns('/home/apiiit-rkv/Desktop/uncertain/output')\n            memUSS = ap.getMemoryUSS()\n            print(\"Total Memory in USS:\", memUSS)\n            memRSS = ap.getMemoryRSS()\n            print(\"Total Memory in RSS\", memRSS)\n            run = ap.getRuntime()\n            print(\"Total ExecutionTime in ms:\", run)\n        print(\"Error! The number of input parameters do not match the total number of parameters provided\")\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/uncertainPeriodicFrequentPattern/basic/PTubeS.py b/PAMI/uncertainPeriodicFrequentPattern/basic/PTubeS.py
--- a/PAMI/uncertainPeriodicFrequentPattern/basic/PTubeS.py	(revision 13e95f8a76f333a1a390dbc39efe0767be0b94b4)
+++ b/PAMI/uncertainPeriodicFrequentPattern/basic/PTubeS.py	(date 1656441096665)
@@ -849,13 +849,13 @@
         _run = _ap.getRuntime()
         print("Total ExecutionTime in ms:", _run)
     else:
-        l = [140]
+        l = [150]
         for i in l:
-            ap = PTubeS('/home/apiiit-rkv/Desktop/uncertain/congestion_temporal.txt', i, 2000, ' ')
+            ap = PTubeS('/Users/Likhitha/Downloads/uncertain/additionalMaterial/Congestion.txt', i, 2000, ' ')
             ap.startMine()
             Patterns = ap.getPatterns()
             print("Total number of Patterns:", len(Patterns))
-            ap.savePatterns('/home/apiiit-rkv/Desktop/uncertain/output')
+            ap.savePatterns('/Users/Likhitha/Downloads/uncertain/output.txt')
             memUSS = ap.getMemoryUSS()
             print("Total Memory in USS:", memUSS)
             memRSS = ap.getMemoryRSS()
Index: PAMI/uncertainPeriodicFrequentPattern/basic/PTubeP.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#  Copyright (C)  2021 Rage Uday Kiran\n#\n#      This program is free software: you can redistribute it and/or modify\n#      it under the terms of the GNU General Public License as published by\n#      the Free Software Foundation, either version 3 of the License, or\n#      (at your option) any later version.\n#\n#      This program is distributed in the hope that it will be useful,\n#      but WITHOUT ANY WARRANTY; without even the implied warranty of\n#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#      GNU General Public License for more details.\n#\n#      You should have received a copy of the GNU General Public License\n#      along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\n\nfrom PAMI.uncertainPeriodicFrequentPattern.basic import abstract as _ab\n\n_minSup = float()\n_maxPer = float()\n_lno = int()\n_first = int()\n_last = int()\n\n\nclass _Item:\n    \"\"\"\n    A class used to represent the item with probability in transaction of dataset\n\n    Attributes:\n    __________\n        item : int or string\n            Represents the name of the item\n        probability : float\n            Represent the existential probability(likelihood presence) of an item\n    \"\"\"\n\n    def __init__(self, item, probability):\n        self.item = item\n        self.probability = probability\n\n\nclass _Node(object):\n    \"\"\"\n        A class used to represent the node of frequentPatternTree\n\n        ...\n        Attributes:\n        ----------\n            item : int\n                storing item of a node\n            probability : int\n                To maintain the expected support of node\n            parent : node\n                To maintain the parent of every node\n            children : list\n                To maintain the children of node\n\n        Methods:\n        -------\n            addChild(itemName)\n                storing the children to their respective parent nodes\n    \"\"\"\n\n    def __init__(self, item, children):\n        self.item = item\n        self.probability = 1\n        self.secondProbability = 1\n        self.p = 1\n        self.children = children\n        self.parent = None\n        self.TimeStamps = []\n\n    def addChild(self, node):\n        \"\"\"\n            to add children details to parent node\n\n            :param node: children node\n\n            :return: update parent node children\n        \"\"\"\n        self.children[node.item] = node\n        node.parent = self\n\n\nclass _Tree(object):\n    \"\"\"\n        A class used to represent the frequentPatternGrowth tree structure\n\n        ...\n\n        Attributes:\n        ----------\n            root: Node\n                Represents the root node of the tree\n            summaries: dictionary\n                storing the nodes with same item name\n            info: dictionary\n                stores the support of items\n\n\n        Methods:\n        -------\n            addTransaction(transaction)\n                creating transaction as a branch in Tree\n            addConditionalTransaction(prefixPaths, supportOfItems)\n                construct the conditional tree for prefix paths\n            getConditionalPatterns(Node)\n                generates the conditional patterns from tree for specific node\n            conditionalTransactions(prefixPaths,Support)\n                takes the prefixPath of a node and support at child of the path and extract the frequent items from\n                prefixPaths and generates prefixPaths with items which are frequent\n            remove(Node)\n                removes the node from tree once after generating all the patterns respective to the node\n            generatePatterns(Node)\n                starts from the root node of the tree and mines the frequent patterns\n\n    \"\"\"\n\n    def __init__(self):\n        self.root = _Node(None, {})\n        self.summaries = {}\n        self.info = {}\n\n    def addTransaction(self, transaction, tid):\n        \"\"\"\n            adding transaction into tree\n\n            :param transaction : it represents the one transactions in database\n\n            :type transaction : list\n\n            :param tid : the timestamp of transaction\n\n            :type tid : list\n        \"\"\"\n        currentNode = self.root\n        k = 0\n        for i in range(len(transaction)):\n            k += 1\n            if transaction[i].item not in currentNode.children:\n                newNode = _Node(transaction[i].item, {})\n                newNode.k = k\n                newNode.secondProbability = transaction[i].probability\n                l1 = i - 1\n                temp = []\n                while l1 >= 0:\n                    temp.append(transaction[l1].probability)\n                    l1 -= 1\n                if len(temp) == 0:\n                    newNode.probability = round(transaction[i].probability, 2)\n                else:\n                    newNode.probability = round(max(temp) * transaction[i].probability, 2)\n                currentNode.addChild(newNode)\n                if transaction[i].item in self.summaries:\n                    self.summaries[transaction[i].item].append(newNode)\n                else:\n                    self.summaries[transaction[i].item] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i].item]\n                currentNode.secondProbability = max(transaction[i].probability, currentNode.secondProbability)\n                currentNode.k = k\n                l1 = i - 1\n                temp = []\n                while l1 >= 0:\n                    temp.append(transaction[l1].probability)\n                    l1 -= 1\n                if len(temp) == 0:\n                    currentNode.probability += round(transaction[i].probability, 2)\n                else:\n                    nn = max(temp) * transaction[i].probability\n                    currentNode.probability += round(nn, 2)\n        currentNode.TimeStamps = currentNode.TimeStamps + tid\n\n    def addConditionalPatterns(self, transaction, tid, sup):\n        \"\"\"\n            constructing conditional tree from prefixPaths\n\n            :param transaction : it represents the one transactions in database\n\n            :type transaction : list\n\n            :param tid : timestamps of a pattern or transaction in tree\n\n            :param tid : list\n\n            :param sup : support of prefixPath taken at last child of the path\n\n            :type sup : int\n        \"\"\"\n        currentNode = self.root\n        k = 0\n        for i in range(len(transaction)):\n            k += 1\n            if transaction[i] not in currentNode.children:\n                newNode = _Node(transaction[i], {})\n                newNode.k = k\n                newNode.probability = sup\n                currentNode.addChild(newNode)\n                if transaction[i] in self.summaries:\n                    self.summaries[transaction[i]].append(newNode)\n                else:\n                    self.summaries[transaction[i]] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i]]\n                currentNode.k = k\n                currentNode.probability += sup\n        currentNode.TimeStamps = currentNode.TimeStamps + tid\n\n    def conditionalPatterns(self, alpha):\n        \"\"\"generates all the conditional patterns of respective node\n\n                :param alpha : it represents the Node in tree\n\n                :type alpha : Node\n        \"\"\"\n        finalPatterns = []\n        finalSets = []\n        sup = []\n        for i in self.summaries[alpha]:\n            set1 = i.TimeStamps\n            s = i.probability\n            set2 = []\n            while i.parent.item is not None:\n                set2.append(i.parent.item)\n                i = i.parent\n            if len(set2) > 0:\n                set2.reverse()\n                finalPatterns.append(set2)\n                finalSets.append(set1)\n                sup.append(s)\n        finalPatterns, finalSets, support, info = self.conditionalTransactions(finalPatterns, finalSets, sup)\n        return finalPatterns, finalSets, support, info\n\n    def removeNode(self, nodeValue):\n        \"\"\"removing the node from tree\n\n            :param nodeValue : it represents the node in tree\n\n            :type nodeValue : node\n        \"\"\"\n        for i in self.summaries[nodeValue]:\n            i.parent.TimeStamps = i.parent.TimeStamps + i.TimeStamps\n            del i.parent.children[nodeValue]\n\n    def getPeriodAndSupport(self, support, TimeStamps):\n        \"\"\"\n\n        Parameters\n        ----------\n        support: support of pattern\n        TimeStamps: timmeStamps of a pattern\n\n        Returns\n        -------\n        support and period\n\n        \"\"\"\n        global _maxPer\n        global _lno\n        TimeStamps.sort()\n        cur = 0\n        per = 0\n        sup = support\n        for j in range(len(TimeStamps)):\n            per = max(per, TimeStamps[j] - cur)\n            if per > _maxPer:\n                return [0, 0]\n            cur = TimeStamps[j]\n        per = max(per, _lno - cur)\n        return [sup, per]\n\n    def conditionalTransactions(self, conditionalPatterns, conditionalTimeStamps, support):\n        \"\"\" It generates the conditional patterns with frequent items\n\n            :param conditionalPatterns : conditional patterns generated from conditionalPatterns() method for respective node\n\n            :type conditionalPatterns : list\n\n            :param conditionalTimeStamps : timestamps of respective conditional timestamps\n\n            :type conditionalTimeStamps : list\n\n            :param support : the support of conditional pattern in tree\n\n            :type support : list\n        \"\"\"\n        global _minSup, _maxPer, _lno\n        pat = []\n        TimeStamps = []\n        sup = []\n        data1 = {}\n        count = {}\n        for i in range(len(conditionalPatterns)):\n            for j in conditionalPatterns[i]:\n                if j in data1:\n                    data1[j] = data1[j] + conditionalTimeStamps[i]\n                    count[j] += support[i]\n                else:\n                    data1[j] = conditionalTimeStamps[i]\n                    count[j] = support[i]\n        updatedDict = {}\n        for m in data1:\n            updatedDict[m] = self.getPeriodAndSupport(count[m], data1[m])\n        updatedDict = {k: v for k, v in updatedDict.items() if v[0] >= _minSup and v[1] <= _maxPer}\n        count = 0\n        for p in conditionalPatterns:\n            p1 = [v for v in p if v in updatedDict]\n            trans = sorted(p1, key=lambda x: (updatedDict.get(x)[0]), reverse=True)\n            if len(trans) > 0:\n                pat.append(trans)\n                TimeStamps.append(conditionalTimeStamps[count])\n                sup.append(support[count])\n            count += 1\n        return pat, TimeStamps, sup, updatedDict\n\n    def generatePatterns(self, prefix, periodic):\n        \"\"\"generates the patterns\n\n            :param prefix : forms the combination of items\n\n            :type prefix : list\n        \"\"\"\n        global _minSup\n        for i in sorted(self.summaries, key=lambda x: (self.info.get(x)[0])):\n            pattern = prefix[:]\n            pattern.append(i)\n            s = 0\n            for x in self.summaries[i]:\n                if x.k <= 2:\n                    s += x.probability\n                elif x.k >= 3:\n                    n = x.probability * pow(x.secondProbability, (x.k - 2))\n                    s += n\n            periodic[tuple(pattern)] = self.info[i]\n            if s >= _minSup:\n                patterns, TimeStamps, support, info = self.conditionalPatterns(i)\n                conditionalTree = _Tree()\n                conditionalTree.info = info.copy()\n                for pat in range(len(patterns)):\n                    conditionalTree.addConditionalPatterns(patterns[pat], TimeStamps[pat], support[pat])\n                if len(patterns) > 0:\n                    conditionalTree.generatePatterns(pattern, periodic)\n            self.removeNode(i)\n\n\nclass PTubeP(_ab._periodicFrequentPatterns):\n    \"\"\"\n        Periodic-TubeP is  to discover periodic-frequent patterns in a temporal database.\n\n        Reference:\n        --------\n\n\n        Attributes:\n        ----------\n            iFile: file\n                Name of the Input file or path of input file\n            oFile: file\n                Name of the output file or path of output file\n            minSup: int or float or str\n                The user can specify minSup either in count or proportion of database size.\n                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.\n                Otherwise, it will be treated as float.\n                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float\n            maxPer: int or float or str\n                The user can specify maxPer either in count or proportion of database size.\n                If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.\n                Otherwise, it will be treated as float.\n                Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float\n            sep: str\n                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \\t.\n                However, the users can override their default separator.\n            memoryUSS: float\n                To store the total amount of USS memory consumed by the program\n            memoryRSS: float\n                To store the total amount of RSS memory consumed by the program\n            startTime: float\n                To record the start time of the mining process\n            endTime: float\n                To record the completion time of the mining process\n            Database: list\n                To store the transactions of a database in list\n            mapSupport: Dictionary\n                To maintain the information of item and their frequency\n            lno: int\n                To represent the total no of transaction\n            tree: class\n                To represents the Tree class\n            itemSetCount: int\n                To represents the total no of patterns\n            finalPatterns: dict\n                To store the complete patterns\n        Methods:\n        -------\n            startMine()\n                Mining process will start from here\n            getPatterns()\n                Complete set of patterns will be retrieved with this function\n            savePatterns(oFile)\n                Complete set of periodic-frequent patterns will be loaded in to a output file\n            getPatternsAsDataFrame()\n                Complete set of periodic-frequent patterns will be loaded in to a dataframe\n            getMemoryUSS()\n                Total amount of USS memory consumed by the mining process will be retrieved from this function\n            getMemoryRSS()\n                Total amount of RSS memory consumed by the mining process will be retrieved from this function\n            getRuntime()\n                Total amount of runtime taken by the mining process will be retrieved from this function\n            creatingItemSets(fileName)\n                Scans the dataset and stores in a list format\n            updateDatabases()\n                Update the database by removing aperiodic items and sort the Database by item decreased support\n            buildTree()\n                After updating the Database, remaining items will be added into the tree by setting root node as null\n            convert()\n                to convert the user specified value\n            PeriodicFrequentOneItems()\n                To extract the one-length periodic-frequent items\n\n        Executing the code on terminal:\n        -------\n            Format:\n            ------\n                python3 PTubeP.py <inputFile> <outputFile> <minSup> <maxPer>\n\n            Examples:\n            --------\n                python3 PTubeP.py sampleTDB.txt patterns.txt 0.3 4     (minSup and maxPer will be considered in support count or frequency)\n\n        Sample run of importing the code:\n        -------------------\n\n            from PAMI.uncertainPeriodicFrequentPattern.basic import PTubeP as alg\n\n            obj = alg.PTubeP(iFile, minSup, maxPer)\n\n            obj.startMine()\n\n            periodicFrequentPatterns = obj.getPatterns()\n\n            print(\"Total number of Periodic Frequent Patterns:\", len(periodicFrequentPatterns))\n\n            obj.savePatterns(oFile)\n\n            Df = obj.getPatternsAsDataFrame()\n\n            memUSS = obj.getMemoryUSS()\n\n            print(\"Total Memory in USS:\", memUSS)\n\n            memRSS = obj.getMemoryRSS()\n\n            print(\"Total Memory in RSS\", memRSS)\n\n            run = obj.getRuntime()\n\n            print(\"Total ExecutionTime in seconds:\", run)\n\n        Credits:\n        -------\n            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\\n\n\n    \"\"\"\n    _startTime = float()\n    _endTime = float()\n    _minSup = float()\n    _maxPer = float()\n    _finalPatterns = {}\n    _iFile = \" \"\n    _oFile = \" \"\n    _sep = \" \"\n    _memoryUSS = float()\n    _memoryRSS = float()\n    _Database = []\n    _rank = {}\n    _lno = 0\n    _periodic = {}\n\n    def _creatingItemSets(self):\n        \"\"\"\n            Storing the complete transactions of the database/input file in a database variable\n\n\n        \"\"\"\n\n        self._Database = []\n        if isinstance(self._iFile, _ab._pd.DataFrame):\n            uncertain, data, ts = [], [], []\n            if self._iFile.empty:\n                print(\"its empty..\")\n            i = self._iFile.columns.values.tolist()\n            if 'TS' in i:\n                ts = self._iFile['TS'].tolist()\n            if 'Transactions' in i:\n                data = self._iFile['Transactions'].tolist()\n            if 'uncertain' in i:\n                uncertain = self._iFile['uncertain'].tolist()\n            for k in range(len(data)):\n                tr = [ts[k]]\n                for j in range(len(k)):\n                    product = _Item(data[k][j], uncertain[k][j])\n                    tr.append(product)\n                self._Database.append(tr)\n                self._lno += 1\n\n            # print(self.Database)\n        if isinstance(self._iFile, str):\n            if _ab._validators.url(self._iFile):\n                data = _ab._urlopen(self._iFile)\n                for line in data:\n                    line.strip()\n                    line = line.decode(\"utf-8\")\n                    temp = [i.rstrip() for i in line.split(self._sep)]\n                    temp = [x for x in temp if x]\n                    tr = []\n                    for i in temp[1:]:\n                        i1 = i.index('(')\n                        i2 = i.index(')')\n                        item = i[0:i1]\n                        probability = float(i[i1 + 1:i2])\n                        product = _Item(item, probability)\n                        tr.append(product)\n                    self._lno += 1\n                    self._Database.append(temp)\n            else:\n                try:\n                    count = 0\n                    with open(self._iFile, 'r') as f:\n                        for line in f:\n                            count += 1\n                            temp = [i.rstrip() for i in line.split(self._sep)]\n                            temp = [x for x in temp if x]\n                            tr = [count]\n                            for i in temp:\n                                i1 = i.index('(')\n                                i2 = i.index(')')\n                                item = i[0:i1]\n                                probability = float(i[i1 + 1:i2])\n                                product = _Item(item, probability)\n                                tr.append(product)\n                            self._lno += 1\n                            self._Database.append(tr)\n                except IOError:\n                    print(\"File Not Found\")\n\n    def _PeriodicFrequentOneItems(self):\n        \"\"\"takes the transactions and calculates the support of each item in the dataset and assign the\n                            ranks to the items by decreasing support and returns the frequent items list\n\n        \"\"\"\n        global first, last\n        mapSupport = {}\n        for i in self._Database:\n            n = int(i[0])\n            for j in i[1:]:\n                if j.item not in mapSupport:\n                    mapSupport[j.item] = [round(j.probability, 2), abs(0 - n), n]\n                else:\n                    mapSupport[j.item][0] += round(j.probability, 2)\n                    mapSupport[j.item][1] = max(mapSupport[j.item][1], abs(n - mapSupport[j.item][2]))\n                    mapSupport[j.item][2] = n\n        for key in mapSupport:\n            mapSupport[key][1] = max(mapSupport[key][1], self._lno - mapSupport[key][2])\n        mapSupport = {k: [round(v[0], 2), v[1]] for k, v in mapSupport.items() if\n                      v[1] <= self._maxPer and v[0] >= self._minSup}\n        plist = [k for k, v in sorted(mapSupport.items(), key=lambda x: (x[1][0], x[0]), reverse=True)]\n        self._rank = dict([(index, item) for (item, index) in enumerate(plist)])\n        return mapSupport, plist\n\n    def _buildTree(self, data, info):\n        \"\"\"it takes the transactions and support of each item and construct the main tree with setting root\n                            node as null\n\n            :param data : it represents the one transactions in database\n\n            :type data : list\n\n            :param info : it represents the support of each item\n\n            :type info : dictionary\n        \"\"\"\n        rootNode = _Tree()\n        rootNode.info = info.copy()\n        for i in range(len(data)):\n            set1 = [data[i][0]]\n            rootNode.addTransaction(data[i][1:], set1)\n        return rootNode\n\n    def _updateTransactions(self, dict1):\n        \"\"\"remove the items which are not frequent from transactions and updates the transactions with rank of items\n\n                :param dict1 : frequent items with support\n\n                :type dict1 : dictionary\n        \"\"\"\n        list1 = []\n        for tr in self._Database:\n            list2 = [int(tr[0])]\n            for i in range(1, len(tr)):\n                if tr[i].item in dict1:\n                    list2.append(tr[i])\n            if len(list2) >= 2:\n                basket = list2[1:]\n                basket.sort(key=lambda val: self._rank[val.item])\n                list2[1:] = basket[0:]\n                list1.append(list2)\n        return list1\n\n    def _Check(self, i, x):\n        \"\"\"To check the presence of item or pattern in transaction\n\n            :param x: it represents the pattern\n\n            :type x : list\n\n            :param i : represents the uncertain transactions\n\n            :type i : list\n        \"\"\"\n        for m in x:\n            k = 0\n            for n in i:\n                if m == n.item:\n                    k += 1\n            if k == 0:\n                return 0\n        return 1\n\n    def _convert(self, value):\n        \"\"\"\n            To convert the given user specified value\n\n            :param value: user specified value\n\n            :return: converted value\n        \"\"\"\n        if type(value) is int:\n            value = int(value)\n        if type(value) is float:\n            value = int(len(self._Database) * value)\n        if type(value) is str:\n            if '.' in value:\n                value = int(len(self._Database) * value)\n            else:\n                value = int(value)\n\n        return value\n\n    def _removeFalsePositives(self):\n        \"\"\"\n        To remove false positives in generated patterns\n\n        :return: original patterns\n        \"\"\"\n        periods = {}\n        for i in self._Database:\n            for x, y in self._periodic.items():\n                if len(x) == 1:\n                    periods[x] = y\n                else:\n                    s = 1\n                    check = self._Check(i[1:], x)\n                    if check == 1:\n                        for j in i[1:]:\n                            if j.item in x:\n                                s *= j.probability\n                        if x in periods:\n                            periods[x][0] += s\n                        else:\n                            periods[x] = [s, y[1]]\n        for x, y in periods.items():\n            if y[0] >= _minSup:\n                sample = str()\n                for i in x:\n                    sample = sample + i + \" \"\n                self._finalPatterns[sample] = y\n\n    def startMine(self):\n        \"\"\"Main method where the patterns are mined by constructing tree and remove the remove the false patterns\n                           by counting the original support of a patterns\n\n\n               \"\"\"\n        global _minSup, _maxPer, _first, _last, _lno\n        self._startTime = _ab._time.time()\n        self._creatingItemSets()\n        self._minSup = self._convert(self._minSup)\n        self._maxPer = self._convert(self._maxPer)\n        self._finalPatterns = {}\n        _minSup, _maxPer, _lno = self._minSup, self._maxPer, len(self._Database)\n        mapSupport, plist = self._PeriodicFrequentOneItems()\n        updatedTrans = self._updateTransactions(mapSupport)\n        info = {k: v for k, v in mapSupport.items()}\n        root = self._buildTree(updatedTrans, info)\n        self._periodic = {}\n        root.generatePatterns([], self._periodic)\n        self._removeFalsePositives()\n        print(\"Periodic Frequent patterns were generated successfully using Periodic-TubeP algorithm\")\n        self._endTime = _ab._time.time()\n        process = _ab._psutil.Process(_ab._os.getpid())\n        self._memoryUSS = float()\n        self._memoryRSS = float()\n        self._memoryUSS = process.memory_full_info().uss\n        self._memoryRSS = process.memory_info().rss\n\n    def getMemoryUSS(self):\n        \"\"\"Total amount of USS memory consumed by the mining process will be retrieved from this function\n\n        :return: returning USS memory consumed by the mining process\n\n        :rtype: float\n        \"\"\"\n\n        return self._memoryUSS\n\n    def getMemoryRSS(self):\n        \"\"\"Total amount of RSS memory consumed by the mining process will be retrieved from this function\n\n        :return: returning RSS memory consumed by the mining process\n\n        :rtype: float\n        \"\"\"\n\n        return self._memoryRSS\n\n    def getRuntime(self):\n        \"\"\"Calculating the total amount of runtime taken by the mining process\n\n        :return: returning total amount of runtime taken by the mining process\n\n        :rtype: float\n        \"\"\"\n\n        return self._endTime - self._startTime\n\n    def getPatternsAsDataFrame(self):\n        \"\"\"Storing final frequent patterns in a dataframe\n\n        :return: returning frequent patterns in a dataframe\n\n        :rtype: pd.DataFrame\n        \"\"\"\n\n        dataframe = {}\n        data = []\n        for a, b in self._finalPatterns.items():\n            data.append([a, b[0], b[1]])\n            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])\n        return dataframe\n\n    def savePatterns(self, outFile):\n        \"\"\"Complete set of frequent patterns will be loaded in to a output file\n\n        :param outFile: name of the output file\n\n        :type outFile: file\n        \"\"\"\n        self._oFile = outFile\n        writer = open(self._oFile, 'w+')\n        for x, y in self._finalPatterns.items():\n            s1 = x + \":\" + str(y)\n            writer.write(\"%s \\n\" % s1)\n\n    def getPatterns(self):\n        \"\"\" Function to send the set of frequent patterns after completion of the mining process\n\n        :return: returning frequent patterns\n        :rtype: dict\n        \"\"\"\n        return self._finalPatterns\n\n\nif __name__ == \"__main__\":\n    _ap = str()\n    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:\n        if len(_ab._sys.argv) == 6:\n            _ap = PTubeP(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])\n        if len(_ab._sys.argv) == 5:\n            _ap = PTubeP(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])\n        _ap.startMine()\n        _Patterns = _ap.getPatterns()\n        print(\"Total number of Patterns:\", len(_Patterns))\n        _ap.savePatterns(_ab._sys.argv[2])\n        # print(ap.getPatternsAsDataFrame())\n        _memUSS = _ap.getMemoryUSS()\n        print(\"Total Memory in USS:\", _memUSS)\n        _memRSS = _ap.getMemoryRSS()\n        print(\"Total Memory in RSS\", _memRSS)\n        _run = _ap.getRuntime()\n        print(\"Total ExecutionTime in ms:\", _run)\n    else:\n        l = [140]\n        for i in l:\n            ap = PTubeP('/home/apiiit-rkv/Desktop/uncertain/congestion', i, 2000, ' ')\n            ap.startMine()\n            Patterns = ap.getPatterns()\n            print(\"Total number of Patterns:\", len(Patterns))\n            ap.savePatterns('/home/apiiit-rkv/Desktop/uncertain/output')\n            memUSS = ap.getMemoryUSS()\n            print(\"Total Memory in USS:\", memUSS)\n            memRSS = ap.getMemoryRSS()\n            print(\"Total Memory in RSS\", memRSS)\n            run = ap.getRuntime()\n            print(\"Total ExecutionTime in ms:\", run)\n        print(\"Error! The number of input parameters do not match the total number of parameters provided\")\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/uncertainPeriodicFrequentPattern/basic/PTubeP.py b/PAMI/uncertainPeriodicFrequentPattern/basic/PTubeP.py
--- a/PAMI/uncertainPeriodicFrequentPattern/basic/PTubeP.py	(revision 13e95f8a76f333a1a390dbc39efe0767be0b94b4)
+++ b/PAMI/uncertainPeriodicFrequentPattern/basic/PTubeP.py	(date 1656441096683)
@@ -534,7 +534,7 @@
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
                             tr = [count]
-                            for i in temp:
+                            for i in temp[1:]:
                                 i1 = i.index('(')
                                 i2 = i.index(')')
                                 item = i[0:i1]
@@ -792,13 +792,13 @@
         _run = _ap.getRuntime()
         print("Total ExecutionTime in ms:", _run)
     else:
-        l = [140]
+        l = [150]
         for i in l:
-            ap = PTubeP('/home/apiiit-rkv/Desktop/uncertain/congestion', i, 2000, ' ')
+            ap = PTubeP('/Users/Likhitha/Downloads/uncertain/additionalMaterial/Congestion.txt', i, 2000, ' ')
             ap.startMine()
             Patterns = ap.getPatterns()
             print("Total number of Patterns:", len(Patterns))
-            ap.savePatterns('/home/apiiit-rkv/Desktop/uncertain/output')
+            ap.savePatterns('/Users/Likhitha/Downloads/uncertain/output.txt')
             memUSS = ap.getMemoryUSS()
             print("Total Memory in USS:", memUSS)
             memRSS = ap.getMemoryRSS()
Index: PAMI/uncertainFrequentPattern/basic/PUFGrowth.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#  Copyright (C)  2021 Rage Uday Kiran\n#\n#      This program is free software: you can redistribute it and/or modify\n#      it under the terms of the GNU General Public License as published by\n#      the Free Software Foundation, either version 3 of the License, or\n#      (at your option) any later version.\n#\n#      This program is distributed in the hope that it will be useful,\n#      but WITHOUT ANY WARRANTY; without even the implied warranty of\n#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#      GNU General Public License for more details.\n#\n#      You should have received a copy of the GNU General Public License\n#      along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nfrom PAMI.uncertainFrequentPattern.basic import abstract as _ab\n\n_minSup = str()\n_ab._sys.setrecursionlimit(20000)\n_finalPatterns = {}\n\n\nclass _Item:\n    \"\"\"\n    A class used to represent the item with probability in transaction of dataset\n    ...\n    Attributes:\n    __________\n        item : int or word\n            Represents the name of the item\n        probability : float\n            Represent the existential probability(likelihood presence) of an item\n    \"\"\"\n\n    def __init__(self, item, probability):\n        self.item = item\n        self.probability = probability\n\n\nclass _Node(object):\n    \"\"\"\n    A class used to represent the node of frequentPatternTree\n        ...\n    Attributes:\n    ----------\n        item : int\n            storing item of a node\n        probability : int\n            To maintain the expected support of node\n        parent : node\n            To maintain the parent of every node\n        children : list\n            To maintain the children of node\n    Methods:\n    -------\n        addChild(itemName)\n            storing the children to their respective parent nodes\n    \"\"\"\n\n    def __init__(self, item, children):\n        self.item = item\n        self.probability = 1\n        self.children = children\n        self.parent = None\n\n    def addChild(self, node):\n        self.children[node.item] = node\n        node.parent = self\n\n\nclass _Tree(object):\n    \"\"\"\n    A class used to represent the frequentPatternGrowth tree structure\n    ...\n    Attributes:\n    ----------\n        root : Node\n            Represents the root node of the tree\n        summaries : dictionary\n            storing the nodes with same item name\n        info : dictionary\n            stores the support of items\n    Methods:\n    -------\n        addTransaction(transaction)\n            creating transaction as a branch in frequentPatternTree\n        addConditionalPattern(prefixPaths, supportOfItems)\n            construct the conditional tree for prefix paths\n        conditionalPatterns(Node)\n            generates the conditional patterns from tree for specific node\n        conditionalTransactions(prefixPaths,Support)\n            takes the prefixPath of a node and support at child of the path and extract the frequent items from\n            prefixPaths and generates prefixPaths with items which are frequent\n        remove(Node)\n            removes the node from tree once after generating all the patterns respective to the node\n        generatePatterns(Node)\n            starts from the root node of the tree and mines the frequent patterns\n    \"\"\"\n\n    def __init__(self):\n        self.root = _Node(None, {})\n        self.summaries = {}\n        self.info = {}\n\n    def addTransaction(self, transaction):\n        \"\"\"adding transaction into tree\n            :param transaction : it represents the one self.Database in database\n            :type transaction : list\n        \"\"\"\n\n        currentNode = self.root\n        for i in range(len(transaction)):\n            if transaction[i].item not in currentNode.children:\n                newNode = _Node(transaction[i].item, {})\n                l1 = i - 1\n                lp = []\n                while l1 >= 0:\n                    lp.append(transaction[l1].probability)\n                    l1 -= 1\n                if len(lp) == 0:\n                    newNode.probability = transaction[i].probability\n                else:\n                    newNode.probability = max(lp) * transaction[i].probability\n                currentNode.addChild(newNode)\n                if transaction[i].item in self.summaries:\n                    self.summaries[transaction[i].item].append(newNode)\n                else:\n                    self.summaries[transaction[i].item] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i].item]\n                l1 = i - 1\n                lp = []\n                while l1 >= 0:\n                    lp.append(transaction[l1].probability)\n                    l1 -= 1\n                if len(lp) == 0:\n                    currentNode.probability += transaction[i].probability\n                else:\n                    currentNode.probability += max(lp) * transaction[i].probability\n\n    def addConditionalPattern(self, transaction, sup):\n        \"\"\"constructing conditional tree from prefixPaths\n            :param transaction : it represents the one self.Database in database\n            :type transaction : list\n            :param sup : support of prefixPath taken at last child of the path\n            :type sup : int\n        \"\"\"\n\n        # This method takes transaction, support and constructs the conditional tree\n        currentNode = self.root\n        for i in range(len(transaction)):\n            if transaction[i] not in currentNode.children:\n                newNode = _Node(transaction[i], {})\n                newNode.probability = sup\n                currentNode.addChild(newNode)\n                if transaction[i] in self.summaries:\n                    self.summaries[transaction[i]].append(newNode)\n                else:\n                    self.summaries[transaction[i]] = [newNode]\n                currentNode = newNode\n            else:\n                currentNode = currentNode.children[transaction[i]]\n                currentNode.probability += sup\n\n    def conditionalPatterns(self, alpha):\n        \"\"\"generates all the conditional patterns of respective node\n            :param alpha : it represents the Node in tree\n            :type alpha : _Node\n        \"\"\"\n\n        # This method generates conditional patterns of node by traversing the tree\n        finalPatterns = []\n        sup = []\n        for i in self.summaries[alpha]:\n            s = i.probability\n            set2 = []\n            while i.parent.item is not None:\n                set2.append(i.parent.item)\n                i = i.parent\n            if len(set2) > 0:\n                set2.reverse()\n                finalPatterns.append(set2)\n                sup.append(s)\n        finalPatterns, support, info = self.conditionalTransactions(finalPatterns, sup)\n        return finalPatterns, support, info\n\n    def removeNode(self, nodeValue):\n        \"\"\"removing the node from tree\n            :param nodeValue : it represents the node in tree\n            :type nodeValue : node\n        \"\"\"\n\n        for i in self.summaries[nodeValue]:\n            del i.parent.children[nodeValue]\n\n    def conditionalTransactions(self, condPatterns, support):\n        \"\"\" It generates the conditional patterns with frequent items\n                :param condPatterns : conditionalPatterns generated from conditionalPattern method for respective node\n                :type condPatterns : list\n                :support : the support of conditional pattern in tree\n                :support : int\n        \"\"\"\n\n        global minSup\n        pat = []\n        sup = []\n        count = {}\n        for i in range(len(condPatterns)):\n            for j in condPatterns[i]:\n                if j in count:\n                    count[j] += support[i]\n                else:\n                    count[j] = support[i]\n        updatedDict = {}\n        updatedDict = {k: v for k, v in count.items() if v >= minSup}\n        count = 0\n        for p in condPatterns:\n            p1 = [v for v in p if v in updatedDict]\n            trans = sorted(p1, key=lambda x: updatedDict[x], reverse=True)\n            if len(trans) > 0:\n                pat.append(trans)\n                sup.append(support[count])\n                count += 1\n        return pat, sup, updatedDict\n\n    def generatePatterns(self, prefix):\n        \"\"\"generates the patterns\n            :param prefix : forms the combination of items\n            :type prefix : list\n        \"\"\"\n\n        global _finalPatterns, minSup\n        for i in sorted(self.summaries, key=lambda x: (self.info.get(x))):\n            pattern = prefix[:]\n            pattern.append(i)\n            s = 0\n            for x in self.summaries[i]:\n                s += x.probability\n            _finalPatterns[tuple(pattern)] = self.info[i]\n            if s >= minSup:\n                patterns, support, info = self.conditionalPatterns(i)\n                conditionalTree = _Tree()\n                conditionalTree.info = info.copy()\n                for pat in range(len(patterns)):\n                    conditionalTree.addConditionalPattern(patterns[pat], support[pat])\n                if len(patterns) > 0:\n                    conditionalTree.generatePatterns(pattern)\n            self.removeNode(i)\n\n\nclass PUFGrowth(_ab._frequentPatterns):\n    \"\"\"\n        It is one of the fundamental algorithm to discover frequent patterns in a uncertain transactional database\n        using PUF-Tree.\n    Reference:\n    --------\n        Carson Kai-Sang Leung, Syed Khairuzzaman Tanbeer, \"PUF-Tree: A Compact Tree Structure for Frequent Pattern Mining of Uncertain Data\",\n        Pacific-Asia Conference on Knowledge Discovery and Data Mining(PAKDD 2013), https://link.springer.com/chapter/10.1007/978-3-642-37453-1_2\n    Attributes:\n    ----------\n        iFile : file\n            Name of the Input file or path of the input file\n        oFile : file\n            Name of the output file or path of the output file\n        minSup: float or int or str\n            The user can specify minSup either in count or proportion of database size.\n            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.\n            Otherwise, it will be treated as float.\n            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float\n        sep : str\n            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \\t.\n            However, the users can override their default separator.\n        memoryUSS : float\n            To store the total amount of USS memory consumed by the program\n        memoryRSS : float\n            To store the total amount of RSS memory consumed by the program\n        startTime:float\n            To record the start time of the mining process\n        endTime:float\n            To record the completion time of the mining process\n        Database : list\n            To store the transactions of a database in list\n        mapSupport : Dictionary\n            To maintain the information of item and their frequency\n        lno : int\n            To represent the total no of transaction\n        tree : class\n            To represents the Tree class\n        itemSetCount : int\n            To represents the total no of patterns\n        finalPatterns : dict\n            To store the complete patterns\n    Methods:\n    -------\n        startMine()\n            Mining process will start from here\n        getPatterns()\n            Complete set of patterns will be retrieved with this function\n        savePatterns(oFile)\n            Complete set of frequent patterns will be loaded in to a output file\n        getPatternsAsDataFrame()\n            Complete set of frequent patterns will be loaded in to a dataframe\n        getMemoryUSS()\n            Total amount of USS memory consumed by the mining process will be retrieved from this function\n        getMemoryRSS()\n            Total amount of RSS memory consumed by the mining process will be retrieved from this function\n        getRuntime()\n            Total amount of runtime taken by the mining process will be retrieved from this function\n        creatingItemSets(fileName)\n            Scans the dataset and stores in a list format\n        frequentOneItem()\n            Extracts the one-length frequent patterns from database\n        updateTransactions()\n            Update the transactions by removing non-frequent items and sort the Database by item decreased support\n        buildTree()\n            After updating the Database, remaining items will be added into the tree by setting root node as null\n        convert()\n            to convert the user specified value\n        startMine()\n            Mining process will start from this function\n    Executing the code on terminal:\n    -------\n        Format:\n        ------\n        python3 PUFGrowth.py <inputFile> <outputFile> <minSup>\n        Examples:\n        --------\n        python3 PUFGrowth.py sampleTDB.txt patterns.txt 3    (minSup  will be considered in support count or frequency)\n    Sample run of importing the code:\n    -------------------\n        from PAMI.uncertainFrequentPattern.basic import puf as alg\n        obj = alg.PUFGrowth(iFile, minSup)\n        obj.startMine()\n        Patterns = obj.getPatterns()\n        print(\"Total number of  Patterns:\", len(Patterns))\n        obj.savePatterns(oFile)\n        Df = obj.getPatternsAsDataFrame()\n        memUSS = obj.getMemoryUSS()\n        print(\"Total Memory in USS:\", memUSS)\n        memRSS = obj.getMemoryRSS()\n        print(\"Total Memory in RSS\", memRSS)\n        run = obj.getRuntime()\n        print(\"Total ExecutionTime in seconds:\", run)\n    Credits:\n    -------\n        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\\n\n    \"\"\"\n    _startTime = float()\n    _endTime = float()\n    _minSup = str()\n    _finalPatterns = {}\n    _iFile = \" \"\n    _oFile = \" \"\n    _sep = \" \"\n    _memoryUSS = float()\n    _memoryRSS = float()\n    _Database = []\n    _rank = {}\n\n    def __init__(self, iFile, minSup, sep='\\t'):\n        super().__init__(iFile, minSup, sep)\n\n    def _creatingItemSets(self):\n        \"\"\"\n            Scans the uncertain transactional dataset\n        \"\"\"\n        self._Database = []\n        if isinstance(self._iFile, _ab._pd.DataFrame):\n            uncertain, data = [], []\n            if self._iFile.empty:\n                print(\"its empty..\")\n            i = self._iFile.columns.values.tolist()\n            if 'Transactions' in i:\n                self._Database = self._iFile['Transactions'].tolist()\n            if 'uncertain' in i:\n                uncertain = self._iFile['uncertain'].tolist()\n            for k in range(len(data)):\n                tr = []\n                for j in range(len(data[k])):\n                    product = _Item(data[k][j], uncertain[k][j])\n                    tr.append(product)\n                self._Database.append(tr)\n\n            # print(self.Database)\n        if isinstance(self._iFile, str):\n            if _ab._validators.url(self._iFile):\n                data = _ab._urlopen(self._iFile)\n                for line in data:\n                    line.strip()\n                    line = line.decode(\"utf-8\")\n                    temp = [i.rstrip() for i in line.split(self._sep)]\n                    temp = [x for x in temp if x]\n                    tr = []\n                    for i in temp:\n                        i1 = i.index('(')\n                        i2 = i.index(')')\n                        item = i[0:i1]\n                        probability = float(i[i1 + 1:i2])\n                        product = _Item(item, probability)\n                        tr.append(product)\n                    self._Database.append(temp)\n            else:\n                try:\n                    with open(self._iFile, 'r') as f:\n                        for line in f:\n                            temp = [i.rstrip() for i in line.split(self._sep)]\n                            temp = [x for x in temp if x]\n                            tr = []\n                            for i in temp:\n                                i1 = i.index('(')\n                                i2 = i.index(')')\n                                item = i[0:i1]\n                                probability = float(i[i1 + 1:i2])\n                                product = _Item(item, probability)\n                                tr.append(product)\n                            self._Database.append(tr)\n                except IOError:\n                    print(\"File Not Found\")\n\n    def _frequentOneItem(self):\n        \"\"\"takes the self.Database and calculates the support of each item in the dataset and assign the\n            ranks to the items by decreasing support and returns the frequent items list\n                :param self.Database : it represents the one self.Database in database\n                :type self.Database : list\n        \"\"\"\n\n        mapSupport = {}\n        for i in self._Database:\n            for j in i:\n                if j.item not in mapSupport:\n                    mapSupport[j.item] = j.probability\n                else:\n                    mapSupport[j.item] += j.probability\n        mapSupport = {k: v for k, v in mapSupport.items() if v >= self._minSup}\n        plist = [k for k, v in sorted(mapSupport.items(), key=lambda x: x[1], reverse=True)]\n        self.rank = dict([(index, item) for (item, index) in enumerate(plist)])\n        return mapSupport, plist\n\n    @staticmethod\n    def _buildTree(data, info):\n        \"\"\"it takes the self.Database and support of each item and construct the main tree with setting root\n            node as null\n                :param data : it represents the one self.Database in database\n                :type data : list\n                :param info : it represents the support of each item\n                :type info : dictionary\n        \"\"\"\n\n        rootNode = _Tree()\n        rootNode.info = info.copy()\n        for i in range(len(data)):\n            rootNode.addTransaction(data[i])\n        return rootNode\n\n    def _updateTransactions(self, dict1):\n        \"\"\"remove the items which are not frequent from self.Database and updates the self.Database with rank of items\n            :param dict1 : frequent items with support\n            :type dict1 : dictionary\n        \"\"\"\n\n        list1 = []\n        for tr in self._Database:\n            list2 = []\n            for i in range(0, len(tr)):\n                if tr[i].item in dict1:\n                    list2.append(tr[i])\n            if len(list2) >= 2:\n                basket = list2\n                basket.sort(key=lambda val: self.rank[val.item])\n                list2 = basket\n                list1.append(list2)\n        return list1\n\n    @staticmethod\n    def _check(i, x):\n        \"\"\"To check the presence of item or pattern in transaction\n                :param x: it represents the pattern\n                :type x : list\n                :param i : represents the uncertain self.Database\n                :type i : list\n        \"\"\"\n\n        # This method taken a transaction as input and returns the tree\n        for m in x:\n            k = 0\n            for n in i:\n                if m == n.item:\n                    k += 1\n            if k == 0:\n                return 0\n        return 1\n\n    def _convert(self, value):\n        \"\"\"\n        To convert the type of user specified minSup value\n            :param value: user specified minSup value\n            :return: converted type minSup value\n        \"\"\"\n        if type(value) is int:\n            value = int(value)\n        if type(value) is float:\n            value = (len(self._Database) * value)\n        if type(value) is str:\n            if '.' in value:\n                value = (len(self._Database) * value)\n            else:\n                value = int(value)\n        return value\n\n    def _removeFalsePositives(self):\n        \"\"\"\n            To remove the false positive patterns generated in frequent patterns\n            :return: patterns with accurate probability\n        \"\"\"\n        global _finalPatterns\n        periods = {}\n        for i in self._Database:\n            for x, y in _finalPatterns.items():\n                if len(x) == 1:\n                    periods[x] = y\n                else:\n                    s = 1\n                    check = self._check(i, x)\n                    if check == 1:\n                        for j in i:\n                            if j.item in x:\n                                s *= j.probability\n                        if x in periods:\n                            periods[x] += s\n                        else:\n                            periods[x] = s\n        for x, y in periods.items():\n            if y >= self._minSup:\n                sample = str()\n                for i in x:\n                    sample = sample + i + \" \"\n                self._finalPatterns[sample] = y\n\n    def startMine(self):\n        \"\"\"Main method where the patterns are mined by constructing tree and remove the remove the false patterns\n            by counting the original support of a patterns\n        \"\"\"\n        global minSup\n        self._startTime = _ab._time.time()\n        self._creatingItemSets()\n        self._minSup = self._convert(self._minSup)\n        minSup = self._minSup\n        self._finalPatterns = {}\n        mapSupport, plist = self._frequentOneItem()\n        self.Database1 = self._updateTransactions(mapSupport)\n        info = {k: v for k, v in mapSupport.items()}\n        Tree1 = self._buildTree(self.Database1, info)\n        Tree1.generatePatterns([])\n        self._removeFalsePositives()\n        print(\"Frequent patterns were generated from uncertain databases successfully using PUF algorithm\")\n        self._endTime = _ab._time.time()\n        process = _ab._psutil.Process(_ab._os.getpid())\n        self._memoryUSS = float()\n        self.memoryRSS = float()\n        self._memoryUSS = process.memory_full_info().uss\n        self.memoryRSS = process.memory_info().rss\n\n    def getMemoryUSS(self):\n        \"\"\"Total amount of USS memory consumed by the mining process will be retrieved from this function\n        :return: returning USS memory consumed by the mining process\n        :rtype: float\n        \"\"\"\n\n        return self._memoryUSS\n\n    def getMemoryRSS(self):\n        \"\"\"Total amount of RSS memory consumed by the mining process will be retrieved from this function\n        :return: returning RSS memory consumed by the mining process\n        :rtype: float\n        \"\"\"\n\n        return self.memoryRSS\n\n    def getRuntime(self):\n        \"\"\"Calculating the total amount of runtime taken by the mining process\n        :return: returning total amount of runtime taken by the mining process\n        :rtype: float\n        \"\"\"\n\n        return self._endTime - self._startTime\n\n    def getPatternsAsDataFrame(self):\n        \"\"\"Storing final frequent patterns in a dataframe\n        :return: returning frequent patterns in a dataframe\n        :rtype: pd.DataFrame\n        \"\"\"\n\n        dataframe = {}\n        data = []\n        for a, b in self._finalPatterns.items():\n            data.append([a, b])\n            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])\n        return dataframe\n\n    def savePatterns(self, outFile):\n        \"\"\"Complete set of frequent patterns will be loaded in to a output file\n        :param outFile: name of the output file\n        :type outFile: file\n        \"\"\"\n        self.oFile = outFile\n        writer = open(self.oFile, 'w+')\n        for x, y in self._finalPatterns.items():\n            s1 = x + \":\" + str(y)\n            writer.write(\"%s \\n\" % s1)\n\n    def getPatterns(self):\n        \"\"\" Function to send the set of frequent patterns after completion of the mining process\n        :return: returning frequent patterns\n        :rtype: dict\n        \"\"\"\n        return self._finalPatterns\n\n\nif __name__ == \"__main__\":\n    _ap = str()\n    if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:\n        if len(_ab._sys.argv) == 5:\n            _ap = PUFGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])\n        if len(_ab._sys.argv) == 4:\n            _ap = PUFGrowth(_ab._sys.argv[1], _ab._sys.argv[3])\n        _ap.startMine()\n        _Patterns = _ap.getPatterns()\n        print(\"Total number of Patterns:\", len(_Patterns))\n        _ap.savePatterns(_ab._sys.argv[2])\n        _memUSS = _ap.getMemoryUSS()\n        print(\"Total Memory in USS:\", _memUSS)\n        _memRSS = _ap.getMemoryRSS()\n        print(\"Total Memory in RSS\", _memRSS)\n        _run = _ap.getRuntime()\n        print(\"Total ExecutionTime in ms:\", _run)\n    else:\n        '''ap = PUFGrowth(\"/home/apiiit-rkv/Desktop/uncertain/tubeSample\", 0.01, ' ')\n        ap.startMine()\n        Patterns = ap.getPatterns()\n        print(\"Total number of Patterns:\", len(Patterns))\n        ap.savePatterns(\"patterns.txt\")\n        memUSS = ap.getMemoryUSS()\n        print(\"Total Memory in USS:\", memUSS)\n        memRSS = ap.getMemoryRSS()\n        print(\"Total Memory in RSS\", memRSS)\n        run = ap.getRuntime()\n        print(\"Total ExecutionTime in ms:\", run)'''\n        print(\"Error! The number of input parameters do not match the total number of parameters provided\")
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/uncertainFrequentPattern/basic/PUFGrowth.py b/PAMI/uncertainFrequentPattern/basic/PUFGrowth.py
--- a/PAMI/uncertainFrequentPattern/basic/PUFGrowth.py	(revision 13e95f8a76f333a1a390dbc39efe0767be0b94b4)
+++ b/PAMI/uncertainFrequentPattern/basic/PUFGrowth.py	(date 1656441096695)
@@ -544,8 +544,10 @@
         global minSup
         self._startTime = _ab._time.time()
         self._creatingItemSets()
-        self._minSup = self._convert(self._minSup)
+        #self._minSup = self._convert(self._minSup)
+        self._minSup = float(self._minSup)
         minSup = self._minSup
+        print(self._minSup)
         self._finalPatterns = {}
         mapSupport, plist = self._frequentOneItem()
         self.Database1 = self._updateTransactions(mapSupport)
@@ -635,7 +637,7 @@
         _run = _ap.getRuntime()
         print("Total ExecutionTime in ms:", _run)
     else:
-        '''ap = PUFGrowth("/home/apiiit-rkv/Desktop/uncertain/tubeSample", 0.01, ' ')
+        ap = PUFGrowth("/Users/likhitha/Downloads/Nighbours_gen/uncertainSpatailFrequent/sample.txt", 0.1, ' ')
         ap.startMine()
         Patterns = ap.getPatterns()
         print("Total number of Patterns:", len(Patterns))
@@ -645,5 +647,5 @@
         memRSS = ap.getMemoryRSS()
         print("Total Memory in RSS", memRSS)
         run = ap.getRuntime()
-        print("Total ExecutionTime in ms:", run)'''
+        print("Total ExecutionTime in ms:", run)
         print("Error! The number of input parameters do not match the total number of parameters provided")
\ No newline at end of file
diff --git a/PAMI/weightedFrequentNeighbourhoodPattern/SWFPGrowth.py b/PAMI/weightedFrequentNeighbourhoodPattern/SWFPGrowth.py
new file mode 100644
